{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "804c5b61",
   "metadata": {},
   "source": [
    "using sampler=\"schlichtkrull\" and num_workers = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30eabec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykeen.pipeline import pipeline\n",
    "from pykeen.datasets import Nations, get_dataset\n",
    "import torch\n",
    "from pykeen.evaluation import evaluate, RankBasedEvaluator\n",
    "from pykeen.metrics.ranking import HitsAtK\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "import click\n",
    "import more_click\n",
    "import torch\n",
    "from pykeen.evaluation import RankBasedEvaluator\n",
    "from pykeen.losses import NSSALoss,CrossEntropyLoss\n",
    "from pykeen.models.inductive import InductiveNodePiece, InductiveNodePieceGNN\n",
    "from pykeen.trackers import ConsoleResultTracker, WANDBResultTracker, FileResultTracker\n",
    "from pykeen.training import SLCWATrainingLoop\n",
    "from pykeen.typing import TESTING, TRAINING, VALIDATION\n",
    "from pykeen.utils import resolve_device, set_random_seed\n",
    "from torch.optim import Adam\n",
    "\n",
    "\n",
    "from pykeen.metrics.ranking import HitsAtK\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from pykeen.datasets.inductive.base import DisjointInductivePathDataset\n",
    "from pykeen.datasets.base import PathDataset, Dataset\n",
    "from typing_extensions import Literal\n",
    "import os\n",
    "from pykeen.hpo import hpo_pipeline\n",
    "from pykeen.triples import TriplesFactory\n",
    "from pykeen.models import InductiveNodePiece, TransE, RGCN\n",
    "from pykeen.typing import TESTING, TRAINING, VALIDATION\n",
    "\n",
    "import time\n",
    "\n",
    "import platform\n",
    "\n",
    "import sys\n",
    "\n",
    "import cpuinfo\n",
    "\n",
    "import psutil\n",
    "\n",
    "import subprocess\n",
    "\n",
    "import zipfile\n",
    "\n",
    "seed = 1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba970fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_metrics(dictionary,model_name,csv_name):\n",
    "    for key in dictionary.keys():\n",
    "        print(key)\n",
    "        df = pd.DataFrame(dictionary[key])\n",
    "        df.to_csv(f\"{model_name}/{model_name}_{csv_name}_{key}.csv\")\n",
    "        print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612fd4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TYPE = \"_transductive.tsv\"\n",
    "TRAIN_PATH = \"MSCallGraph_train\" + DATA_TYPE\n",
    "TEST_PATH = \"MSCallGraph_test\" + DATA_TYPE\n",
    "VALIDATE_PATH = \"MSCallGraph_validation\" + DATA_TYPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750b49c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PathDataset(training_path = TRAIN_PATH,\n",
    "                     testing_path = TEST_PATH,\n",
    "                     validation_path = VALIDATE_PATH,\n",
    "                      eager = True\n",
    "                     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b863c567",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'rgcn_transductive_2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e64fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker = ConsoleResultTracker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141b31a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = NSSALoss() #used by RotatE and NodePiece\n",
    "embedding_dim = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee10f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RGCN(\n",
    "        triples_factory=dataset.training,\n",
    "        random_seed = seed,\n",
    "        loss = loss,\n",
    "        embedding_dim = embedding_dim,\n",
    "    ).to(resolve_device())\n",
    "print(f\"Number of parameters: {sum(p.numel() for p in model.parameters())}\")\n",
    "print(f\"Space occupied: {model.num_parameter_bytes} bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f247b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = model_name\n",
    "\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "    print(f'Directory {directory} created successfully!')\n",
    "else:\n",
    "    print(f'Directory {directory} already exists.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3530c9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 5e-2 #1e-3 stops after 20 iterations and actually does not reduce the error too much\n",
    "optimizer = Adam(params=model.parameters(), lr=learning_rate)\n",
    "num_epochs = 2000\n",
    "patience = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc2a40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['meanreciprocalrank', HitsAtK(1),\n",
    "                 HitsAtK(3), HitsAtK(5), HitsAtK(10)]\n",
    "\n",
    "train_evaluator = RankBasedEvaluator(\n",
    "        metrics=metrics,\n",
    "        add_defaults=False,\n",
    "    )\n",
    "valid_evaluator = RankBasedEvaluator(\n",
    "        metrics=metrics,\n",
    "        add_defaults=False,\n",
    "    )\n",
    "test_evaluator = RankBasedEvaluator(\n",
    "        metrics = metrics,\n",
    "        add_defaults=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7cd0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykeen.stoppers import EarlyStopper\n",
    "\n",
    "stopper = EarlyStopper(\n",
    "    model = model,\n",
    "    metric='meanreciprocalrank',\n",
    "    patience=patience,\n",
    "    frequency=1,\n",
    "    evaluator = valid_evaluator,\n",
    "    training_triples_factory = dataset.training,\n",
    "    evaluation_triples_factory = dataset.validation,\n",
    "    result_tracker = tracker\n",
    "\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4971a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default training regime is negative sampling (SLCWA)\n",
    "# you can also use the 1-N regime with the LCWATrainingLoop\n",
    "# the LCWA loop does not need negative sampling kwargs, but accepts label_smoothing in the .train() method\n",
    "training_loop = SLCWATrainingLoop(\n",
    "        triples_factory=dataset.training,\n",
    "        model=model,\n",
    "        result_tracker=tracker,\n",
    "        optimizer=optimizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf15a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_start = time.time()\n",
    "train_epoch =  training_loop.train(\n",
    "        triples_factory=dataset.training,\n",
    "        num_epochs=num_epochs,\n",
    "        stopper = stopper,\n",
    "        sampler=\"schlichtkrull\",\n",
    "        num_workers = 32\n",
    "    )\n",
    "training_duration = time.time() - training_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494b8a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,f\"{model_name}/model.pth\")\n",
    "model = torch.load(f\"{model_name}/model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f77bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train error per epoch:\")\n",
    "df = pd.DataFrame(train_epoch)\n",
    "print(df)\n",
    "df.to_csv(f\"{model_name}/{model_name}_train_error_per_epoch.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4aabaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_evaluation_start = time.time()\n",
    "# train\n",
    "print(\"Train error\")\n",
    "show_metrics(train_evaluator.evaluate(\n",
    "        model=model,\n",
    "        mapped_triples=dataset.training.mapped_triples,\n",
    "        additional_filter_triples=[\n",
    "        dataset.training.mapped_triples,\n",
    "    ]\n",
    "    ).to_dict(),model_name,'train_metrics')\n",
    "training_evaluation_duration = time.time() - training_evaluation_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c7e30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_evaluation_start = time.time()\n",
    "# validation\n",
    "print(\"Validation error\")\n",
    "show_metrics(valid_evaluator.evaluate(\n",
    "        model=model,\n",
    "        mapped_triples=dataset.validation.mapped_triples,\n",
    "        additional_filter_triples=[\n",
    "            # filtering of other positive triples\n",
    "            dataset.training.mapped_triples\n",
    "        ],\n",
    "    ).to_dict(),model_name,'validation_metrics')\n",
    "validation_evaluation_duration = time.time() - validation_evaluation_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98aaf677",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_evaluation_start = time.time()\n",
    "# result on the test set\n",
    "print(\"Test error\")\n",
    "show_metrics(test_evaluator.evaluate(\n",
    "        model=model,\n",
    "        mapped_triples=dataset.testing.mapped_triples,\n",
    "        additional_filter_triples=[\n",
    "            # filtering of other positive triples\n",
    "            dataset.training.mapped_triples,\n",
    "            dataset.validation.mapped_triples,\n",
    "        ],\n",
    "    ).to_dict(),model_name,'test_metrics')\n",
    "testing_evaluation_duration = time.time() - testing_evaluation_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb170ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "infodict = {}\n",
    "infodict['device'] = model.device\n",
    "infodict['parameters bytes'] = model.num_parameter_bytes\n",
    "infodict['number parameters'] = model.num_parameters\n",
    "infodict['training duration'] = training_duration\n",
    "infodict['training evaluation duration'] = training_evaluation_duration\n",
    "infodict['validation evaluation duration'] = validation_evaluation_duration\n",
    "infodict['testing evaluation duration'] = testing_evaluation_duration\n",
    "infodict[\"Operating system name\"] = platform.system()\n",
    "infodict[\"Operating system version\"] = platform.release()\n",
    "infodict[\"Processor architecture\"] = platform.machine()\n",
    "infodict[\"Python version\"] = sys.version\n",
    "infodict[\"Processor model name\"] = cpuinfo.get_cpu_info()['brand_raw']\n",
    "infodict['Number cpu cores'] = os.cpu_count()\n",
    "infodict[\"Total physical memory\"] = psutil.virtual_memory().total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc302cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output = subprocess.check_output(['nvidia-smi', '--query-gpu=name', '--format=csv'])\n",
    "output = output.decode('utf-8')  # convert byte string to regular string\n",
    "\n",
    "# split output into rows and remove header row\n",
    "rows = output.strip().split('\\n')[1:]\n",
    "\n",
    "# extract GPU names from each row\n",
    "gpu_names = []\n",
    "for row in rows:\n",
    "    name = row.strip()\n",
    "    gpu_names.append(name)\n",
    "\n",
    "infodict['GPU'] = gpu_names[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7079e496",
   "metadata": {},
   "outputs": [],
   "source": [
    "infodict['loss'] = NSSALoss\n",
    "infodict['embedding_dim'] = embedding_dim\n",
    "infodict['learning_rate'] = learning_rate\n",
    "infodict['optimizer'] = Adam\n",
    "infodict['num_epochs'] = num_epochs\n",
    "infodict['patience'] = patience\n",
    "infodict['sampler']=\"schlichtkrull\"\n",
    "infodict['num_workers']=32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a75c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "info_df = pd.DataFrame(columns=['name','value'], data = infodict.items())\n",
    "info_df.to_csv(f\"{model_name}/{model_name}_information.csv\")\n",
    "print(info_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28602afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zip_folder(folder_path, output_path):\n",
    "    with zipfile.ZipFile(output_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "        for root, dirs, files in os.walk(folder_path):\n",
    "            for file in files:\n",
    "                zipf.write(os.path.join(root, file))\n",
    "\n",
    "folder_path = model_name\n",
    "output_path = f'{model_name}.zip'\n",
    "\n",
    "zip_folder(folder_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ad8fdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
