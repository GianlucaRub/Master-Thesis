{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d30eabec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykeen.pipeline import pipeline\n",
    "from pykeen.datasets import Nations, get_dataset\n",
    "import torch\n",
    "from pykeen.evaluation import evaluate, RankBasedEvaluator\n",
    "from pykeen.metrics.ranking import HitsAtK\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "import click\n",
    "import more_click\n",
    "import torch\n",
    "from pykeen.evaluation import RankBasedEvaluator\n",
    "from pykeen.losses import NSSALoss,CrossEntropyLoss\n",
    "from pykeen.models.inductive import InductiveNodePiece, InductiveNodePieceGNN\n",
    "from pykeen.trackers import ConsoleResultTracker, WANDBResultTracker, FileResultTracker\n",
    "from pykeen.training import SLCWATrainingLoop\n",
    "from pykeen.typing import TESTING, TRAINING, VALIDATION\n",
    "from pykeen.utils import resolve_device, set_random_seed\n",
    "from torch.optim import Adam\n",
    "\n",
    "\n",
    "from pykeen.metrics.ranking import HitsAtK\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from pykeen.datasets.inductive.base import DisjointInductivePathDataset\n",
    "from pykeen.datasets.base import PathDataset, Dataset\n",
    "from typing_extensions import Literal\n",
    "import os\n",
    "from pykeen.hpo import hpo_pipeline\n",
    "from pykeen.triples import TriplesFactory\n",
    "from pykeen.models import InductiveNodePiece, TransE\n",
    "from pykeen.typing import TESTING, TRAINING, VALIDATION\n",
    "\n",
    "import time\n",
    "\n",
    "import platform\n",
    "\n",
    "import sys\n",
    "\n",
    "import cpuinfo\n",
    "\n",
    "import psutil\n",
    "\n",
    "import subprocess\n",
    "\n",
    "import zipfile\n",
    "\n",
    "seed = 1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fba970fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_metrics(dictionary,model_name,csv_name):\n",
    "    for key in dictionary.keys():\n",
    "        print(key)\n",
    "        df = pd.DataFrame(dictionary[key])\n",
    "        df.to_csv(f\"{model_name}/{model_name}_{csv_name}_{key}.csv\")\n",
    "        print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02c3ca5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TYPE = \"_transductive.tsv\"\n",
    "TRAIN_PATH = \"MSCallGraph_train\" + DATA_TYPE\n",
    "TEST_PATH = \"MSCallGraph_test\" + DATA_TYPE\n",
    "VALIDATE_PATH = \"MSCallGraph_validation\" + DATA_TYPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29c36f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PathDataset(training_path = TRAIN_PATH,\n",
    "                     testing_path = TEST_PATH,\n",
    "                     validation_path = VALIDATE_PATH,\n",
    "                      eager = True\n",
    "                     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b863c567",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'transE_transductive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78e64fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker = ConsoleResultTracker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "141b31a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = NSSALoss() #used by RotatE and NodePiece\n",
    "embedding_dim = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eee10f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No cuda devices were available. The model runs on CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 3332600\n",
      "Space occupied: 13330400 bytes\n"
     ]
    }
   ],
   "source": [
    "model = TransE(\n",
    "        triples_factory=dataset.training,\n",
    "        random_seed = seed,\n",
    "        loss = loss,\n",
    "        embedding_dim = embedding_dim\n",
    "    ).to(resolve_device())\n",
    "print(f\"Number of parameters: {sum(p.numel() for p in model.parameters())}\")\n",
    "print(f\"Space occupied: {model.num_parameter_bytes} bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61f247b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory transE_transductive created successfully!\n"
     ]
    }
   ],
   "source": [
    "directory = model_name\n",
    "\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "    print(f'Directory {directory} created successfully!')\n",
    "else:\n",
    "    print(f'Directory {directory} already exists.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3530c9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "optimizer = Adam(params=model.parameters(), lr=learning_rate)\n",
    "num_epochs = 1\n",
    "patience = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fc2a40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['meanreciprocalrank', HitsAtK(1),\n",
    "                 HitsAtK(3), HitsAtK(5), HitsAtK(10)]\n",
    "\n",
    "train_evaluator = RankBasedEvaluator(\n",
    "        metrics=metrics,\n",
    "        add_defaults=False,\n",
    "    )\n",
    "valid_evaluator = RankBasedEvaluator(\n",
    "        metrics=metrics,\n",
    "        add_defaults=False,\n",
    "    )\n",
    "test_evaluator = RankBasedEvaluator(\n",
    "        metrics = metrics,\n",
    "        add_defaults=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf7cd0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykeen.stoppers import EarlyStopper\n",
    "\n",
    "stopper = EarlyStopper(\n",
    "    model = model,\n",
    "    metric='meanreciprocalrank',\n",
    "    patience=patience,\n",
    "    frequency=1,\n",
    "    evaluator = valid_evaluator,\n",
    "    training_triples_factory = dataset.training,\n",
    "    evaluation_triples_factory = dataset.validation,\n",
    "    result_tracker = tracker\n",
    "\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae4971a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default training regime is negative sampling (SLCWA)\n",
    "# you can also use the 1-N regime with the LCWATrainingLoop\n",
    "# the LCWA loop does not need negative sampling kwargs, but accepts label_smoothing in the .train() method\n",
    "training_loop = SLCWATrainingLoop(\n",
    "        triples_factory=dataset.training,\n",
    "        model=model,\n",
    "        result_tracker=tracker,\n",
    "        optimizer=optimizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fdf15a48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f2ff8611d644030a6318cfed8b78342",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epochs on cpu:   0%|          | 0/1 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches on cpu:   0%|          | 0/139 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "904dc1bfeef849b68d5aa99b23d6dcb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating on cpu:   0%|          | 0.00/8.80k [00:00<?, ?triple/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1\n",
      "Metric: validation.head.optimistic.inverse_harmonic_mean_rank = 0.011895816049562536\n",
      "Metric: validation.tail.optimistic.inverse_harmonic_mean_rank = 0.012952582483340972\n",
      "Metric: validation.both.optimistic.inverse_harmonic_mean_rank = 0.012424199266451753\n",
      "Metric: validation.head.realistic.inverse_harmonic_mean_rank = 0.011895811185240746\n",
      "Metric: validation.tail.realistic.inverse_harmonic_mean_rank = 0.012952581979334354\n",
      "Metric: validation.both.realistic.inverse_harmonic_mean_rank = 0.012424196116626263\n",
      "Metric: validation.head.pessimistic.inverse_harmonic_mean_rank = 0.011895806435073139\n",
      "Metric: validation.tail.pessimistic.inverse_harmonic_mean_rank = 0.012952581985077006\n",
      "Metric: validation.both.pessimistic.inverse_harmonic_mean_rank = 0.012424194210075073\n",
      "Metric: validation.head.optimistic.hits_at_1 = 0.010907851380524941\n",
      "Metric: validation.tail.optimistic.hits_at_1 = 0.010907851380524941\n",
      "Metric: validation.both.optimistic.hits_at_1 = 0.010907851380524941\n",
      "Metric: validation.head.realistic.hits_at_1 = 0.010907851380524941\n",
      "Metric: validation.tail.realistic.hits_at_1 = 0.010907851380524941\n",
      "Metric: validation.both.realistic.hits_at_1 = 0.010907851380524941\n",
      "Metric: validation.head.pessimistic.hits_at_1 = 0.010907851380524941\n",
      "Metric: validation.tail.pessimistic.hits_at_1 = 0.010907851380524941\n",
      "Metric: validation.both.pessimistic.hits_at_1 = 0.010907851380524941\n",
      "Metric: validation.head.optimistic.hits_at_3 = 0.011248721736166345\n",
      "Metric: validation.tail.optimistic.hits_at_3 = 0.011816838995568686\n",
      "Metric: validation.both.optimistic.hits_at_3 = 0.011532780365867515\n",
      "Metric: validation.head.realistic.hits_at_3 = 0.011248721736166345\n",
      "Metric: validation.tail.realistic.hits_at_3 = 0.011816838995568686\n",
      "Metric: validation.both.realistic.hits_at_3 = 0.011532780365867515\n",
      "Metric: validation.head.pessimistic.hits_at_3 = 0.011248721736166345\n",
      "Metric: validation.tail.pessimistic.hits_at_3 = 0.011816838995568686\n",
      "Metric: validation.both.pessimistic.hits_at_3 = 0.011532780365867515\n",
      "Metric: validation.head.optimistic.hits_at_5 = 0.01158959209180775\n",
      "Metric: validation.tail.optimistic.hits_at_5 = 0.012953073514373368\n",
      "Metric: validation.both.optimistic.hits_at_5 = 0.012271332803090559\n",
      "Metric: validation.head.realistic.hits_at_5 = 0.01158959209180775\n",
      "Metric: validation.tail.realistic.hits_at_5 = 0.012953073514373368\n",
      "Metric: validation.both.realistic.hits_at_5 = 0.012271332803090559\n",
      "Metric: validation.head.pessimistic.hits_at_5 = 0.01158959209180775\n",
      "Metric: validation.tail.pessimistic.hits_at_5 = 0.012953073514373368\n",
      "Metric: validation.both.pessimistic.hits_at_5 = 0.012271332803090559\n",
      "Metric: validation.head.optimistic.hits_at_10 = 0.012498579706851495\n",
      "Metric: validation.tail.optimistic.hits_at_10 = 0.015111919100102261\n",
      "Metric: validation.both.optimistic.hits_at_10 = 0.013805249403476877\n",
      "Metric: validation.head.realistic.hits_at_10 = 0.012498579706851495\n",
      "Metric: validation.tail.realistic.hits_at_10 = 0.015111919100102261\n",
      "Metric: validation.both.realistic.hits_at_10 = 0.013805249403476877\n",
      "Metric: validation.head.pessimistic.hits_at_10 = 0.012498579706851495\n",
      "Metric: validation.tail.pessimistic.hits_at_10 = 0.015111919100102261\n",
      "Metric: validation.both.pessimistic.hits_at_10 = 0.013805249403476877\n",
      "Step: 1\n",
      "Metric: loss = 3.967333246478074\n",
      "Step: 1\n",
      "Metric: validation.head.optimistic.inverse_harmonic_mean_rank = 0.011895816049562536\n",
      "Metric: validation.tail.optimistic.inverse_harmonic_mean_rank = 0.012952582483340972\n",
      "Metric: validation.both.optimistic.inverse_harmonic_mean_rank = 0.012424199266451753\n",
      "Metric: validation.head.realistic.inverse_harmonic_mean_rank = 0.011895811185240746\n",
      "Metric: validation.tail.realistic.inverse_harmonic_mean_rank = 0.012952581979334354\n",
      "Metric: validation.both.realistic.inverse_harmonic_mean_rank = 0.012424196116626263\n",
      "Metric: validation.head.pessimistic.inverse_harmonic_mean_rank = 0.011895806435073139\n",
      "Metric: validation.tail.pessimistic.inverse_harmonic_mean_rank = 0.012952581985077006\n",
      "Metric: validation.both.pessimistic.inverse_harmonic_mean_rank = 0.012424194210075073\n",
      "Metric: validation.head.optimistic.hits_at_1 = 0.010907851380524941\n",
      "Metric: validation.tail.optimistic.hits_at_1 = 0.010907851380524941\n",
      "Metric: validation.both.optimistic.hits_at_1 = 0.010907851380524941\n",
      "Metric: validation.head.realistic.hits_at_1 = 0.010907851380524941\n",
      "Metric: validation.tail.realistic.hits_at_1 = 0.010907851380524941\n",
      "Metric: validation.both.realistic.hits_at_1 = 0.010907851380524941\n",
      "Metric: validation.head.pessimistic.hits_at_1 = 0.010907851380524941\n",
      "Metric: validation.tail.pessimistic.hits_at_1 = 0.010907851380524941\n",
      "Metric: validation.both.pessimistic.hits_at_1 = 0.010907851380524941\n",
      "Metric: validation.head.optimistic.hits_at_3 = 0.011248721736166345\n",
      "Metric: validation.tail.optimistic.hits_at_3 = 0.011816838995568686\n",
      "Metric: validation.both.optimistic.hits_at_3 = 0.011532780365867515\n",
      "Metric: validation.head.realistic.hits_at_3 = 0.011248721736166345\n",
      "Metric: validation.tail.realistic.hits_at_3 = 0.011816838995568686\n",
      "Metric: validation.both.realistic.hits_at_3 = 0.011532780365867515\n",
      "Metric: validation.head.pessimistic.hits_at_3 = 0.011248721736166345\n",
      "Metric: validation.tail.pessimistic.hits_at_3 = 0.011816838995568686\n",
      "Metric: validation.both.pessimistic.hits_at_3 = 0.011532780365867515\n",
      "Metric: validation.head.optimistic.hits_at_5 = 0.01158959209180775\n",
      "Metric: validation.tail.optimistic.hits_at_5 = 0.012953073514373368\n",
      "Metric: validation.both.optimistic.hits_at_5 = 0.012271332803090559\n",
      "Metric: validation.head.realistic.hits_at_5 = 0.01158959209180775\n",
      "Metric: validation.tail.realistic.hits_at_5 = 0.012953073514373368\n",
      "Metric: validation.both.realistic.hits_at_5 = 0.012271332803090559\n",
      "Metric: validation.head.pessimistic.hits_at_5 = 0.01158959209180775\n",
      "Metric: validation.tail.pessimistic.hits_at_5 = 0.012953073514373368\n",
      "Metric: validation.both.pessimistic.hits_at_5 = 0.012271332803090559\n",
      "Metric: validation.head.optimistic.hits_at_10 = 0.012498579706851495\n",
      "Metric: validation.tail.optimistic.hits_at_10 = 0.015111919100102261\n",
      "Metric: validation.both.optimistic.hits_at_10 = 0.013805249403476877\n",
      "Metric: validation.head.realistic.hits_at_10 = 0.012498579706851495\n",
      "Metric: validation.tail.realistic.hits_at_10 = 0.015111919100102261\n",
      "Metric: validation.both.realistic.hits_at_10 = 0.013805249403476877\n",
      "Metric: validation.head.pessimistic.hits_at_10 = 0.012498579706851495\n",
      "Metric: validation.tail.pessimistic.hits_at_10 = 0.015111919100102261\n",
      "Metric: validation.both.pessimistic.hits_at_10 = 0.013805249403476877\n"
     ]
    }
   ],
   "source": [
    "training_start = time.time()\n",
    "train_epoch =  training_loop.train(\n",
    "        triples_factory=dataset.training,\n",
    "        num_epochs=num_epochs,\n",
    "        callbacks=\"evaluation\",\n",
    "        callback_kwargs=dict(\n",
    "            evaluator=valid_evaluator,\n",
    "            evaluation_triples=dataset.validation.mapped_triples,\n",
    "            prefix=\"validation\",\n",
    "            frequency=1,\n",
    "            additional_filter_triples=dataset.training.mapped_triples,\n",
    "        ),\n",
    "        stopper = stopper\n",
    "        \n",
    "    )\n",
    "training_duration = time.time() - training_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b19de67",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,f\"{model_name}/model.pth\")\n",
    "model = torch.load(f\"{model_name}/model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98f77bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train error per epoch:\n",
      "          0\n",
      "0  3.967333\n"
     ]
    }
   ],
   "source": [
    "print(\"Train error per epoch:\")\n",
    "df = pd.DataFrame(train_epoch)\n",
    "print(df)\n",
    "df.to_csv(f\"{model_name}/{model_name}_train_error_per_epoch.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a4aabaae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train error\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5f7e95a7eb94ad1b24040278c805447",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating on cpu:   0%|          | 0.00/35.6k [00:00<?, ?triple/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# train\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m show_metrics(\u001b[43mtrain_evaluator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmapped_triples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmapped_triples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43madditional_filter_triples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmapped_triples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto_dict(),model_name,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_metrics\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     11\u001b[0m training_evaluation_duration \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m training_evaluation_start\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\MasterThesis\\lib\\site-packages\\pykeen\\evaluation\\evaluator.py:208\u001b[0m, in \u001b[0;36mEvaluator.evaluate\u001b[1;34m(self, model, mapped_triples, batch_size, slice_size, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m         \u001b[38;5;66;03m# Clear the ranks from the current evaluator\u001b[39;00m\n\u001b[0;32m    206\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinalize()\n\u001b[1;32m--> 208\u001b[0m rv \u001b[38;5;241m=\u001b[39m evaluate(\n\u001b[0;32m    209\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m    210\u001b[0m     mapped_triples\u001b[38;5;241m=\u001b[39mmapped_triples,\n\u001b[0;32m    211\u001b[0m     evaluator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    212\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m    213\u001b[0m     slice_size\u001b[38;5;241m=\u001b[39mslice_size,\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    215\u001b[0m )\n\u001b[0;32m    216\u001b[0m \u001b[38;5;66;03m# Since squeeze is true, we can expect that evaluate returns a MetricResult, but we need to tell MyPy that\u001b[39;00m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cast(MetricResults, rv)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\MasterThesis\\lib\\site-packages\\pykeen\\evaluation\\evaluator.py:682\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(model, mapped_triples, evaluator, only_size_probing, batch_size, slice_size, device, use_tqdm, tqdm_kwargs, restrict_entities_to, restrict_relations_to, do_time_consuming_checks, additional_filter_triples, pre_filtered_triples, targets, mode)\u001b[0m\n\u001b[0;32m    680\u001b[0m relation_filter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    681\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m target \u001b[38;5;129;01min\u001b[39;00m targets:\n\u001b[1;32m--> 682\u001b[0m     relation_filter \u001b[38;5;241m=\u001b[39m \u001b[43m_evaluate_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    683\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    684\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    685\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    686\u001b[0m \u001b[43m        \u001b[49m\u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevaluator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    687\u001b[0m \u001b[43m        \u001b[49m\u001b[43mslice_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mslice_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    688\u001b[0m \u001b[43m        \u001b[49m\u001b[43mall_pos_triples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_pos_triples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    689\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrelation_filter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelation_filter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    690\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrestrict_entities_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrestrict_entities_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    691\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    692\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    694\u001b[0m \u001b[38;5;66;03m# If we only probe sizes we do not need more than one batch\u001b[39;00m\n\u001b[0;32m    695\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m only_size_probing \u001b[38;5;129;01mand\u001b[39;00m evaluated_once:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\MasterThesis\\lib\\site-packages\\pykeen\\evaluation\\evaluator.py:755\u001b[0m, in \u001b[0;36m_evaluate_batch\u001b[1;34m(batch, model, target, evaluator, slice_size, all_pos_triples, relation_filter, restrict_entities_to, mode)\u001b[0m\n\u001b[0;32m    715\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_evaluate_batch\u001b[39m(\n\u001b[0;32m    716\u001b[0m     batch: MappedTriples,\n\u001b[0;32m    717\u001b[0m     model: Model,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    725\u001b[0m     mode: Optional[InductiveMode],\n\u001b[0;32m    726\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mBoolTensor:\n\u001b[0;32m    727\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;124;03m    Evaluate ranking for batch.\u001b[39;00m\n\u001b[0;32m    729\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    753\u001b[0m \u001b[38;5;124;03m        The relation filter, which can be re-used for the same batch.\u001b[39;00m\n\u001b[0;32m    754\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 755\u001b[0m     scores \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhrt_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mslice_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mslice_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    757\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m evaluator\u001b[38;5;241m.\u001b[39mfiltered \u001b[38;5;129;01mor\u001b[39;00m evaluator\u001b[38;5;241m.\u001b[39mrequires_positive_mask:\n\u001b[0;32m    758\u001b[0m         column \u001b[38;5;241m=\u001b[39m TARGET_TO_INDEX[target]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\MasterThesis\\lib\\site-packages\\pykeen\\models\\base.py:475\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, hrt_batch, target, full_batch, ids, **kwargs)\u001b[0m\n\u001b[0;32m    473\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m full_batch:\n\u001b[0;32m    474\u001b[0m         hrt_batch \u001b[38;5;241m=\u001b[39m hrt_batch[:, \u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m3\u001b[39m]\n\u001b[1;32m--> 475\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_h(hrt_batch, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs, heads\u001b[38;5;241m=\u001b[39mids)\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown target=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\MasterThesis\\lib\\site-packages\\pykeen\\models\\base.py:368\u001b[0m, in \u001b[0;36mModel.predict_h\u001b[1;34m(self, rt_batch, **kwargs)\u001b[0m\n\u001b[0;32m    366\u001b[0m     scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscore_h_inverse(rt_batch\u001b[38;5;241m=\u001b[39mrt_batch, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    367\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 368\u001b[0m     scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscore_h(rt_batch, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_with_sigmoid:\n\u001b[0;32m    370\u001b[0m     scores \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(scores)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\MasterThesis\\lib\\site-packages\\pykeen\\models\\nbase.py:493\u001b[0m, in \u001b[0;36mERModel.score_h\u001b[1;34m(self, rt_batch, slice_size, mode, heads)\u001b[0m\n\u001b[0;32m    490\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m heads \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m heads\u001b[38;5;241m.\u001b[39mndimension() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    491\u001b[0m     h \u001b[38;5;241m=\u001b[39m parallel_unsqueeze(h, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    492\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m repeat_if_necessary(\n\u001b[1;32m--> 493\u001b[0m     scores\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minteraction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mslice_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mslice_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mslice_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    494\u001b[0m     representations\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mentity_representations,\n\u001b[0;32m    495\u001b[0m     num\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_entity_len(mode\u001b[38;5;241m=\u001b[39mmode) \u001b[38;5;28;01mif\u001b[39;00m heads \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m heads\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m],\n\u001b[0;32m    496\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\MasterThesis\\lib\\site-packages\\pykeen\\nn\\modules.py:255\u001b[0m, in \u001b[0;36mInteraction.score\u001b[1;34m(self, h, r, t, slice_size, slice_dim)\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;124;03m\"\"\"Compute broadcasted triple scores with optional slicing.\u001b[39;00m\n\u001b[0;32m    234\u001b[0m \n\u001b[0;32m    235\u001b[0m \u001b[38;5;124;03m.. note ::\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;124;03m    The scores.\u001b[39;00m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    254\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m slice_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 255\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(\n\u001b[0;32m    258\u001b[0m     [\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mself\u001b[39m(h\u001b[38;5;241m=\u001b[39mh_batch, r\u001b[38;5;241m=\u001b[39mr_batch, t\u001b[38;5;241m=\u001b[39mt_batch)\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    262\u001b[0m     dim\u001b[38;5;241m=\u001b[39mslice_dim,\n\u001b[0;32m    263\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\MasterThesis\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\MasterThesis\\lib\\site-packages\\pykeen\\nn\\modules.py:402\u001b[0m, in \u001b[0;36mFunctionalInteraction.forward\u001b[1;34m(self, h, r, t)\u001b[0m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    385\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    386\u001b[0m     h: HeadRepresentation,\n\u001b[0;32m    387\u001b[0m     r: RelationRepresentation,\n\u001b[0;32m    388\u001b[0m     t: TailRepresentation,\n\u001b[0;32m    389\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor:\n\u001b[0;32m    390\u001b[0m     \u001b[38;5;124;03m\"\"\"Compute broadcasted triple scores given broadcasted representations for head, relation and tails.\u001b[39;00m\n\u001b[0;32m    391\u001b[0m \n\u001b[0;32m    392\u001b[0m \u001b[38;5;124;03m    :param h: shape: (`*batch_dims`, `*dims`)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    400\u001b[0m \u001b[38;5;124;03m        The scores.\u001b[39;00m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 402\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_for_functional(h\u001b[38;5;241m=\u001b[39mh, r\u001b[38;5;241m=\u001b[39mr, t\u001b[38;5;241m=\u001b[39mt))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\MasterThesis\\lib\\site-packages\\pykeen\\nn\\functional.py:809\u001b[0m, in \u001b[0;36mtranse_interaction\u001b[1;34m(h, r, t, p, power_norm)\u001b[0m\n\u001b[0;32m    786\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtranse_interaction\u001b[39m(\n\u001b[0;32m    787\u001b[0m     h: torch\u001b[38;5;241m.\u001b[39mFloatTensor,\n\u001b[0;32m    788\u001b[0m     r: torch\u001b[38;5;241m.\u001b[39mFloatTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    791\u001b[0m     power_norm: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    792\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor:\n\u001b[0;32m    793\u001b[0m     \u001b[38;5;124;03m\"\"\"Evaluate the TransE interaction function.\u001b[39;00m\n\u001b[0;32m    794\u001b[0m \n\u001b[0;32m    795\u001b[0m \u001b[38;5;124;03m    :param h: shape: (`*batch_dims`, dim)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    807\u001b[0m \u001b[38;5;124;03m        The scores.\u001b[39;00m\n\u001b[0;32m    808\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 809\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnegative_norm_of_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpower_norm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpower_norm\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\MasterThesis\\lib\\site-packages\\pykeen\\utils.py:651\u001b[0m, in \u001b[0;36mnegative_norm_of_sum\u001b[1;34m(p, power_norm, *x)\u001b[0m\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnegative_norm_of_sum\u001b[39m(\n\u001b[0;32m    635\u001b[0m     \u001b[38;5;241m*\u001b[39mx: torch\u001b[38;5;241m.\u001b[39mFloatTensor,\n\u001b[0;32m    636\u001b[0m     p: Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m    637\u001b[0m     power_norm: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    638\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor:\n\u001b[0;32m    639\u001b[0m     \u001b[38;5;124;03m\"\"\"Evaluate negative norm of a sum of vectors on already broadcasted representations.\u001b[39;00m\n\u001b[0;32m    640\u001b[0m \n\u001b[0;32m    641\u001b[0m \u001b[38;5;124;03m    :param x: shape: (batch_size, num_heads, num_relations, num_tails, dim)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    649\u001b[0m \u001b[38;5;124;03m        The scores.\u001b[39;00m\n\u001b[0;32m    650\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 651\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m negative_norm(\u001b[43mtensor_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m, p\u001b[38;5;241m=\u001b[39mp, power_norm\u001b[38;5;241m=\u001b[39mpower_norm)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\MasterThesis\\lib\\site-packages\\pykeen\\utils.py:625\u001b[0m, in \u001b[0;36mtensor_sum\u001b[1;34m(*tensors)\u001b[0m\n\u001b[0;32m    623\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtensor_sum\u001b[39m(\u001b[38;5;241m*\u001b[39mtensors: torch\u001b[38;5;241m.\u001b[39mFloatTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor:\n\u001b[0;32m    624\u001b[0m     \u001b[38;5;124;03m\"\"\"Compute element-wise sum of tensors in broadcastable shape.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 625\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_reorder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training_evaluation_start = time.time()\n",
    "# train\n",
    "print(\"Train error\")\n",
    "show_metrics(train_evaluator.evaluate(\n",
    "        model=model,\n",
    "        mapped_triples=dataset.training.mapped_triples,\n",
    "        additional_filter_triples=[\n",
    "        dataset.training.mapped_triples,\n",
    "    ]\n",
    "    ).to_dict(),model_name,'train_metrics')\n",
    "training_evaluation_duration = time.time() - training_evaluation_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c3c7e30e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation error\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baacebd89cb043df86cd0c530a5bdde6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating on cpu:   0%|          | 0.00/8.80k [00:00<?, ?triple/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head\n",
      "                            optimistic  realistic  pessimistic\n",
      "inverse_harmonic_mean_rank    0.011896   0.011896     0.011896\n",
      "hits_at_1                     0.010908   0.010908     0.010908\n",
      "hits_at_3                     0.011249   0.011249     0.011249\n",
      "hits_at_5                     0.011590   0.011590     0.011590\n",
      "hits_at_10                    0.012499   0.012499     0.012499\n",
      "tail\n",
      "                            optimistic  realistic  pessimistic\n",
      "inverse_harmonic_mean_rank    0.012953   0.012953     0.012953\n",
      "hits_at_1                     0.010908   0.010908     0.010908\n",
      "hits_at_3                     0.011817   0.011817     0.011817\n",
      "hits_at_5                     0.012953   0.012953     0.012953\n",
      "hits_at_10                    0.015112   0.015112     0.015112\n",
      "both\n",
      "                            optimistic  realistic  pessimistic\n",
      "inverse_harmonic_mean_rank    0.012424   0.012424     0.012424\n",
      "hits_at_1                     0.010908   0.010908     0.010908\n",
      "hits_at_3                     0.011533   0.011533     0.011533\n",
      "hits_at_5                     0.012271   0.012271     0.012271\n",
      "hits_at_10                    0.013805   0.013805     0.013805\n"
     ]
    }
   ],
   "source": [
    "validation_evaluation_start = time.time()\n",
    "# validation\n",
    "print(\"Validation error\")\n",
    "show_metrics(valid_evaluator.evaluate(\n",
    "        model=model,\n",
    "        mapped_triples=dataset.validation.mapped_triples,\n",
    "        additional_filter_triples=[\n",
    "            # filtering of other positive triples\n",
    "            dataset.training.mapped_triples\n",
    "        ],\n",
    "    ).to_dict(),model_name,'validation_metrics')\n",
    "validation_evaluation_duration = time.time() - validation_evaluation_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98aaf677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9697d37ff9074472ac74d942b115d697",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating on cpu:   0%|          | 0.00/11.2k [00:00<?, ?triple/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head\n",
      "                            optimistic  realistic  pessimistic\n",
      "inverse_harmonic_mean_rank    0.011825   0.011825     0.011825\n",
      "hits_at_1                     0.010802   0.010802     0.010802\n",
      "hits_at_3                     0.011069   0.011069     0.011069\n",
      "hits_at_5                     0.011427   0.011427     0.011427\n",
      "hits_at_10                    0.012676   0.012676     0.012676\n",
      "tail\n",
      "                            optimistic  realistic  pessimistic\n",
      "inverse_harmonic_mean_rank    0.012670   0.012670     0.012670\n",
      "hits_at_1                     0.010712   0.010712     0.010712\n",
      "hits_at_3                     0.011962   0.011962     0.011962\n",
      "hits_at_5                     0.012587   0.012587     0.012587\n",
      "hits_at_10                    0.014372   0.014372     0.014372\n",
      "both\n",
      "                            optimistic  realistic  pessimistic\n",
      "inverse_harmonic_mean_rank    0.012247   0.012247     0.012247\n",
      "hits_at_1                     0.010757   0.010757     0.010757\n",
      "hits_at_3                     0.011516   0.011516     0.011516\n",
      "hits_at_5                     0.012007   0.012007     0.012007\n",
      "hits_at_10                    0.013524   0.013524     0.013524\n"
     ]
    }
   ],
   "source": [
    "testing_evaluation_start = time.time()\n",
    "# result on the test set\n",
    "print(\"Test error\")\n",
    "show_metrics(test_evaluator.evaluate(\n",
    "        model=model,\n",
    "        mapped_triples=dataset.testing.mapped_triples,\n",
    "        additional_filter_triples=[\n",
    "            # filtering of other positive triples\n",
    "            dataset.training.mapped_triples,\n",
    "            dataset.validation.mapped_triples,\n",
    "        ],\n",
    "    ).to_dict(),model_name,'test_metrics')\n",
    "testing_evaluation_duration = time.time() - testing_evaluation_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dcb170ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "infodict = {}\n",
    "infodict['device'] = model.device\n",
    "infodict['parameters bytes'] = model.num_parameter_bytes\n",
    "infodict['number parameters'] = model.num_parameters\n",
    "infodict['training duration'] = training_duration\n",
    "infodict['training evaluation duration'] = training_evaluation_duration\n",
    "infodict['validation evaluation duration'] = validation_evaluation_duration\n",
    "infodict['testing evaluation duration'] = testing_evaluation_duration\n",
    "infodict[\"Operating system name\"] = platform.system()\n",
    "infodict[\"Operating system version\"] = platform.release()\n",
    "infodict[\"Processor architecture\"] = platform.machine()\n",
    "infodict[\"Python version\"] = sys.version\n",
    "infodict[\"Processor model name\"] = cpuinfo.get_cpu_info()['brand_raw']\n",
    "infodict['Number cpu cores'] = os.cpu_count()\n",
    "infodict[\"Total physical memory\"] = psutil.virtual_memory().total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cc302cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output = subprocess.check_output(['nvidia-smi', '--query-gpu=name', '--format=csv'])\n",
    "output = output.decode('utf-8')  # convert byte string to regular string\n",
    "\n",
    "# split output into rows and remove header row\n",
    "rows = output.strip().split('\\n')[1:]\n",
    "\n",
    "# extract GPU names from each row\n",
    "gpu_names = []\n",
    "for row in rows:\n",
    "    name = row.strip()\n",
    "    gpu_names.append(name)\n",
    "\n",
    "infodict['GPU'] = gpu_names[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7079e496",
   "metadata": {},
   "outputs": [],
   "source": [
    "infodict['loss'] = NSSALoss\n",
    "infodict['embedding_dim'] = embedding_dim\n",
    "infodict['learning_rate'] = learning_rate\n",
    "infodict['optimizer'] = Adam\n",
    "infodict['num_epochs'] = num_epochs\n",
    "infodict['patience'] = patience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "43a75c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              name  \\\n",
      "0                           device   \n",
      "1                 parameters bytes   \n",
      "2                number parameters   \n",
      "3                training duration   \n",
      "4     training evaluation duration   \n",
      "5   validation evaluation duration   \n",
      "6      testing evaluation duration   \n",
      "7            Operating system name   \n",
      "8         Operating system version   \n",
      "9           Processor architecture   \n",
      "10                  Python version   \n",
      "11            Processor model name   \n",
      "12                Number cpu cores   \n",
      "13           Total physical memory   \n",
      "14                            loss   \n",
      "15                   embedding_dim   \n",
      "16                   learning_rate   \n",
      "17                       optimizer   \n",
      "18                      num_epochs   \n",
      "19                        patience   \n",
      "\n",
      "                                                value  \n",
      "0                                                 cpu  \n",
      "1                                            13330400  \n",
      "2                                             3332600  \n",
      "3                                          252.387353  \n",
      "4                                          474.315323  \n",
      "5                                          119.237597  \n",
      "6                                          154.559298  \n",
      "7                                             Windows  \n",
      "8                                                  10  \n",
      "9                                               AMD64  \n",
      "10  3.9.16 (main, Jan 11 2023, 16:16:36) [MSC v.19...  \n",
      "11             AMD Ryzen 7 5700U with Radeon Graphics  \n",
      "12                                                 16  \n",
      "13                                         7851745280  \n",
      "14                   <class 'pykeen.losses.NSSALoss'>  \n",
      "15                                                200  \n",
      "16                                              0.001  \n",
      "17                    <class 'torch.optim.adam.Adam'>  \n",
      "18                                                  1  \n",
      "19                                                  1  \n"
     ]
    }
   ],
   "source": [
    "info_df = pd.DataFrame(columns=['name','value'], data = infodict.items())\n",
    "info_df.to_csv(f\"{model_name}/{model_name}_information.csv\")\n",
    "print(info_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "28602afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zip_folder(folder_path, output_path):\n",
    "    with zipfile.ZipFile(output_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "        for root, dirs, files in os.walk(folder_path):\n",
    "            for file in files:\n",
    "                zipf.write(os.path.join(root, file))\n",
    "\n",
    "folder_path = model_name\n",
    "output_path = f'{model_name}.zip'\n",
    "\n",
    "zip_folder(folder_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ad8fdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
