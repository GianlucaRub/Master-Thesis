{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d56261d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import zipfile\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "940a7e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(trace_id):\n",
    "    train_prop = f'PATH_TRAINING = MSCallGraph_traces/train/{trace_id}_transductive_train.tsv\\nPATH_OUTPUT   = rules\\nSNAPSHOTS_AT = 10\\nWORKER_THREADS = 7'\n",
    "    f = open(\"train_prop.txt\", \"w\")\n",
    "    f.write(train_prop)\n",
    "    f.close()\n",
    "    !java -Xmx1G -cp AnyBURL-23-1.jar de.unima.ki.anyburl.Learn config-learn.properties train_prop.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f55b1b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(trace_id):\n",
    "    predict_prop = f'PATH_TRAINING = MSCallGraph_traces/train/{trace_id}_transductive_train.tsv\\nPATH_VALID    = MSCallGraph_traces/test/{trace_id}_transductive_test.tsv\\nPATH_TEST     = MSCallGraph_traces/test/{trace_id}_transductive_test.tsv\\nPATH_RULES    = rules-10\\nPATH_OUTPUT   = preds-10\\nWORKER_THREADS = 7\\nTOP_K_OUTPUT = 100'\n",
    "    f = open(\"predict_prop.txt\", \"w\")\n",
    "    f.write(predict_prop)\n",
    "    f.close()\n",
    "    !java -Xmx1G -cp AnyBURL-23-1.jar de.unima.ki.anyburl.Apply predict_prop.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca3793b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(trace_id):\n",
    "    eval_prop = f'PATH_TRAINING = MSCallGraph_traces/train/{trace_id}_transductive_train.tsv\\nPATH_VALID    = MSCallGraph_traces/test/{trace_id}_transductive_test.tsv\\nPATH_TEST     = MSCallGraph_traces/test/{trace_id}_transductive_test.tsv\\nPATH_PREDICTIONS = preds-10\\nTOP_K = 100'\n",
    "    f = open(\"eval_prop.txt\", \"w\")\n",
    "    f.write(eval_prop)\n",
    "    f.close()\n",
    "    to_return = !java -Xmx1G -cp AnyBURL-23-1.jar de.unima.ki.anyburl.Eval eval_prop.txt\n",
    "    return to_return[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "daa267e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_metrics(traceid):\n",
    "    train(traceid)\n",
    "    predict(traceid)\n",
    "    return(test(traceid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "116c1dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_on_traces(model_name):\n",
    "    directory = model_name+\"_testing_traces\"\n",
    "\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        print(f'Directory {directory} created successfully!')\n",
    "    else:\n",
    "        print(f'Directory {directory} already exists.')\n",
    "        \n",
    "\n",
    "\n",
    "    # Specifica il percorso della cartella da cui si vogliono ottenere i nomi dei file\n",
    "    folder_path =  \"MSCallGraph_traces/train/\"\n",
    "\n",
    "    files_list = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        # Ottenere il nome del file\n",
    "        file_name = os.path.basename(filename)\n",
    "        files_list.append(file_name)\n",
    "    \n",
    "    files_list = files_list[:10]\n",
    "    metric_names = ['hits_at_1','hits_at_3','hits_at_10','mrr']\n",
    "    all_traces_list = []\n",
    "    # Scansione di ogni file nella cartella\n",
    "    with tqdm(desc=f'{model_name} testing traces', total=len(files_list)) as progress_bar:\n",
    "        for file_name in files_list:\n",
    "            # Stampa il nome del file\n",
    "            all_traces_list.append(test_metrics(file_name[:-23]))\n",
    "            progress_bar.update(1)\n",
    "\n",
    "\n",
    "    mean_trace_df = pd.Dataframe(all_traces_list,columns=metric_names)\n",
    "    mean_trace_df.to_csv(f\"{model_name}_testing_traces/mean_trace_test.csv\")\n",
    "    \n",
    "    display(mean_trace_df)\n",
    "    def zip_folder(folder_path, output_path):\n",
    "        with zipfile.ZipFile(output_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "            for root, dirs, files in os.walk(folder_path):\n",
    "                for file in files:\n",
    "                    zipf.write(os.path.join(root, file))\n",
    "\n",
    "    folder_path = model_name+\"_testing_traces\"\n",
    "    output_path = f'{folder_path}.zip'\n",
    "\n",
    "    zip_folder(folder_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29f1b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory anyburl_testing_traces already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "anyburl testing traces:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* read 141449 triples\n",
      "* indexed 10000 triples\n",
      "* indexed 20000 triples\n",
      "* indexed 40000 triples\n",
      "* indexed 80000 triples\n",
      "* set up index for 18 relations, 40505 head entities, and 40552 tail entities\n",
      "* set up list structure for randomized access searches uring rule learning ...  done\n",
      "* precomputing random starting points for each relation/direction for the beam search ... done.\n",
      "* creating worker thread #0\n",
      "* creating worker thread #1\n",
      "* creating worker thread #2\n",
      "* creating worker thread #3\n",
      "* creating worker thread #4\n",
      "* creating worker thread #5\n",
      "* creating worker thread #6\n",
      "THREAD-3 starts to work with L=3 C=Cyclic \n",
      "THREAD-2 starts to work with L=1 C=Cyclic \n",
      "THREAD-0 starts to work with L=3 C=Cyclic \n",
      "THREAD-4 starts to work with L=1 C=Cyclic \n",
      "THREAD-6 starts to work with L=3 C=Cyclic \n",
      "THREAD-5 starts to work with L=3 C=Cyclic \n",
      "THREAD-1 starts to work with L=0 C=Zero \n",
      " 000020 | 033120  > 99k 000063 |  > 99k\n",
      "\n",
      ">>> CREATING SNAPSHOT 0 after 11 seconds\n",
      "\n",
      ">>> storing rules in file rules-10\n",
      ">>> stored 17722 rules in 860ms\n",
      " 000000 | 014075 000414 000510 | 000529\n",
      " 000000 | 000866 000414 000193 | 000123\n",
      " 000000 | 000042 000194 000193 | 000312\n",
      " 000000 | 000001 000117 000381 | 000291\n",
      " 000000 | 000001 000041 000138 | 000435\n",
      " 000000 | 000001 000041 000127 | 000320\n",
      " 000000 | 000001 000037 000092 | 000180\n",
      "\n",
      ">>> CREATING SNAPSHOT 1 after 51 seconds\n",
      "\n",
      ">>> storing rules in file rules-50\n",
      ">>> stored 36817 rules in 709ms\n",
      " 000000 | 000001 000025 000118 | 000262\n",
      " 000000 | 000001 000025 000083 | 000181\n",
      " 000000 | 000001 000017 000069 | 000113\n",
      " 000000 | 000001 000017 000046 | 000102\n",
      " 000000 | 000001 000008 000043 | 000063\n",
      " 000000 | 000001 000008 000019 | 000123\n",
      " 000000 | 000001 000008 000033 | 000118\n",
      " 000000 | 000001 000003 000043 | 000118\n",
      " 000000 | 000001 000003 000037 | 000109\n",
      "\n",
      ">>> CREATING SNAPSHOT 2 after 101 seconds\n",
      "\n",
      ">>> Bye, bye.\n",
      ">>> storing rules in file rules-100\n",
      ">>> stored 43422 rules in 391ms\n",
      ">>> waiting for rule writer thread to finish\n",
      "* reading params from file predict_prop.txt\n",
      "* writing prediction to preds-10\n",
      "* read 111 triples\n",
      "* set up index for 5 relations, 99 head entities, and 41 tail entities\n",
      "* read 24 triples\n",
      "* set up index for 3 relations, 15 head entities, and 12 tail entities\n",
      "* read 24 triples\n",
      "* set up index for 3 relations, 15 head entities, and 12 tail entities\n",
      "* reading rules from rules-10, read 17722 rules\n",
      "* applied confidence threshold of 1.0E-4 and reduced from 17722 to 17722 rules\n",
      "* applying rules\n",
      "* indexed and sorted 17722 rules for using them to make predictions\n",
      "* set up index structure covering rules for prediction for 18 relations\n",
      "* creating worker threads #0 #1 #2 #3 #4 #5 #6 \n",
      "* done with rule application\n",
      "* evaluated 17722 rules to propose candiates for 24*2 completion tasks\n",
      "* finished in 2958ms.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "anyburl testing traces:  10%|â–ˆ         | 1/10 [01:56<17:32, 116.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* read 141449 triples\n",
      "* indexed 10000 triples\n",
      "* indexed 20000 triples\n",
      "* indexed 40000 triples\n",
      "* indexed 80000 triples\n",
      "* set up index for 18 relations, 40505 head entities, and 40552 tail entities\n",
      "* set up list structure for randomized access searches uring rule learning ...  done\n",
      "* precomputing random starting points for each relation/direction for the beam search ... done.\n",
      "* creating worker thread #0\n",
      "* creating worker thread #1\n",
      "* creating worker thread #2\n",
      "* creating worker thread #3\n",
      "* creating worker thread #4\n",
      "* creating worker thread #5\n",
      "* creating worker thread #6\n",
      "THREAD-5 starts to work with L=1 C=Cyclic \n",
      "THREAD-6 starts to work with L=1 C=Cyclic \n",
      "THREAD-4 starts to work with L=1 C=Cyclic \n",
      "THREAD-2 starts to work with L=1 C=Cyclic \n",
      "THREAD-1 starts to work with L=2 C=Cyclic \n",
      "THREAD-0 starts to work with L=3 C=Cyclic \n",
      "THREAD-3 starts to work with L=1 C=Acyclic \n",
      "  > 99k | 021680 000083 000000 | 000045\n",
      "\n",
      ">>> CREATING SNAPSHOT 0 after 11 seconds\n",
      "\n",
      ">>> storing rules in file rules-10\n",
      ">>> stored 22213 rules in 905ms\n",
      " 000004 | 008029 000083 000714 | 000045\n",
      " 000000 | 001780 000083 000393 | 000192\n",
      " 000000 | 000132 000306 000393 | 000192\n",
      " 000000 | 000009 000225 000357 | 000144\n",
      " 000000 | 000009 000066 000221 | 000241\n",
      " 000000 | 000009 000059 000097 | 000311\n",
      " 000000 | 000009 000056 000056 | 000187\n",
      "\n",
      ">>> CREATING SNAPSHOT 1 after 51 seconds\n",
      "\n",
      ">>> storing rules in file rules-50\n",
      ">>> stored 35720 rules in 408ms\n",
      " 000000 | 000005 000056 000056 | 000340\n",
      " 000000 | 000005 000041 000047 | 000122\n",
      " 000000 | 000005 000034 000058 | 000116\n",
      " 000000 | 000005 000030 000092 | 000083\n",
      " 000000 | 000005 000029 000077 | 000109\n",
      " 000000 | 000000 000012 000048 | 000087\n",
      " 000000 | 000000 000012 000096 | 000140\n",
      " 000000 | 000000 000012 000023 | 000061\n",
      "\n",
      ">>> CREATING SNAPSHOT 2 after 101 seconds\n",
      "\n",
      ">>> Bye, bye.\n",
      ">>> storing rules in file rules-100\n",
      ">>> stored 41605 rules in 338ms\n",
      ">>> waiting for rule writer thread to finish\n",
      "* reading params from file predict_prop.txt\n",
      "* writing prediction to preds-10\n",
      "* read 19 triples\n",
      "* set up index for 2 relations, 19 head entities, and 4 tail entities\n",
      "* read 1 triples\n",
      "* set up index for 1 relations, 1 head entities, and 1 tail entities\n",
      "* read 1 triples\n",
      "* set up index for 1 relations, 1 head entities, and 1 tail entities\n",
      "* reading rules from rules-10, read 22213 rules\n",
      "* applied confidence threshold of 1.0E-4 and reduced from 22213 to 22213 rules\n",
      "* applying rules\n",
      "* indexed and sorted 22213 rules for using them to make predictions\n",
      "* set up index structure covering rules for prediction for 18 relations\n",
      "* creating worker threads #0 #1 #2 #3 #4 #5 #6 \n",
      "* done with rule application\n",
      "* evaluated 22213 rules to propose candiates for 1*2 completion tasks\n",
      "* finished in 3349ms.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "anyburl testing traces:  20%|â–ˆâ–ˆ        | 2/10 [03:53<15:34, 116.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* read 141449 triples\n",
      "* indexed 10000 triples\n",
      "* indexed 20000 triples\n",
      "* indexed 40000 triples\n",
      "* indexed 80000 triples\n",
      "* set up index for 18 relations, 40505 head entities, and 40552 tail entities\n",
      "* set up list structure for randomized access searches uring rule learning ...  done\n",
      "* precomputing random starting points for each relation/direction for the beam search ... done.\n",
      "* creating worker thread #0\n",
      "* creating worker thread #1\n",
      "* creating worker thread #2\n",
      "* creating worker thread #3\n",
      "* creating worker thread #4\n",
      "* creating worker thread #5\n",
      "* creating worker thread #6\n",
      "THREAD-4 starts to work with L=0 C=Zero \n",
      "THREAD-3 starts to work with L=1 C=Acyclic \n",
      "THREAD-5 starts to work with L=3 C=Cyclic \n",
      "THREAD-1 starts to work with L=3 C=Cyclic \n",
      "THREAD-6 starts to work with L=1 C=Acyclic \n",
      "THREAD-2 starts to work with L=3 C=Cyclic \n",
      "THREAD-0 starts to work with L=2 C=Cyclic \n",
      " 000020 |  > 99k 000008 000047 | 000038\n",
      "\n",
      ">>> CREATING SNAPSHOT 0 after 11 seconds\n",
      "\n",
      ">>> storing rules in file rules-10\n",
      ">>> stored 15257 rules in 980ms\n",
      " 000000 | 024505 000008 000316 | 000382\n",
      " 000000 | 000754 000214 000316 | 000382\n",
      " 000000 | 000754 000214 000222 | 000297\n",
      " 000000 | 000254 000160 000211 | 000275\n",
      " 000000 | 000038 000160 000164 | 000062\n",
      " 000000 | 000003 000113 000097 | 000260\n",
      " 000000 | 000003 000035 000153 | 000252\n",
      "\n",
      ">>> CREATING SNAPSHOT 1 after 51 seconds\n",
      "\n",
      ">>> storing rules in file rules-50\n",
      ">>> stored 35131 rules in 655ms\n",
      " 000000 | 000003 000035 000127 | 000282\n",
      " 000000 | 000003 000046 000077 | 000173\n",
      " 000000 | 000003 000014 000077 | 000121\n",
      " 000000 | 000003 000014 000037 | 000098\n",
      " 000000 | 000003 000014 000055 | 000100\n",
      " 000000 | 000001 000014 000015 | 000083\n",
      " 000000 | 000001 000014 000056 | 000138\n",
      " 000000 | 000000 000014 000017 | 000101\n",
      " 000000 | 000000 000014 000079 | 000103\n",
      "\n",
      ">>> CREATING SNAPSHOT 2 after 101 seconds\n",
      "\n",
      ">>> Bye, bye.\n",
      ">>> storing rules in file rules-100\n",
      ">>> stored 41759 rules in 359ms\n",
      ">>> waiting for rule writer thread to finish\n",
      "* reading params from file predict_prop.txt\n",
      "* writing prediction to preds-10\n",
      "* read 19 triples\n",
      "* set up index for 3 relations, 17 head entities, and 4 tail entities\n",
      "* read 2 triples\n",
      "* set up index for 2 relations, 2 head entities, and 2 tail entities\n",
      "* read 2 triples\n",
      "* set up index for 2 relations, 2 head entities, and 2 tail entities\n",
      "* reading rules from rules-10, read 15257 rules\n",
      "* applied confidence threshold of 1.0E-4 and reduced from 15257 to 15257 rules\n",
      "* applying rules\n",
      "* indexed and sorted 15257 rules for using them to make predictions\n",
      "* set up index structure covering rules for prediction for 18 relations\n",
      "* creating worker threads #0 #1 #2 #3 #4 #5 #6 \n",
      "* done with rule application\n",
      "* evaluated 15257 rules to propose candiates for 2*2 completion tasks\n",
      "* finished in 2820ms.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "anyburl testing traces:  30%|â–ˆâ–ˆâ–ˆ       | 3/10 [05:51<13:41, 117.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* read 141449 triples\n",
      "* indexed 10000 triples\n",
      "* indexed 20000 triples\n",
      "* indexed 40000 triples\n",
      "* indexed 80000 triples\n",
      "* set up index for 18 relations, 40505 head entities, and 40552 tail entities\n",
      "* set up list structure for randomized access searches uring rule learning ...  done\n",
      "* precomputing random starting points for each relation/direction for the beam search ... done.\n",
      "* creating worker thread #0\n",
      "* creating worker thread #1\n",
      "* creating worker thread #2\n",
      "* creating worker thread #3\n",
      "* creating worker thread #4\n",
      "* creating worker thread #5\n",
      "* creating worker thread #6\n",
      "THREAD-4 starts to work with L=1 C=Acyclic \n",
      "THREAD-6 starts to work with L=3 C=Cyclic \n",
      "THREAD-3 starts to work with L=1 C=Cyclic \n",
      "THREAD-2 starts to work with L=0 C=Zero \n",
      "THREAD-1 starts to work with L=1 C=Acyclic \n",
      "THREAD-0 starts to work with L=1 C=Cyclic \n",
      "THREAD-5 starts to work with L=0 C=Zero \n",
      " 000010 | 035299  > 99k 000146 | 000206\n",
      " 000000 | 008854 000097 000137 | 000094\n",
      "\n",
      ">>> CREATING SNAPSHOT 0 after 11 seconds\n",
      "\n",
      ">>> storing rules in file rules-10\n",
      ">>> stored 23066 rules in 1395ms\n",
      " 000000 | 004429 000097 000161 | 000094\n",
      " 000000 | 000927 000192 000161 | 000597\n",
      " 000000 | 000109 000192 000338 | 000330\n",
      " 000000 | 000027 000293 000060 | 000330\n",
      " 000000 | 000027 000064 000060 | 000279\n",
      " 000000 | 000027 000036 000024 | 000153\n",
      " 000000 | 000010 000033 000024 | 000190\n",
      "\n",
      ">>> CREATING SNAPSHOT 1 after 51 seconds\n",
      "\n",
      ">>> storing rules in file rules-50\n",
      ">>> stored 36007 rules in 825ms\n",
      " 000000 | 000005 000016 000024 | 000169\n",
      " 000000 | 000005 000016 000024 | 000163\n",
      " 000000 | 000005 000033 000165 | 000119\n",
      " 000000 | 000005 000005 000086 | 000140\n",
      " 000000 | 000005 000005 000050 | 000118\n",
      " 000000 | 000001 000005 000042 | 000098\n",
      " 000000 | 000002 000005 000044 | 000122\n",
      " 000000 | 000002 000005 000054 | 000095\n",
      " 000000 | 000000 000019 000054 | 000117\n",
      "\n",
      ">>> CREATING SNAPSHOT 2 after 101 seconds\n",
      "\n",
      ">>> Bye, bye.\n",
      ">>> storing rules in file rules-100\n",
      ">>> stored 43658 rules in 361ms\n",
      ">>> waiting for rule writer thread to finish\n",
      "* reading params from file predict_prop.txt\n",
      "* writing prediction to preds-10\n",
      "* read 31 triples\n",
      "* set up index for 3 relations, 29 head entities, and 11 tail entities\n",
      "* read 1 triples\n",
      "* set up index for 1 relations, 1 head entities, and 1 tail entities\n",
      "* read 1 triples\n",
      "* set up index for 1 relations, 1 head entities, and 1 tail entities\n",
      "* reading rules from rules-10, read 23066 rules\n",
      "* applied confidence threshold of 1.0E-4 and reduced from 23066 to 23066 rules\n",
      "* applying rules\n",
      "* indexed and sorted 23066 rules for using them to make predictions\n",
      "* set up index structure covering rules for prediction for 18 relations\n",
      "* creating worker threads #0 #1 #2 #3 #4 #5 #6 \n",
      "* done with rule application\n",
      "* evaluated 23066 rules to propose candiates for 1*2 completion tasks\n",
      "* finished in 3442ms.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "anyburl testing traces:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [07:47<11:41, 116.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* read 141449 triples\n",
      "* indexed 10000 triples\n",
      "* indexed 20000 triples\n",
      "* indexed 40000 triples\n",
      "* indexed 80000 triples\n",
      "* set up index for 18 relations, 40505 head entities, and 40552 tail entities\n",
      "* set up list structure for randomized access searches uring rule learning ...  done\n",
      "* precomputing random starting points for each relation/direction for the beam search ... done.\n",
      "* creating worker thread #0\n",
      "* creating worker thread #1\n",
      "* creating worker thread #2\n",
      "* creating worker thread #3\n",
      "* creating worker thread #4\n",
      "* creating worker thread #5\n",
      "* creating worker thread #6\n",
      "THREAD-4 starts to work with L=2 C=Cyclic \n",
      "THREAD-5 starts to work with L=1 C=Cyclic \n",
      "THREAD-2 starts to work with L=0 C=Zero \n",
      "THREAD-6 starts to work with L=3 C=Cyclic \n",
      "THREAD-1 starts to work with L=2 C=Cyclic \n",
      "THREAD-0 starts to work with L=0 C=Zero \n",
      "THREAD-3 starts to work with L=1 C=Cyclic \n",
      " 000010 | 035631 000154 000153 |  > 99k\n",
      " 000010 | 006726 000125 000208 | 000165\n",
      "\n",
      ">>> CREATING SNAPSHOT 0 after 11 seconds\n",
      "\n",
      ">>> storing rules in file rules-10\n",
      ">>> stored 26314 rules in 1605ms\n",
      " 000000 | 001728 000208 000208 | 000165\n",
      " 000000 | 000084 000208 000353 | 000095\n",
      " 000000 | 000084 000098 000148 | 000227\n",
      " 000000 | 000084 000098 000073 | 000319\n",
      " 000000 | 000084 000098 000171 | 000188\n",
      " 000000 | 000084 000056 000102 | 000114\n",
      " 000000 | 000084 000046 000089 | 000160\n",
      "\n",
      ">>> CREATING SNAPSHOT 1 after 51 seconds\n",
      "\n",
      ">>> storing rules in file rules-50\n",
      ">>> stored 35924 rules in 442ms\n",
      " 000000 | 000016 000031 000075 | 000171\n",
      " 000000 | 000001 000039 000072 | 000170\n",
      " 000000 | 000001 000030 000107 | 000170\n",
      " 000000 | 000001 000030 000023 | 000136\n",
      " 000000 | 000001 000030 000023 | 000142\n",
      " 000000 | 000000 000030 000025 | 000093\n",
      " 000000 | 000000 000008 000028 | 000108\n",
      " 000000 | 000000 000008 000028 | 000065\n",
      " 000000 | 000000 000013 000030 | 000094\n",
      "\n",
      ">>> CREATING SNAPSHOT 2 after 101 seconds\n",
      "\n",
      ">>> Bye, bye.\n",
      ">>> storing rules in file rules-100\n",
      ">>> stored 42756 rules in 295ms\n",
      ">>> waiting for rule writer thread to finish\n",
      "* reading params from file predict_prop.txt\n",
      "* writing prediction to preds-10\n",
      "* read 28 triples\n",
      "* set up index for 5 relations, 25 head entities, and 11 tail entities\n",
      "* read 6 triples\n",
      "* set up index for 4 relations, 5 head entities, and 5 tail entities\n",
      "* read 6 triples\n",
      "* set up index for 4 relations, 5 head entities, and 5 tail entities\n",
      "* reading rules from rules-10, read 26314 rules\n",
      "* applied confidence threshold of 1.0E-4 and reduced from 26314 to 26314 rules\n",
      "* applying rules\n",
      "* indexed and sorted 26314 rules for using them to make predictions\n",
      "* set up index structure covering rules for prediction for 18 relations\n",
      "* creating worker threads #0 #1 #2 #3 #4 #5 #6 \n",
      "* done with rule application\n",
      "* evaluated 26314 rules to propose candiates for 6*2 completion tasks\n",
      "* finished in 3745ms.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "anyburl testing traces:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [09:43<09:41, 116.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* read 141449 triples\n",
      "* indexed 10000 triples\n",
      "* indexed 20000 triples\n",
      "* indexed 40000 triples\n",
      "* indexed 80000 triples\n",
      "* set up index for 18 relations, 40505 head entities, and 40552 tail entities\n",
      "* set up list structure for randomized access searches uring rule learning ...  done\n",
      "* precomputing random starting points for each relation/direction for the beam search ... done.\n",
      "* creating worker thread #0\n",
      "* creating worker thread #1\n",
      "* creating worker thread #2\n",
      "* creating worker thread #3\n",
      "* creating worker thread #4\n",
      "* creating worker thread #5\n",
      "* creating worker thread #6\n",
      "THREAD-1 starts to work with L=3 C=Cyclic \n",
      "THREAD-2 starts to work with L=3 C=Cyclic \n",
      "THREAD-4 starts to work with L=1 C=Acyclic \n",
      "THREAD-0 starts to work with L=2 C=Cyclic \n",
      "THREAD-5 starts to work with L=3 C=Cyclic \n",
      "THREAD-3 starts to work with L=0 C=Zero \n",
      "THREAD-6 starts to work with L=0 C=Zero \n",
      " 000010 |  > 99k 000150 000074 | 000160\n",
      " 000000 | 024524 000150 000074 | 000074\n",
      "\n",
      ">>> CREATING SNAPSHOT 0 after 11 seconds\n",
      "\n",
      ">>> storing rules in file rules-10\n",
      ">>> stored 28761 rules in 1285ms\n",
      " 000000 | 001136 000150 000010 | 000157\n",
      " 000000 | 000223 000151 000010 | 000178\n",
      " 000000 | 000033 000229 000010 | 000318\n",
      " 000000 | 000033 000050 000738 | 000159\n",
      " 000000 | 000020 000050 000296 | 000248\n",
      " 000000 | 000020 000019 000178 | 000097\n",
      " 000000 | 000020 000019 000073 | 000118\n",
      "\n",
      ">>> CREATING SNAPSHOT 1 after 51 seconds\n",
      "\n",
      ">>> storing rules in file rules-50\n",
      ">>> stored 36167 rules in 564ms\n",
      " 000000 | 000006 000019 000073 | 000133\n",
      " 000000 | 000003 000019 000066 | 000114\n",
      " 000000 | 000003 000020 000066 | 000077\n",
      " 000000 | 000003 000005 000040 | 000062\n",
      " 000000 | 000003 000005 000046 | 000108\n",
      " 000000 | 000003 000005 000058 | 000068\n",
      " 000000 | 000001 000005 000030 | 000062\n",
      " 000000 | 000001 000005 000052 | 000099\n",
      " 000000 | 000001 000005 000052 | 000089\n",
      "\n",
      ">>> CREATING SNAPSHOT 2 after 101 seconds\n",
      "\n",
      ">>> Bye, bye.\n",
      ">>> storing rules in file rules-100\n",
      ">>> stored 41023 rules in 598ms\n",
      ">>> waiting for rule writer thread to finish\n",
      "* reading params from file predict_prop.txt\n",
      "* writing prediction to preds-10\n",
      "* read 125 triples\n",
      "* set up index for 5 relations, 117 head entities, and 43 tail entities\n",
      "* read 27 triples\n",
      "* set up index for 4 relations, 17 head entities, and 15 tail entities\n",
      "* read 27 triples\n",
      "* set up index for 4 relations, 17 head entities, and 15 tail entities\n",
      "* reading rules from rules-10, read 28761 rules\n",
      "* applied confidence threshold of 1.0E-4 and reduced from 28761 to 28761 rules\n",
      "* applying rules\n",
      "* indexed and sorted 28761 rules for using them to make predictions\n",
      "* set up index structure covering rules for prediction for 18 relations\n",
      "* creating worker threads #0 #1 #2 #3 #4 #5 #6 \n",
      "* done with rule application\n",
      "* evaluated 28761 rules to propose candiates for 27*2 completion tasks\n",
      "* finished in 5094ms.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "anyburl testing traces:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [11:44<07:51, 117.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* read 141449 triples\n",
      "* indexed 10000 triples\n",
      "* indexed 20000 triples\n",
      "* indexed 40000 triples\n",
      "* indexed 80000 triples\n",
      "* set up index for 18 relations, 40505 head entities, and 40552 tail entities\n",
      "* set up list structure for randomized access searches uring rule learning ...  done\n",
      "* precomputing random starting points for each relation/direction for the beam search ... done.\n",
      "* creating worker thread #0\n",
      "* creating worker thread #1\n",
      "* creating worker thread #2\n",
      "* creating worker thread #3\n",
      "* creating worker thread #4\n",
      "* creating worker thread #5\n",
      "* creating worker thread #6\n",
      "THREAD-6 starts to work with L=1 C=Acyclic \n",
      "THREAD-4 starts to work with L=3 C=Cyclic \n",
      "THREAD-5 starts to work with L=2 C=Cyclic \n",
      "THREAD-3 starts to work with L=2 C=Cyclic \n",
      "THREAD-1 starts to work with L=0 C=Zero \n",
      "THREAD-2 starts to work with L=0 C=Zero \n",
      "THREAD-0 starts to work with L=1 C=Cyclic \n",
      " 000010 | 049010 000076 000140 | 000017\n",
      " 000010 | 015064 000085 000240 | 000087\n",
      "\n",
      ">>> CREATING SNAPSHOT 0 after 12 seconds\n",
      "\n",
      ">>> storing rules in file rules-10\n",
      ">>> stored 10610 rules in 1131ms\n",
      " 000010 | 005054 000081 000110 | 000087\n",
      " 000010 | 000783 000009 000110 | 000087\n",
      " 000010 | 000057 000140 000110 | 000238\n",
      " 000010 | 000057 000071 000326 | 000171\n",
      " 000010 | 000011 000034 000200 | 000204\n",
      " 000010 | 000011 000114 000191 | 000246\n",
      "\n",
      ">>> CREATING SNAPSHOT 1 after 51 seconds\n",
      "\n",
      ">>> storing rules in file rules-50\n",
      ">>> stored 34830 rules in 1323ms\n",
      " 000000 | 000006 000059 000354 | 000360\n",
      " 000000 | 000006 000028 000050 | 000186\n",
      " 000000 | 000001 000013 000066 | 000089\n",
      " 000000 | 000001 000022 000035 | 000145\n",
      " 000000 | 000001 000022 000040 | 000099\n",
      " 000000 | 000001 000025 000103 | 000176\n",
      " 000000 | 000001 000019 000042 | 000072\n",
      " 000000 | 000001 000019 000053 | 000126\n",
      " 000000 | 000001 000019 000056 | 000110\n",
      "\n",
      ">>> CREATING SNAPSHOT 2 after 101 seconds\n",
      "\n",
      ">>> Bye, bye.\n",
      ">>> storing rules in file rules-100\n",
      ">>> stored 39070 rules in 943ms\n",
      ">>> waiting for rule writer thread to finish\n",
      "* reading params from file predict_prop.txt\n",
      "* writing prediction to preds-10\n",
      "* read 105 triples\n",
      "* set up index for 5 relations, 97 head entities, and 33 tail entities\n",
      "* read 17 triples\n",
      "* set up index for 4 relations, 11 head entities, and 12 tail entities\n",
      "* read 17 triples\n",
      "* set up index for 4 relations, 11 head entities, and 12 tail entities\n",
      "* reading rules from rules-10, read 10610 rules\n",
      "* applied confidence threshold of 1.0E-4 and reduced from 10610 to 10610 rules\n",
      "* applying rules\n",
      "* indexed and sorted 10610 rules for using them to make predictions\n",
      "* set up index structure covering rules for prediction for 18 relations\n",
      "* creating worker threads #0 #1 #2 #3 #4 #5 #6 \n",
      "* done with rule application\n",
      "* evaluated 10610 rules to propose candiates for 17*2 completion tasks\n",
      "* finished in 2614ms.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "anyburl testing traces:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [13:42<05:54, 118.13s/it]"
     ]
    }
   ],
   "source": [
    "test_on_traces(\"anyburl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
