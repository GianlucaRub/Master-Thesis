{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d30eabec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykeen.pipeline import pipeline\n",
    "from pykeen.datasets import Nations, get_dataset\n",
    "import torch\n",
    "from pykeen.evaluation import evaluate, RankBasedEvaluator\n",
    "from pykeen.metrics.ranking import HitsAtK\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "import click\n",
    "import more_click\n",
    "import torch\n",
    "from pykeen.evaluation import RankBasedEvaluator\n",
    "from pykeen.losses import NSSALoss,CrossEntropyLoss\n",
    "from pykeen.models.inductive import InductiveNodePiece, InductiveNodePieceGNN\n",
    "from pykeen.trackers import ConsoleResultTracker, WANDBResultTracker, FileResultTracker\n",
    "from pykeen.training import SLCWATrainingLoop\n",
    "from pykeen.typing import TESTING, TRAINING, VALIDATION\n",
    "from pykeen.utils import resolve_device, set_random_seed\n",
    "from torch.optim import Adam\n",
    "\n",
    "\n",
    "from pykeen.metrics.ranking import HitsAtK\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from pykeen.datasets.inductive.base import DisjointInductivePathDataset\n",
    "from pykeen.datasets.base import PathDataset, Dataset\n",
    "from typing_extensions import Literal\n",
    "import os\n",
    "from pykeen.hpo import hpo_pipeline\n",
    "from pykeen.triples import TriplesFactory\n",
    "from pykeen.models import InductiveNodePiece, TransE, RGCN\n",
    "from pykeen.typing import TESTING, TRAINING, VALIDATION\n",
    "\n",
    "import time\n",
    "\n",
    "import platform\n",
    "\n",
    "import sys\n",
    "\n",
    "import cpuinfo\n",
    "\n",
    "import psutil\n",
    "\n",
    "import subprocess\n",
    "\n",
    "import zipfile\n",
    "\n",
    "seed = 1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fba970fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_metrics(dictionary,model_name,csv_name):\n",
    "    for key in dictionary.keys():\n",
    "        print(key)\n",
    "        df = pd.DataFrame(dictionary[key])\n",
    "        df.to_csv(f\"{model_name}/{model_name}_{csv_name}_{key}.csv\")\n",
    "        print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "612fd4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TYPE = \"_transductive.tsv\"\n",
    "TRAIN_PATH = \"MSCallGraph_train\" + DATA_TYPE\n",
    "TEST_PATH = \"MSCallGraph_test\" + DATA_TYPE\n",
    "VALIDATE_PATH = \"MSCallGraph_validation\" + DATA_TYPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "750b49c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PathDataset(training_path = TRAIN_PATH,\n",
    "                     testing_path = TEST_PATH,\n",
    "                     validation_path = VALIDATE_PATH,\n",
    "                      eager = True\n",
    "                     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b863c567",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'rgcn_transductive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78e64fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker = ConsoleResultTracker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "141b31a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = NSSALoss() #used by RotatE and NodePiece\n",
    "embedding_dim = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eee10f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No cuda devices were available. The model runs on CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 3332600\n",
      "Space occupied: 13330400 bytes\n"
     ]
    }
   ],
   "source": [
    "model = RGCN(\n",
    "        triples_factory=dataset.training,\n",
    "        random_seed = seed,\n",
    "        loss = loss,\n",
    "        embedding_dim = embedding_dim\n",
    "    ).to(resolve_device())\n",
    "print(f\"Number of parameters: {sum(p.numel() for p in model.parameters())}\")\n",
    "print(f\"Space occupied: {model.num_parameter_bytes} bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61f247b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory transE_transductive already exists.\n"
     ]
    }
   ],
   "source": [
    "directory = model_name\n",
    "\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "    print(f'Directory {directory} created successfully!')\n",
    "else:\n",
    "    print(f'Directory {directory} already exists.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3530c9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "optimizer = Adam(params=model.parameters(), lr=learning_rate)\n",
    "num_epochs = 200\n",
    "patience = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8fc2a40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['meanreciprocalrank', HitsAtK(1),\n",
    "                 HitsAtK(3), HitsAtK(5), HitsAtK(10)]\n",
    "\n",
    "train_evaluator = RankBasedEvaluator(\n",
    "        metrics=metrics,\n",
    "        add_defaults=False,\n",
    "    )\n",
    "valid_evaluator = RankBasedEvaluator(\n",
    "        metrics=metrics,\n",
    "        add_defaults=False,\n",
    "    )\n",
    "test_evaluator = RankBasedEvaluator(\n",
    "        metrics = metrics,\n",
    "        add_defaults=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf7cd0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykeen.stoppers import EarlyStopper\n",
    "\n",
    "stopper = EarlyStopper(\n",
    "    model = model,\n",
    "    metric='meanreciprocalrank',\n",
    "    patience=patience,\n",
    "    frequency=1,\n",
    "    evaluator = valid_evaluator,\n",
    "    training_triples_factory = dataset.training,\n",
    "    evaluation_triples_factory = dataset.validation,\n",
    "    result_tracker = tracker\n",
    "\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae4971a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default training regime is negative sampling (SLCWA)\n",
    "# you can also use the 1-N regime with the LCWATrainingLoop\n",
    "# the LCWA loop does not need negative sampling kwargs, but accepts label_smoothing in the .train() method\n",
    "training_loop = SLCWATrainingLoop(\n",
    "        triples_factory=dataset.training,\n",
    "        model=model,\n",
    "        result_tracker=tracker,\n",
    "        optimizer=optimizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fdf15a48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0743f10405124f86a9b6fe1b160d0406",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epochs on cpu:   0%|          | 0/1 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches on cpu:   0%|          | 0/139 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45696a140c6c4aa2996d1449d89013d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating on cpu:   0%|          | 0.00/8.80k [00:00<?, ?triple/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1\n",
      "Metric: validation.head.optimistic.inverse_harmonic_mean_rank = 0.011895816049562536\n",
      "Metric: validation.tail.optimistic.inverse_harmonic_mean_rank = 0.012952582483340972\n",
      "Metric: validation.both.optimistic.inverse_harmonic_mean_rank = 0.012424199266451753\n",
      "Metric: validation.head.realistic.inverse_harmonic_mean_rank = 0.011895811185240746\n",
      "Metric: validation.tail.realistic.inverse_harmonic_mean_rank = 0.012952581979334354\n",
      "Metric: validation.both.realistic.inverse_harmonic_mean_rank = 0.012424196116626263\n",
      "Metric: validation.head.pessimistic.inverse_harmonic_mean_rank = 0.011895806435073139\n",
      "Metric: validation.tail.pessimistic.inverse_harmonic_mean_rank = 0.012952581985077006\n",
      "Metric: validation.both.pessimistic.inverse_harmonic_mean_rank = 0.012424194210075073\n",
      "Metric: validation.head.optimistic.hits_at_1 = 0.010907851380524941\n",
      "Metric: validation.tail.optimistic.hits_at_1 = 0.010907851380524941\n",
      "Metric: validation.both.optimistic.hits_at_1 = 0.010907851380524941\n",
      "Metric: validation.head.realistic.hits_at_1 = 0.010907851380524941\n",
      "Metric: validation.tail.realistic.hits_at_1 = 0.010907851380524941\n",
      "Metric: validation.both.realistic.hits_at_1 = 0.010907851380524941\n",
      "Metric: validation.head.pessimistic.hits_at_1 = 0.010907851380524941\n",
      "Metric: validation.tail.pessimistic.hits_at_1 = 0.010907851380524941\n",
      "Metric: validation.both.pessimistic.hits_at_1 = 0.010907851380524941\n",
      "Metric: validation.head.optimistic.hits_at_3 = 0.011248721736166345\n",
      "Metric: validation.tail.optimistic.hits_at_3 = 0.011816838995568686\n",
      "Metric: validation.both.optimistic.hits_at_3 = 0.011532780365867515\n",
      "Metric: validation.head.realistic.hits_at_3 = 0.011248721736166345\n",
      "Metric: validation.tail.realistic.hits_at_3 = 0.011816838995568686\n",
      "Metric: validation.both.realistic.hits_at_3 = 0.011532780365867515\n",
      "Metric: validation.head.pessimistic.hits_at_3 = 0.011248721736166345\n",
      "Metric: validation.tail.pessimistic.hits_at_3 = 0.011816838995568686\n",
      "Metric: validation.both.pessimistic.hits_at_3 = 0.011532780365867515\n",
      "Metric: validation.head.optimistic.hits_at_5 = 0.01158959209180775\n",
      "Metric: validation.tail.optimistic.hits_at_5 = 0.012953073514373368\n",
      "Metric: validation.both.optimistic.hits_at_5 = 0.012271332803090559\n",
      "Metric: validation.head.realistic.hits_at_5 = 0.01158959209180775\n",
      "Metric: validation.tail.realistic.hits_at_5 = 0.012953073514373368\n",
      "Metric: validation.both.realistic.hits_at_5 = 0.012271332803090559\n",
      "Metric: validation.head.pessimistic.hits_at_5 = 0.01158959209180775\n",
      "Metric: validation.tail.pessimistic.hits_at_5 = 0.012953073514373368\n",
      "Metric: validation.both.pessimistic.hits_at_5 = 0.012271332803090559\n",
      "Metric: validation.head.optimistic.hits_at_10 = 0.012498579706851495\n",
      "Metric: validation.tail.optimistic.hits_at_10 = 0.015111919100102261\n",
      "Metric: validation.both.optimistic.hits_at_10 = 0.013805249403476877\n",
      "Metric: validation.head.realistic.hits_at_10 = 0.012498579706851495\n",
      "Metric: validation.tail.realistic.hits_at_10 = 0.015111919100102261\n",
      "Metric: validation.both.realistic.hits_at_10 = 0.013805249403476877\n",
      "Metric: validation.head.pessimistic.hits_at_10 = 0.012498579706851495\n",
      "Metric: validation.tail.pessimistic.hits_at_10 = 0.015111919100102261\n",
      "Metric: validation.both.pessimistic.hits_at_10 = 0.013805249403476877\n",
      "Step: 1\n",
      "Metric: loss = 3.967333246478074\n",
      "Step: 1\n",
      "Metric: validation.head.optimistic.inverse_harmonic_mean_rank = 0.011895816049562536\n",
      "Metric: validation.tail.optimistic.inverse_harmonic_mean_rank = 0.012952582483340972\n",
      "Metric: validation.both.optimistic.inverse_harmonic_mean_rank = 0.012424199266451753\n",
      "Metric: validation.head.realistic.inverse_harmonic_mean_rank = 0.011895811185240746\n",
      "Metric: validation.tail.realistic.inverse_harmonic_mean_rank = 0.012952581979334354\n",
      "Metric: validation.both.realistic.inverse_harmonic_mean_rank = 0.012424196116626263\n",
      "Metric: validation.head.pessimistic.inverse_harmonic_mean_rank = 0.011895806435073139\n",
      "Metric: validation.tail.pessimistic.inverse_harmonic_mean_rank = 0.012952581985077006\n",
      "Metric: validation.both.pessimistic.inverse_harmonic_mean_rank = 0.012424194210075073\n",
      "Metric: validation.head.optimistic.hits_at_1 = 0.010907851380524941\n",
      "Metric: validation.tail.optimistic.hits_at_1 = 0.010907851380524941\n",
      "Metric: validation.both.optimistic.hits_at_1 = 0.010907851380524941\n",
      "Metric: validation.head.realistic.hits_at_1 = 0.010907851380524941\n",
      "Metric: validation.tail.realistic.hits_at_1 = 0.010907851380524941\n",
      "Metric: validation.both.realistic.hits_at_1 = 0.010907851380524941\n",
      "Metric: validation.head.pessimistic.hits_at_1 = 0.010907851380524941\n",
      "Metric: validation.tail.pessimistic.hits_at_1 = 0.010907851380524941\n",
      "Metric: validation.both.pessimistic.hits_at_1 = 0.010907851380524941\n",
      "Metric: validation.head.optimistic.hits_at_3 = 0.011248721736166345\n",
      "Metric: validation.tail.optimistic.hits_at_3 = 0.011816838995568686\n",
      "Metric: validation.both.optimistic.hits_at_3 = 0.011532780365867515\n",
      "Metric: validation.head.realistic.hits_at_3 = 0.011248721736166345\n",
      "Metric: validation.tail.realistic.hits_at_3 = 0.011816838995568686\n",
      "Metric: validation.both.realistic.hits_at_3 = 0.011532780365867515\n",
      "Metric: validation.head.pessimistic.hits_at_3 = 0.011248721736166345\n",
      "Metric: validation.tail.pessimistic.hits_at_3 = 0.011816838995568686\n",
      "Metric: validation.both.pessimistic.hits_at_3 = 0.011532780365867515\n",
      "Metric: validation.head.optimistic.hits_at_5 = 0.01158959209180775\n",
      "Metric: validation.tail.optimistic.hits_at_5 = 0.012953073514373368\n",
      "Metric: validation.both.optimistic.hits_at_5 = 0.012271332803090559\n",
      "Metric: validation.head.realistic.hits_at_5 = 0.01158959209180775\n",
      "Metric: validation.tail.realistic.hits_at_5 = 0.012953073514373368\n",
      "Metric: validation.both.realistic.hits_at_5 = 0.012271332803090559\n",
      "Metric: validation.head.pessimistic.hits_at_5 = 0.01158959209180775\n",
      "Metric: validation.tail.pessimistic.hits_at_5 = 0.012953073514373368\n",
      "Metric: validation.both.pessimistic.hits_at_5 = 0.012271332803090559\n",
      "Metric: validation.head.optimistic.hits_at_10 = 0.012498579706851495\n",
      "Metric: validation.tail.optimistic.hits_at_10 = 0.015111919100102261\n",
      "Metric: validation.both.optimistic.hits_at_10 = 0.013805249403476877\n",
      "Metric: validation.head.realistic.hits_at_10 = 0.012498579706851495\n",
      "Metric: validation.tail.realistic.hits_at_10 = 0.015111919100102261\n",
      "Metric: validation.both.realistic.hits_at_10 = 0.013805249403476877\n",
      "Metric: validation.head.pessimistic.hits_at_10 = 0.012498579706851495\n",
      "Metric: validation.tail.pessimistic.hits_at_10 = 0.015111919100102261\n",
      "Metric: validation.both.pessimistic.hits_at_10 = 0.013805249403476877\n"
     ]
    }
   ],
   "source": [
    "training_start = time.time()\n",
    "train_epoch =  training_loop.train(\n",
    "        triples_factory=dataset.training,\n",
    "        num_epochs=num_epochs,\n",
    "        callbacks=\"evaluation\",\n",
    "        callback_kwargs=dict(\n",
    "            evaluator=valid_evaluator,\n",
    "            evaluation_triples=dataset.validation.mapped_triples,\n",
    "            prefix=\"validation\",\n",
    "            frequency=1,\n",
    "            additional_filter_triples=dataset.training.mapped_triples,\n",
    "        ),\n",
    "        stopper = stopper\n",
    "        \n",
    "    )\n",
    "training_duration = time.time() - training_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98f77bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train error per epoch:\n",
      "          0\n",
      "0  3.967333\n"
     ]
    }
   ],
   "source": [
    "print(\"Train error per epoch:\")\n",
    "df = pd.DataFrame(train_epoch)\n",
    "print(df)\n",
    "df.to_csv(f\"{model_name}/{model_name}_train_error_per_epoch.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4aabaae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train error\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b50f8f0a0c244709abcae77b0eb4703c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating on cpu:   0%|          | 0.00/35.6k [00:00<?, ?triple/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head\n",
      "                            optimistic  realistic  pessimistic\n",
      "inverse_harmonic_mean_rank    0.022962   0.022962     0.022962\n",
      "hits_at_1                     0.010968   0.010968     0.010968\n",
      "hits_at_3                     0.024016   0.024016     0.024016\n",
      "hits_at_5                     0.030147   0.030147     0.030147\n",
      "hits_at_10                    0.041002   0.041002     0.041002\n",
      "tail\n",
      "                            optimistic  realistic  pessimistic\n",
      "inverse_harmonic_mean_rank    0.032993   0.032993     0.032993\n",
      "hits_at_1                     0.010968   0.010968     0.010968\n",
      "hits_at_3                     0.037684   0.037684     0.037684\n",
      "hits_at_5                     0.049101   0.049101     0.049101\n",
      "hits_at_10                    0.067915   0.067915     0.067915\n",
      "both\n",
      "                            optimistic  realistic  pessimistic\n",
      "inverse_harmonic_mean_rank    0.027978   0.027978     0.027978\n",
      "hits_at_1                     0.010968   0.010968     0.010968\n",
      "hits_at_3                     0.030850   0.030850     0.030850\n",
      "hits_at_5                     0.039624   0.039624     0.039624\n",
      "hits_at_10                    0.054459   0.054459     0.054459\n"
     ]
    }
   ],
   "source": [
    "training_evaluation_start = time.time()\n",
    "# train\n",
    "print(\"Train error\")\n",
    "show_metrics(train_evaluator.evaluate(\n",
    "        model=model,\n",
    "        mapped_triples=dataset.training.mapped_triples,\n",
    "        additional_filter_triples=[\n",
    "        dataset.training.mapped_triples,\n",
    "    ]\n",
    "    ).to_dict(),model_name,'train_metrics')\n",
    "training_evaluation_duration = time.time() - training_evaluation_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c3c7e30e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation error\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baacebd89cb043df86cd0c530a5bdde6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating on cpu:   0%|          | 0.00/8.80k [00:00<?, ?triple/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head\n",
      "                            optimistic  realistic  pessimistic\n",
      "inverse_harmonic_mean_rank    0.011896   0.011896     0.011896\n",
      "hits_at_1                     0.010908   0.010908     0.010908\n",
      "hits_at_3                     0.011249   0.011249     0.011249\n",
      "hits_at_5                     0.011590   0.011590     0.011590\n",
      "hits_at_10                    0.012499   0.012499     0.012499\n",
      "tail\n",
      "                            optimistic  realistic  pessimistic\n",
      "inverse_harmonic_mean_rank    0.012953   0.012953     0.012953\n",
      "hits_at_1                     0.010908   0.010908     0.010908\n",
      "hits_at_3                     0.011817   0.011817     0.011817\n",
      "hits_at_5                     0.012953   0.012953     0.012953\n",
      "hits_at_10                    0.015112   0.015112     0.015112\n",
      "both\n",
      "                            optimistic  realistic  pessimistic\n",
      "inverse_harmonic_mean_rank    0.012424   0.012424     0.012424\n",
      "hits_at_1                     0.010908   0.010908     0.010908\n",
      "hits_at_3                     0.011533   0.011533     0.011533\n",
      "hits_at_5                     0.012271   0.012271     0.012271\n",
      "hits_at_10                    0.013805   0.013805     0.013805\n"
     ]
    }
   ],
   "source": [
    "validation_evaluation_start = time.time()\n",
    "# validation\n",
    "print(\"Validation error\")\n",
    "show_metrics(valid_evaluator.evaluate(\n",
    "        model=model,\n",
    "        mapped_triples=dataset.validation.mapped_triples,\n",
    "        additional_filter_triples=[\n",
    "            # filtering of other positive triples\n",
    "            dataset.training.mapped_triples\n",
    "        ],\n",
    "    ).to_dict(),model_name,'validation_metrics')\n",
    "validation_evaluation_duration = time.time() - validation_evaluation_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98aaf677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9697d37ff9074472ac74d942b115d697",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating on cpu:   0%|          | 0.00/11.2k [00:00<?, ?triple/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head\n",
      "                            optimistic  realistic  pessimistic\n",
      "inverse_harmonic_mean_rank    0.011825   0.011825     0.011825\n",
      "hits_at_1                     0.010802   0.010802     0.010802\n",
      "hits_at_3                     0.011069   0.011069     0.011069\n",
      "hits_at_5                     0.011427   0.011427     0.011427\n",
      "hits_at_10                    0.012676   0.012676     0.012676\n",
      "tail\n",
      "                            optimistic  realistic  pessimistic\n",
      "inverse_harmonic_mean_rank    0.012670   0.012670     0.012670\n",
      "hits_at_1                     0.010712   0.010712     0.010712\n",
      "hits_at_3                     0.011962   0.011962     0.011962\n",
      "hits_at_5                     0.012587   0.012587     0.012587\n",
      "hits_at_10                    0.014372   0.014372     0.014372\n",
      "both\n",
      "                            optimistic  realistic  pessimistic\n",
      "inverse_harmonic_mean_rank    0.012247   0.012247     0.012247\n",
      "hits_at_1                     0.010757   0.010757     0.010757\n",
      "hits_at_3                     0.011516   0.011516     0.011516\n",
      "hits_at_5                     0.012007   0.012007     0.012007\n",
      "hits_at_10                    0.013524   0.013524     0.013524\n"
     ]
    }
   ],
   "source": [
    "testing_evaluation_start = time.time()\n",
    "# result on the test set\n",
    "print(\"Test error\")\n",
    "show_metrics(test_evaluator.evaluate(\n",
    "        model=model,\n",
    "        mapped_triples=dataset.testing.mapped_triples,\n",
    "        additional_filter_triples=[\n",
    "            # filtering of other positive triples\n",
    "            dataset.training.mapped_triples,\n",
    "            dataset.validation.mapped_triples,\n",
    "        ],\n",
    "    ).to_dict(),model_name,'test_metrics')\n",
    "testing_evaluation_duration = time.time() - testing_evaluation_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dcb170ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "infodict = {}\n",
    "infodict['device'] = model.device\n",
    "infodict['parameters bytes'] = model.num_parameter_bytes\n",
    "infodict['number parameters'] = model.num_parameters\n",
    "infodict['training duration'] = training_duration\n",
    "infodict['training evaluation duration'] = training_evaluation_duration\n",
    "infodict['validation evaluation duration'] = validation_evaluation_duration\n",
    "infodict['testing evaluation duration'] = testing_evaluation_duration\n",
    "infodict[\"Operating system name\"] = platform.system()\n",
    "infodict[\"Operating system version\"] = platform.release()\n",
    "infodict[\"Processor architecture\"] = platform.machine()\n",
    "infodict[\"Python version\"] = sys.version\n",
    "infodict[\"Processor model name\"] = cpuinfo.get_cpu_info()['brand_raw']\n",
    "infodict['Number cpu cores'] = os.cpu_count()\n",
    "infodict[\"Total physical memory\"] = psutil.virtual_memory().total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cc302cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output = subprocess.check_output(['nvidia-smi', '--query-gpu=name', '--format=csv'])\n",
    "output = output.decode('utf-8')  # convert byte string to regular string\n",
    "\n",
    "# split output into rows and remove header row\n",
    "rows = output.strip().split('\\n')[1:]\n",
    "\n",
    "# extract GPU names from each row\n",
    "gpu_names = []\n",
    "for row in rows:\n",
    "    name = row.strip()\n",
    "    gpu_names.append(name)\n",
    "\n",
    "infodict['GPU'] = gpu_names[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7079e496",
   "metadata": {},
   "outputs": [],
   "source": [
    "infodict['loss'] = NSSALoss\n",
    "infodict['embedding_dim'] = embedding_dim\n",
    "infodict['learning_rate'] = learning_rate\n",
    "infodict['optimizer'] = Adam\n",
    "infodict['num_epochs'] = num_epochs\n",
    "infodict['patience'] = patience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "43a75c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              name  \\\n",
      "0                           device   \n",
      "1                 parameters bytes   \n",
      "2                number parameters   \n",
      "3                training duration   \n",
      "4     training evaluation duration   \n",
      "5   validation evaluation duration   \n",
      "6      testing evaluation duration   \n",
      "7            Operating system name   \n",
      "8         Operating system version   \n",
      "9           Processor architecture   \n",
      "10                  Python version   \n",
      "11            Processor model name   \n",
      "12                Number cpu cores   \n",
      "13           Total physical memory   \n",
      "14                            loss   \n",
      "15                   embedding_dim   \n",
      "16                   learning_rate   \n",
      "17                       optimizer   \n",
      "18                      num_epochs   \n",
      "19                        patience   \n",
      "\n",
      "                                                value  \n",
      "0                                                 cpu  \n",
      "1                                            13330400  \n",
      "2                                             3332600  \n",
      "3                                          252.387353  \n",
      "4                                          474.315323  \n",
      "5                                          119.237597  \n",
      "6                                          154.559298  \n",
      "7                                             Windows  \n",
      "8                                                  10  \n",
      "9                                               AMD64  \n",
      "10  3.9.16 (main, Jan 11 2023, 16:16:36) [MSC v.19...  \n",
      "11             AMD Ryzen 7 5700U with Radeon Graphics  \n",
      "12                                                 16  \n",
      "13                                         7851745280  \n",
      "14                   <class 'pykeen.losses.NSSALoss'>  \n",
      "15                                                200  \n",
      "16                                              0.001  \n",
      "17                    <class 'torch.optim.adam.Adam'>  \n",
      "18                                                  1  \n",
      "19                                                  1  \n"
     ]
    }
   ],
   "source": [
    "info_df = pd.DataFrame(columns=['name','value'], data = infodict.items())\n",
    "info_df.to_csv(f\"{model_name}/{model_name}_information.csv\")\n",
    "print(info_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "28602afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zip_folder(folder_path, output_path):\n",
    "    with zipfile.ZipFile(output_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "        for root, dirs, files in os.walk(folder_path):\n",
    "            for file in files:\n",
    "                zipf.write(os.path.join(root, file))\n",
    "\n",
    "folder_path = model_name\n",
    "output_path = f'{model_name}.zip'\n",
    "\n",
    "zip_folder(folder_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ad8fdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
