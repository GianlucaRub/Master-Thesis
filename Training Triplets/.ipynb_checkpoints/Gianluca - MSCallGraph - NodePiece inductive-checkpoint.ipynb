{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d30eabec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykeen.pipeline import pipeline\n",
    "from pykeen.datasets import Nations, get_dataset\n",
    "import torch\n",
    "from pykeen.evaluation import evaluate, RankBasedEvaluator\n",
    "from pykeen.metrics.ranking import HitsAtK\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "import click\n",
    "import more_click\n",
    "import torch\n",
    "from pykeen.evaluation import RankBasedEvaluator\n",
    "from pykeen.losses import NSSALoss,CrossEntropyLoss\n",
    "from pykeen.models.inductive import InductiveNodePiece, InductiveNodePieceGNN\n",
    "from pykeen.trackers import ConsoleResultTracker, WANDBResultTracker, FileResultTracker\n",
    "from pykeen.training import SLCWATrainingLoop\n",
    "from pykeen.typing import TESTING, TRAINING, VALIDATION\n",
    "from pykeen.utils import resolve_device, set_random_seed\n",
    "from torch.optim import Adam\n",
    "\n",
    "\n",
    "from pykeen.metrics.ranking import HitsAtK\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from pykeen.datasets.inductive.base import DisjointInductivePathDataset\n",
    "from typing_extensions import Literal\n",
    "import os\n",
    "from pykeen.hpo import hpo_pipeline\n",
    "from pykeen.triples import TriplesFactory\n",
    "from pykeen.models import InductiveNodePiece\n",
    "from pykeen.typing import TESTING, TRAINING, VALIDATION\n",
    "\n",
    "import time\n",
    "\n",
    "import platform\n",
    "\n",
    "import sys\n",
    "\n",
    "import cpuinfo\n",
    "\n",
    "import psutil\n",
    "\n",
    "import subprocess\n",
    "\n",
    "import zipfile\n",
    "\n",
    "seed = 1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59954771",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InductiveLPDataset(DisjointInductivePathDataset):\n",
    "    \"\"\"An inductive link prediction dataset for the ILPC 2022 Challenge.\"\"\"\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    def __init__(self , **kwargs):\n",
    "        \"\"\"Initialize the inductive link prediction dataset.\n",
    "\n",
    "        :param size: \"small\" or \"large\"\n",
    "        :param kwargs: keyword arguments to forward to the base dataset class, cf. DisjointInductivePathDataset\n",
    "        \"\"\"\n",
    "        DATA_TYPE = \"_fully_inductive.tsv\"\n",
    "        TRAIN_PATH = \"MSCallGraph_train\" + DATA_TYPE\n",
    "        TEST_PATH = \"MSCallGraph_test\" + DATA_TYPE\n",
    "        VALIDATE_PATH = \"MSCallGraph_validation\" + DATA_TYPE\n",
    "        INFERENCE_PATH = \"MSCallGraph_inference\" + DATA_TYPE\n",
    "\n",
    "\n",
    "        super().__init__(\n",
    "            transductive_training_path=os.getcwd()+\"/\"+TRAIN_PATH,\n",
    "            inductive_inference_path=os.getcwd()+\"/\"+INFERENCE_PATH,\n",
    "            inductive_validation_path=os.getcwd()+\"/\"+VALIDATE_PATH,\n",
    "            inductive_testing_path=os.getcwd()+\"/\"+TEST_PATH,\n",
    "            create_inverse_triples=True,\n",
    "            eager=True,\n",
    "            **kwargs\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fba970fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_metrics(dictionary,model_name,csv_name):\n",
    "    for key in dictionary.keys():\n",
    "        print(key)\n",
    "        df = pd.DataFrame(dictionary[key])\n",
    "        df.to_csv(f\"{model_name}/{model_name}_{csv_name}_{key}.csv\")\n",
    "        print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "766f31a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = InductiveLPDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1fb4974",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'nodepiece_inductive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18e592da",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker = ConsoleResultTracker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f962f78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = NSSALoss() #used by RotatE and NodePiece\n",
    "num_tokens = 20\n",
    "embedding_dim = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee10f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = InductiveNodePiece(\n",
    "        triples_factory=dataset.transductive_training,\n",
    "        inference_factory=dataset.inductive_inference,\n",
    "        random_seed = seed,\n",
    "        loss = loss,\n",
    "        num_tokens = num_tokens,\n",
    "        embedding_dim = embedding_dim\n",
    "    ).to(resolve_device())\n",
    "print(f\"Number of parameters: {sum(p.numel() for p in model.parameters())}\")\n",
    "print(f\"Space occupied: {model.num_parameter_bytes} bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d870706a",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = model_name\n",
    "\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "    print(f'Directory {directory} created successfully!')\n",
    "else:\n",
    "    print(f'Directory {directory} already exists.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a351c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "optimizer = Adam(params=model.parameters(), lr=learning_rate)\n",
    "num_epochs = 200\n",
    "patience = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc2a40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['meanreciprocalrank', HitsAtK(1),\n",
    "                 HitsAtK(3), HitsAtK(5), HitsAtK(10)]\n",
    "\n",
    "train_evaluator = RankBasedEvaluator(\n",
    "        mode=TRAINING,\n",
    "        metrics=metrics,\n",
    "        add_defaults=False,\n",
    "    )\n",
    "valid_evaluator = RankBasedEvaluator(\n",
    "        mode=VALIDATION,\n",
    "        metrics=metrics,\n",
    "        add_defaults=False,\n",
    "    )\n",
    "test_evaluator = RankBasedEvaluator(\n",
    "        mode=TESTING,\n",
    "        metrics = metrics,\n",
    "        add_defaults=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63796c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykeen.stoppers import EarlyStopper\n",
    "\n",
    "stopper = EarlyStopper(\n",
    "    model = model,\n",
    "    metric='meanreciprocalrank',\n",
    "    patience=patience,\n",
    "    frequency=1,\n",
    "    evaluator = valid_evaluator,\n",
    "    training_triples_factory = dataset.inductive_inference,\n",
    "    evaluation_triples_factory = dataset.inductive_validation,\n",
    "    result_tracker = tracker\n",
    "\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4971a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default training regime is negative sampling (SLCWA)\n",
    "# you can also use the 1-N regime with the LCWATrainingLoop\n",
    "# the LCWA loop does not need negative sampling kwargs, but accepts label_smoothing in the .train() method\n",
    "training_loop = SLCWATrainingLoop(\n",
    "        triples_factory=dataset.transductive_training,\n",
    "        model=model,\n",
    "        mode=TRAINING,  # must be specified for the inductive setup\n",
    "        result_tracker=tracker,\n",
    "        optimizer=optimizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf15a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_start = time.time()\n",
    "train_epoch =  training_loop.train(\n",
    "        triples_factory=dataset.transductive_training,\n",
    "        num_epochs=num_epochs,\n",
    "        callbacks=\"evaluation\",\n",
    "        callback_kwargs=dict(\n",
    "            evaluator=valid_evaluator,\n",
    "            evaluation_triples=dataset.inductive_validation.mapped_triples,\n",
    "            prefix=\"validation\",\n",
    "            frequency=1,\n",
    "            additional_filter_triples=dataset.inductive_inference.mapped_triples,\n",
    "        ),\n",
    "        stopper = stopper\n",
    "        \n",
    "    )\n",
    "training_duration = time.time() - training_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666a7fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train error per epoch:\")\n",
    "df = pd.DataFrame(train_epoch)\n",
    "print(df)\n",
    "df.to_csv(f\"{model_name}/{model_name}_train_error_per_epoch.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4aabaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_evaluation_start = time.time()\n",
    "# train\n",
    "print(\"Train error\")\n",
    "show_metrics(train_evaluator.evaluate(\n",
    "        model=model,\n",
    "        mapped_triples=dataset.transductive_training.mapped_triples,\n",
    "        additional_filter_triples=[\n",
    "        dataset.transductive_training.mapped_triples,\n",
    "    ]\n",
    "    ).to_dict(),model_name,'train_metrics')\n",
    "training_evaluation_duration = time.time() - training_evaluation_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c7e30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_evaluation_start = time.time()\n",
    "# validation\n",
    "print(\"Validation error\")\n",
    "show_metrics(valid_evaluator.evaluate(\n",
    "        model=model,\n",
    "        mapped_triples=dataset.inductive_validation.mapped_triples,\n",
    "        additional_filter_triples=[\n",
    "            # filtering of other positive triples\n",
    "            dataset.inductive_inference.mapped_triples\n",
    "        ],\n",
    "    ).to_dict(),model_name,'validation_metrics')\n",
    "validation_evaluation_duration = time.time() - validation_evaluation_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98aaf677",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_evaluation_start = time.time()\n",
    "# result on the test set\n",
    "print(\"Test error\")\n",
    "show_metrics(test_evaluator.evaluate(\n",
    "        model=model,\n",
    "        mapped_triples=dataset.inductive_testing.mapped_triples,\n",
    "        additional_filter_triples=[\n",
    "            # filtering of other positive triples\n",
    "            dataset.inductive_inference.mapped_triples,\n",
    "            dataset.inductive_validation.mapped_triples,\n",
    "        ],\n",
    "    ).to_dict(),model_name,'test_metrics')\n",
    "testing_evaluation_duration = time.time() - testing_evaluation_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f5caaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "infodict = {}\n",
    "infodict['device'] = model.device\n",
    "infodict['parameters bytes'] = model.num_parameter_bytes\n",
    "infodict['number parameters'] = model.num_parameters\n",
    "infodict['training duration'] = training_duration\n",
    "infodict['training evaluation duration'] = training_evaluation_duration\n",
    "infodict['validation evaluation duration'] = validation_evaluation_duration\n",
    "infodict['testing evaluation duration'] = testing_evaluation_duration\n",
    "infodict[\"Operating system name\"] = platform.system()\n",
    "infodict[\"Operating system version\"] = platform.release()\n",
    "infodict[\"Processor architecture\"] = platform.machine()\n",
    "infodict[\"Python version\"] = sys.version\n",
    "infodict[\"Processor model name\"] = cpuinfo.get_cpu_info()['brand_raw']\n",
    "infodict['Number cpu cores'] = os.cpu_count()\n",
    "infodict[\"Total physical memory\"] = psutil.virtual_memory().total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af24a031",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output = subprocess.check_output(['nvidia-smi', '--query-gpu=name', '--format=csv'])\n",
    "output = output.decode('utf-8')  # convert byte string to regular string\n",
    "\n",
    "# split output into rows and remove header row\n",
    "rows = output.strip().split('\\n')[1:]\n",
    "\n",
    "# extract GPU names from each row\n",
    "gpu_names = []\n",
    "for row in rows:\n",
    "    name = row.strip()\n",
    "    gpu_names.append(name)\n",
    "\n",
    "infodict['GPU'] = gpu_names[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017a54ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "info_df = pd.DataFrame(columns=['name','value'], data = infodict.items())\n",
    "info_df.to_csv(f\"{model_name}/{model_name}_information.csv\")\n",
    "print(info_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4469b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zip_folder(folder_path, output_path):\n",
    "    with zipfile.ZipFile(output_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "        for root, dirs, files in os.walk(folder_path):\n",
    "            for file in files:\n",
    "                zipf.write(os.path.join(root, file))\n",
    "\n",
    "folder_path = model_name\n",
    "output_path = f'{model_name}.zip'\n",
    "\n",
    "zip_folder(folder_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc6dd51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
