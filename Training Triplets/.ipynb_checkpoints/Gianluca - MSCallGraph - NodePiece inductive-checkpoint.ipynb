{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d30eabec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykeen.pipeline import pipeline\n",
    "from pykeen.datasets import Nations, get_dataset\n",
    "import torch\n",
    "from pykeen.evaluation import evaluate, RankBasedEvaluator\n",
    "from pykeen.metrics.ranking import HitsAtK\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "import click\n",
    "import more_click\n",
    "import torch\n",
    "from pykeen.evaluation import RankBasedEvaluator\n",
    "from pykeen.losses import NSSALoss,CrossEntropyLoss\n",
    "from pykeen.models.inductive import InductiveNodePiece, InductiveNodePieceGNN\n",
    "from pykeen.trackers import ConsoleResultTracker, WANDBResultTracker\n",
    "from pykeen.training import SLCWATrainingLoop\n",
    "from pykeen.typing import TESTING, TRAINING, VALIDATION\n",
    "from pykeen.utils import resolve_device, set_random_seed\n",
    "from torch.optim import Adam\n",
    "\n",
    "\n",
    "from pykeen.metrics.ranking import HitsAtK\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from pykeen.datasets.inductive.base import DisjointInductivePathDataset\n",
    "from typing_extensions import Literal\n",
    "import os\n",
    "from pykeen.hpo import hpo_pipeline\n",
    "from pykeen.triples import TriplesFactory\n",
    "from pykeen.models import InductiveNodePiece\n",
    "from pykeen.typing import TESTING, TRAINING, VALIDATION\n",
    "\n",
    "seed = 1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59954771",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InductiveLPDataset(DisjointInductivePathDataset):\n",
    "    \"\"\"An inductive link prediction dataset for the ILPC 2022 Challenge.\"\"\"\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    def __init__(self , **kwargs):\n",
    "        \"\"\"Initialize the inductive link prediction dataset.\n",
    "\n",
    "        :param size: \"small\" or \"large\"\n",
    "        :param kwargs: keyword arguments to forward to the base dataset class, cf. DisjointInductivePathDataset\n",
    "        \"\"\"\n",
    "        DATA_TYPE = \"_fully_inductive.tsv\"\n",
    "        TRAIN_PATH = \"MSCallGraph_train\" + DATA_TYPE\n",
    "        TEST_PATH = \"MSCallGraph_test\" + DATA_TYPE\n",
    "        VALIDATE_PATH = \"MSCallGraph_validation\" + DATA_TYPE\n",
    "        INFERENCE_PATH = \"MSCallGraph_inference\" + DATA_TYPE\n",
    "\n",
    "\n",
    "        super().__init__(\n",
    "            transductive_training_path=os.getcwd()+\"/\"+TRAIN_PATH,\n",
    "            inductive_inference_path=os.getcwd()+\"/\"+INFERENCE_PATH,\n",
    "            inductive_validation_path=os.getcwd()+\"/\"+VALIDATE_PATH,\n",
    "            inductive_testing_path=os.getcwd()+\"/\"+TEST_PATH,\n",
    "            create_inverse_triples=True,\n",
    "            eager=True,\n",
    "            **kwargs\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fba970fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_metrics(dictionary):\n",
    "    for key in dictionary.keys():\n",
    "        print(key)\n",
    "        print(pd.DataFrame(dictionary[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "766f31a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = InductiveLPDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11a9bfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = NSSALoss() #used by RotatE and NodePiece\n",
    "num_tokens = 20\n",
    "embedding_dim = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eee10f05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling:   0%|          | 0.00/9.06k [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No symbolic computation of output shape.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling:   0%|          | 0.00/3.79k [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No symbolic computation of output shape.\n",
      "No cuda devices were available. The model runs on CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 2600\n",
      "Space occupied: 10400 bytes\n"
     ]
    }
   ],
   "source": [
    "model = InductiveNodePiece(\n",
    "        triples_factory=dataset.transductive_training,\n",
    "        inference_factory=dataset.inductive_inference,\n",
    "        random_seed = seed,\n",
    "        loss = loss,\n",
    "        num_tokens = num_tokens,\n",
    "        embedding_dim = embedding_dim\n",
    "    ).to(resolve_device())\n",
    "print(f\"Number of parameters: {sum(p.numel() for p in model.parameters())}\")\n",
    "print(f\"Space occupied: {model.num_parameter_bytes} bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3c360939",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "optimizer = Adam(params=model.parameters(), lr=learning_rate)\n",
    "num_epochs = 200\n",
    "patience = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8fc2a40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['meanreciprocalrank', HitsAtK(1),\n",
    "                 HitsAtK(3), HitsAtK(5), HitsAtK(10)]\n",
    "\n",
    "train_evaluator = RankBasedEvaluator(\n",
    "        mode=TRAINING,\n",
    "        metrics=metrics,\n",
    "        add_defaults=False,\n",
    "    )\n",
    "valid_evaluator = RankBasedEvaluator(\n",
    "        mode=VALIDATION,\n",
    "        metrics=metrics,\n",
    "        add_defaults=False,\n",
    "    )\n",
    "test_evaluator = RankBasedEvaluator(\n",
    "        mode=TESTING,\n",
    "        metrics = metrics,\n",
    "        add_defaults=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b4564b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykeen.stoppers import EarlyStopper\n",
    "\n",
    "stopper = EarlyStopper(\n",
    "    model = model,\n",
    "    metric='meanreciprocalrank',\n",
    "    patience=patience,\n",
    "    frequency=1,\n",
    "    evaluator = valid_evaluator,\n",
    "    training_triples_factory = dataset.inductive_inference,\n",
    "    evaluation_triples_factory = dataset.inductive_validation,\n",
    "\n",
    "\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ae4971a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker = ConsoleResultTracker()\n",
    "# default training regime is negative sampling (SLCWA)\n",
    "# you can also use the 1-N regime with the LCWATrainingLoop\n",
    "# the LCWA loop does not need negative sampling kwargs, but accepts label_smoothing in the .train() method\n",
    "training_loop = SLCWATrainingLoop(\n",
    "        triples_factory=dataset.transductive_training,\n",
    "        model=model,\n",
    "        mode=TRAINING,  # must be specified for the inductive setup\n",
    "        result_tracker=tracker,\n",
    "        optimizer=optimizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fdf15a48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c720c4b19cdc456b8756521d851535b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epochs on cpu:   0%|          | 0/2 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches on cpu:   0%|          | 0/184 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ab02a43ccb242ec99bfdaebc8543ac6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating on cpu:   0%|          | 0.00/3.13k [00:00<?, ?triple/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1\n",
      "Metric: validation.head.optimistic.inverse_harmonic_mean_rank = 0.012965502637459264\n",
      "Metric: validation.tail.optimistic.inverse_harmonic_mean_rank = 0.035064959190099075\n",
      "Metric: validation.both.optimistic.inverse_harmonic_mean_rank = 0.024015230913779165\n",
      "Metric: validation.head.realistic.inverse_harmonic_mean_rank = 0.012211428023874761\n",
      "Metric: validation.tail.realistic.inverse_harmonic_mean_rank = 0.03313044458627701\n",
      "Metric: validation.both.realistic.inverse_harmonic_mean_rank = 0.022670937702059746\n",
      "Metric: validation.head.pessimistic.inverse_harmonic_mean_rank = 0.011738116099519299\n",
      "Metric: validation.tail.pessimistic.inverse_harmonic_mean_rank = 0.03195572596710741\n",
      "Metric: validation.both.pessimistic.inverse_harmonic_mean_rank = 0.021846921033313357\n",
      "Metric: validation.head.optimistic.hits_at_1 = 0.0063959066197633516\n",
      "Metric: validation.tail.optimistic.hits_at_1 = 0.01726894787336105\n",
      "Metric: validation.both.optimistic.hits_at_1 = 0.0118324272465622\n",
      "Metric: validation.head.realistic.hits_at_1 = 0.0063959066197633516\n",
      "Metric: validation.tail.realistic.hits_at_1 = 0.01726894787336105\n",
      "Metric: validation.both.realistic.hits_at_1 = 0.0118324272465622\n",
      "Metric: validation.head.pessimistic.hits_at_1 = 0.0063959066197633516\n",
      "Metric: validation.tail.pessimistic.hits_at_1 = 0.01726894787336105\n",
      "Metric: validation.both.pessimistic.hits_at_1 = 0.0118324272465622\n",
      "Metric: validation.head.optimistic.hits_at_3 = 0.011512631915574032\n",
      "Metric: validation.tail.optimistic.hits_at_3 = 0.028141989126958745\n",
      "Metric: validation.both.optimistic.hits_at_3 = 0.01982731052126639\n",
      "Metric: validation.head.realistic.hits_at_3 = 0.011192836584585865\n",
      "Metric: validation.tail.realistic.hits_at_3 = 0.024624240486088904\n",
      "Metric: validation.both.realistic.hits_at_3 = 0.017908538535337384\n",
      "Metric: validation.head.pessimistic.hits_at_3 = 0.011192836584585865\n",
      "Metric: validation.tail.pessimistic.hits_at_3 = 0.024304445155100735\n",
      "Metric: validation.both.pessimistic.hits_at_3 = 0.0177486408698433\n",
      "Metric: validation.head.optimistic.hits_at_5 = 0.013431403901503039\n",
      "Metric: validation.tail.optimistic.hits_at_5 = 0.03165973776782859\n",
      "Metric: validation.both.optimistic.hits_at_5 = 0.022545570834665813\n",
      "Metric: validation.head.realistic.hits_at_5 = 0.01311160857051487\n",
      "Metric: validation.tail.realistic.hits_at_5 = 0.028781579788935082\n",
      "Metric: validation.both.realistic.hits_at_5 = 0.020946594179724977\n",
      "Metric: validation.head.pessimistic.hits_at_5 = 0.01311160857051487\n",
      "Metric: validation.tail.pessimistic.hits_at_5 = 0.028461784457946913\n",
      "Metric: validation.both.pessimistic.hits_at_5 = 0.02078669651423089\n",
      "Metric: validation.head.optimistic.hits_at_10 = 0.016629357211384713\n",
      "Metric: validation.tail.optimistic.hits_at_10 = 0.0780300607611129\n",
      "Metric: validation.both.optimistic.hits_at_10 = 0.0473297089862488\n",
      "Metric: validation.head.realistic.hits_at_10 = 0.016309561880396548\n",
      "Metric: validation.tail.realistic.hits_at_10 = 0.060121522225775506\n",
      "Metric: validation.both.realistic.hits_at_10 = 0.03821554205308603\n",
      "Metric: validation.head.pessimistic.hits_at_10 = 0.01566997121842021\n",
      "Metric: validation.tail.pessimistic.hits_at_10 = 0.057563159577870164\n",
      "Metric: validation.both.pessimistic.hits_at_10 = 0.03661656539814519\n",
      "Step: 1\n",
      "Metric: loss = 2.7265683033544086\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtraining_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtriples_factory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransductive_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mevaluation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m            \u001b[49m\u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_evaluator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m            \u001b[49m\u001b[43mevaluation_triples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minductive_validation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmapped_triples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalidation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfrequency\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m            \u001b[49m\u001b[43madditional_filter_triples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minductive_inference\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmapped_triples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopper\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstopper\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m        \u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\MasterThesis\\lib\\site-packages\\pykeen\\training\\training_loop.py:378\u001b[0m, in \u001b[0;36mTrainingLoop.train\u001b[1;34m(self, triples_factory, num_epochs, batch_size, slice_size, label_smoothing, sampler, continue_training, only_size_probing, use_tqdm, use_tqdm_batch, tqdm_kwargs, stopper, sub_batch_size, num_workers, clear_optimizer, checkpoint_directory, checkpoint_name, checkpoint_frequency, checkpoint_on_failure, drop_last, callbacks, callback_kwargs, gradient_clipping_max_norm, gradient_clipping_norm_type, gradient_clipping_max_abs_value, pin_memory)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    376\u001b[0m     \u001b[38;5;66;03m# send model to device before going into the internal training loop\u001b[39;00m\n\u001b[0;32m    377\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mto(get_preferred_device(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, allow_ambiguity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[1;32m--> 378\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    379\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43mslice_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mslice_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43msampler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msampler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    384\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontinue_training\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontinue_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    385\u001b[0m \u001b[43m        \u001b[49m\u001b[43monly_size_probing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43monly_size_probing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_tqdm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_tqdm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    387\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_tqdm_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_tqdm_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    388\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtqdm_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtqdm_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    389\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstopper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[43m        \u001b[49m\u001b[43msub_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msub_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    391\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    392\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_checkpoints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_checkpoints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    393\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    394\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_frequency\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheckpoint_frequency\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    395\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_on_failure_file_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheckpoint_on_failure_file_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    396\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbest_epoch_model_file_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbest_epoch_model_file_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    397\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlast_best_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlast_best_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    398\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdrop_last\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_last\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    399\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    400\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    401\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgradient_clipping_max_norm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgradient_clipping_max_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    402\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgradient_clipping_norm_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgradient_clipping_norm_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    403\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgradient_clipping_max_abs_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgradient_clipping_max_abs_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtriples_factory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtriples_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpin_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpin_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    406\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    408\u001b[0m \u001b[38;5;66;03m# Ensure the release of memory\u001b[39;00m\n\u001b[0;32m    409\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\MasterThesis\\lib\\site-packages\\pykeen\\training\\training_loop.py:734\u001b[0m, in \u001b[0;36mTrainingLoop._train\u001b[1;34m(self, triples_factory, num_epochs, batch_size, slice_size, label_smoothing, sampler, continue_training, only_size_probing, use_tqdm, use_tqdm_batch, tqdm_kwargs, stopper, sub_batch_size, num_workers, save_checkpoints, checkpoint_path, checkpoint_frequency, checkpoint_on_failure_file_path, best_epoch_model_file_path, last_best_epoch, drop_last, callbacks, callback_kwargs, gradient_clipping_max_norm, gradient_clipping_norm_type, gradient_clipping_max_abs_value, pin_memory)\u001b[0m\n\u001b[0;32m    731\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    733\u001b[0m \u001b[38;5;66;03m# Includes a call to result_tracker.log_metrics\u001b[39;00m\n\u001b[1;32m--> 734\u001b[0m \u001b[43mcallback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch_loss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch_loss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    736\u001b[0m \u001b[38;5;66;03m# If a checkpoint file is given, we check whether it is time to save a checkpoint\u001b[39;00m\n\u001b[0;32m    737\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m save_checkpoints \u001b[38;5;129;01mand\u001b[39;00m checkpoint_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\MasterThesis\\lib\\site-packages\\pykeen\\training\\callbacks.py:438\u001b[0m, in \u001b[0;36mMultiTrainingCallback.post_epoch\u001b[1;34m(self, epoch, epoch_loss, **kwargs)\u001b[0m\n\u001b[0;32m    436\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost_epoch\u001b[39m(\u001b[38;5;28mself\u001b[39m, epoch: \u001b[38;5;28mint\u001b[39m, epoch_loss: \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# noqa: D102\u001b[39;00m\n\u001b[0;32m    437\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[1;32m--> 438\u001b[0m         callback\u001b[38;5;241m.\u001b[39mpost_epoch(epoch\u001b[38;5;241m=\u001b[39mepoch, epoch_loss\u001b[38;5;241m=\u001b[39mepoch_loss, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\MasterThesis\\lib\\site-packages\\pykeen\\training\\callbacks.py:362\u001b[0m, in \u001b[0;36mStopperTrainingCallback.post_epoch\u001b[1;34m(self, epoch, epoch_loss, **kwargs)\u001b[0m\n\u001b[0;32m    359\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost_epoch\u001b[39m(\u001b[38;5;28mself\u001b[39m, epoch: \u001b[38;5;28mint\u001b[39m, epoch_loss: \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# noqa: D102\u001b[39;00m\n\u001b[0;32m    360\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstopper\u001b[38;5;241m.\u001b[39mshould_evaluate(epoch):\n\u001b[0;32m    361\u001b[0m         \u001b[38;5;66;03m# TODO how to pass inductive mode\u001b[39;00m\n\u001b[1;32m--> 362\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstopper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshould_stop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    363\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_loop\u001b[38;5;241m.\u001b[39m_should_stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    364\u001b[0m         \u001b[38;5;66;03m# Since the model is also used within the stopper, its graph and cache have to be cleared\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\MasterThesis\\lib\\site-packages\\pykeen\\stoppers\\early_stopping.py:230\u001b[0m, in \u001b[0;36mEarlyStopper.should_stop\u001b[1;34m(self, epoch, mode)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_model_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;66;03m# Evaluate\u001b[39;00m\n\u001b[1;32m--> 230\u001b[0m metric_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    231\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[43m    \u001b[49m\u001b[43madditional_filter_triples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_triples_factory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmapped_triples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    233\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapped_triples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluation_triples_factory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmapped_triples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    234\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_tqdm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluation_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[43m    \u001b[49m\u001b[43mslice_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluation_slice_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    237\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Only perform time consuming checks for the first call.\u001b[39;49;00m\n\u001b[0;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdo_time_consuming_checks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluation_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    240\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    241\u001b[0m \u001b[38;5;66;03m# After the first evaluation pass the optimal batch and slice size is obtained and saved for re-use\u001b[39;00m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluator\u001b[38;5;241m.\u001b[39mbatch_size\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\MasterThesis\\lib\\site-packages\\pykeen\\evaluation\\evaluator.py:208\u001b[0m, in \u001b[0;36mEvaluator.evaluate\u001b[1;34m(self, model, mapped_triples, batch_size, slice_size, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m         \u001b[38;5;66;03m# Clear the ranks from the current evaluator\u001b[39;00m\n\u001b[0;32m    206\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinalize()\n\u001b[1;32m--> 208\u001b[0m rv \u001b[38;5;241m=\u001b[39m evaluate(\n\u001b[0;32m    209\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m    210\u001b[0m     mapped_triples\u001b[38;5;241m=\u001b[39mmapped_triples,\n\u001b[0;32m    211\u001b[0m     evaluator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    212\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m    213\u001b[0m     slice_size\u001b[38;5;241m=\u001b[39mslice_size,\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    215\u001b[0m )\n\u001b[0;32m    216\u001b[0m \u001b[38;5;66;03m# Since squeeze is true, we can expect that evaluate returns a MetricResult, but we need to tell MyPy that\u001b[39;00m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cast(MetricResults, rv)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\MasterThesis\\lib\\site-packages\\pykeen\\evaluation\\evaluator.py:682\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(model, mapped_triples, evaluator, only_size_probing, batch_size, slice_size, device, use_tqdm, tqdm_kwargs, restrict_entities_to, restrict_relations_to, do_time_consuming_checks, additional_filter_triples, pre_filtered_triples, targets, mode)\u001b[0m\n\u001b[0;32m    680\u001b[0m relation_filter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    681\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m target \u001b[38;5;129;01min\u001b[39;00m targets:\n\u001b[1;32m--> 682\u001b[0m     relation_filter \u001b[38;5;241m=\u001b[39m \u001b[43m_evaluate_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    683\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    684\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    685\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    686\u001b[0m \u001b[43m        \u001b[49m\u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevaluator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    687\u001b[0m \u001b[43m        \u001b[49m\u001b[43mslice_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mslice_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    688\u001b[0m \u001b[43m        \u001b[49m\u001b[43mall_pos_triples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_pos_triples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    689\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrelation_filter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelation_filter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    690\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrestrict_entities_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrestrict_entities_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    691\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    692\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    694\u001b[0m \u001b[38;5;66;03m# If we only probe sizes we do not need more than one batch\u001b[39;00m\n\u001b[0;32m    695\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m only_size_probing \u001b[38;5;129;01mand\u001b[39;00m evaluated_once:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\MasterThesis\\lib\\site-packages\\pykeen\\evaluation\\evaluator.py:755\u001b[0m, in \u001b[0;36m_evaluate_batch\u001b[1;34m(batch, model, target, evaluator, slice_size, all_pos_triples, relation_filter, restrict_entities_to, mode)\u001b[0m\n\u001b[0;32m    715\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_evaluate_batch\u001b[39m(\n\u001b[0;32m    716\u001b[0m     batch: MappedTriples,\n\u001b[0;32m    717\u001b[0m     model: Model,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    725\u001b[0m     mode: Optional[InductiveMode],\n\u001b[0;32m    726\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mBoolTensor:\n\u001b[0;32m    727\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;124;03m    Evaluate ranking for batch.\u001b[39;00m\n\u001b[0;32m    729\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    753\u001b[0m \u001b[38;5;124;03m        The relation filter, which can be re-used for the same batch.\u001b[39;00m\n\u001b[0;32m    754\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 755\u001b[0m     scores \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhrt_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mslice_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mslice_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    757\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m evaluator\u001b[38;5;241m.\u001b[39mfiltered \u001b[38;5;129;01mor\u001b[39;00m evaluator\u001b[38;5;241m.\u001b[39mrequires_positive_mask:\n\u001b[0;32m    758\u001b[0m         column \u001b[38;5;241m=\u001b[39m TARGET_TO_INDEX[target]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\MasterThesis\\lib\\site-packages\\pykeen\\models\\base.py:465\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, hrt_batch, target, full_batch, ids, **kwargs)\u001b[0m\n\u001b[0;32m    463\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m full_batch:\n\u001b[0;32m    464\u001b[0m         hrt_batch \u001b[38;5;241m=\u001b[39m hrt_batch[:, \u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m--> 465\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_t(hrt_batch, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs, tails\u001b[38;5;241m=\u001b[39mids)\n\u001b[0;32m    467\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target \u001b[38;5;241m==\u001b[39m LABEL_RELATION:\n\u001b[0;32m    468\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m full_batch:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\MasterThesis\\lib\\site-packages\\pykeen\\models\\base.py:403\u001b[0m, in \u001b[0;36mModel.predict_t\u001b[1;34m(self, hr_batch, **kwargs)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval()  \u001b[38;5;66;03m# Enforce evaluation mode\u001b[39;00m\n\u001b[0;32m    402\u001b[0m hr_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_batch(batch\u001b[38;5;241m=\u001b[39mhr_batch, index_relation\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 403\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscore_t(hr_batch, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    404\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_with_sigmoid:\n\u001b[0;32m    405\u001b[0m     scores \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(scores)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\MasterThesis\\lib\\site-packages\\pykeen\\models\\nbase.py:466\u001b[0m, in \u001b[0;36mERModel.score_t\u001b[1;34m(self, hr_batch, slice_size, mode, tails)\u001b[0m\n\u001b[0;32m    464\u001b[0m \u001b[38;5;66;03m# add broadcast dimension\u001b[39;00m\n\u001b[0;32m    465\u001b[0m hr_batch \u001b[38;5;241m=\u001b[39m hr_batch\u001b[38;5;241m.\u001b[39munsqueeze(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 466\u001b[0m h, r, t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_representations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhr_batch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhr_batch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtails\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    467\u001b[0m \u001b[38;5;66;03m# unsqueeze if necessary\u001b[39;00m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tails \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m tails\u001b[38;5;241m.\u001b[39mndimension() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\MasterThesis\\lib\\site-packages\\pykeen\\models\\nbase.py:570\u001b[0m, in \u001b[0;36mERModel._get_representations\u001b[1;34m(self, h, r, t, mode)\u001b[0m\n\u001b[0;32m    568\u001b[0m head_representations \u001b[38;5;241m=\u001b[39m [head_representations[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minteraction\u001b[38;5;241m.\u001b[39mhead_indices()]\n\u001b[0;32m    569\u001b[0m tail_representations \u001b[38;5;241m=\u001b[39m [tail_representations[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minteraction\u001b[38;5;241m.\u001b[39mtail_indices()]\n\u001b[1;32m--> 570\u001b[0m hr, rr, tr \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    571\u001b[0m     [representation(indices\u001b[38;5;241m=\u001b[39mindices) \u001b[38;5;28;01mfor\u001b[39;00m representation \u001b[38;5;129;01min\u001b[39;00m representations]\n\u001b[0;32m    572\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m indices, representations \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[0;32m    573\u001b[0m         (h, head_representations),\n\u001b[0;32m    574\u001b[0m         (r, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelation_representations),\n\u001b[0;32m    575\u001b[0m         (t, tail_representations),\n\u001b[0;32m    576\u001b[0m     )\n\u001b[0;32m    577\u001b[0m ]\n\u001b[0;32m    578\u001b[0m \u001b[38;5;66;03m# normalization\u001b[39;00m\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[0;32m    580\u001b[0m     Tuple[HeadRepresentation, RelationRepresentation, TailRepresentation],\n\u001b[0;32m    581\u001b[0m     \u001b[38;5;28mtuple\u001b[39m(x[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(x) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m (hr, rr, tr)),\n\u001b[0;32m    582\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\MasterThesis\\lib\\site-packages\\pykeen\\models\\nbase.py:571\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    568\u001b[0m head_representations \u001b[38;5;241m=\u001b[39m [head_representations[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minteraction\u001b[38;5;241m.\u001b[39mhead_indices()]\n\u001b[0;32m    569\u001b[0m tail_representations \u001b[38;5;241m=\u001b[39m [tail_representations[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minteraction\u001b[38;5;241m.\u001b[39mtail_indices()]\n\u001b[0;32m    570\u001b[0m hr, rr, tr \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m--> 571\u001b[0m     [representation(indices\u001b[38;5;241m=\u001b[39mindices) \u001b[38;5;28;01mfor\u001b[39;00m representation \u001b[38;5;129;01min\u001b[39;00m representations]\n\u001b[0;32m    572\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m indices, representations \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[0;32m    573\u001b[0m         (h, head_representations),\n\u001b[0;32m    574\u001b[0m         (r, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelation_representations),\n\u001b[0;32m    575\u001b[0m         (t, tail_representations),\n\u001b[0;32m    576\u001b[0m     )\n\u001b[0;32m    577\u001b[0m ]\n\u001b[0;32m    578\u001b[0m \u001b[38;5;66;03m# normalization\u001b[39;00m\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[0;32m    580\u001b[0m     Tuple[HeadRepresentation, RelationRepresentation, TailRepresentation],\n\u001b[0;32m    581\u001b[0m     \u001b[38;5;28mtuple\u001b[39m(x[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(x) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m (hr, rr, tr)),\n\u001b[0;32m    582\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\MasterThesis\\lib\\site-packages\\pykeen\\models\\nbase.py:571\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    568\u001b[0m head_representations \u001b[38;5;241m=\u001b[39m [head_representations[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minteraction\u001b[38;5;241m.\u001b[39mhead_indices()]\n\u001b[0;32m    569\u001b[0m tail_representations \u001b[38;5;241m=\u001b[39m [tail_representations[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minteraction\u001b[38;5;241m.\u001b[39mtail_indices()]\n\u001b[0;32m    570\u001b[0m hr, rr, tr \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m--> 571\u001b[0m     [\u001b[43mrepresentation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m representation \u001b[38;5;129;01min\u001b[39;00m representations]\n\u001b[0;32m    572\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m indices, representations \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[0;32m    573\u001b[0m         (h, head_representations),\n\u001b[0;32m    574\u001b[0m         (r, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelation_representations),\n\u001b[0;32m    575\u001b[0m         (t, tail_representations),\n\u001b[0;32m    576\u001b[0m     )\n\u001b[0;32m    577\u001b[0m ]\n\u001b[0;32m    578\u001b[0m \u001b[38;5;66;03m# normalization\u001b[39;00m\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[0;32m    580\u001b[0m     Tuple[HeadRepresentation, RelationRepresentation, TailRepresentation],\n\u001b[0;32m    581\u001b[0m     \u001b[38;5;28mtuple\u001b[39m(x[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(x) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m (hr, rr, tr)),\n\u001b[0;32m    582\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\MasterThesis\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\MasterThesis\\lib\\site-packages\\pykeen\\nn\\representation.py:179\u001b[0m, in \u001b[0;36mRepresentation.forward\u001b[1;34m(self, indices)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m indices \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munique:\n\u001b[0;32m    178\u001b[0m     indices, inverse \u001b[38;5;241m=\u001b[39m indices\u001b[38;5;241m.\u001b[39munique(return_inverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 179\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plain_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;66;03m# normalize *before* repeating\u001b[39;00m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\MasterThesis\\lib\\site-packages\\pykeen\\nn\\representation.py:1137\u001b[0m, in \u001b[0;36mCombinedRepresentation._plain_forward\u001b[1;34m(self, indices)\u001b[0m\n\u001b[0;32m   1133\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_plain_forward\u001b[39m(\n\u001b[0;32m   1134\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1135\u001b[0m     indices: Optional[torch\u001b[38;5;241m.\u001b[39mLongTensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1136\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor:  \u001b[38;5;66;03m# noqa: D102\u001b[39;00m\n\u001b[1;32m-> 1137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcombine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcombination\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcombination\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\MasterThesis\\lib\\site-packages\\pykeen\\nn\\representation.py:1130\u001b[0m, in \u001b[0;36mCombinedRepresentation.combine\u001b[1;34m(combination, base, indices)\u001b[0m\n\u001b[0;32m   1116\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m   1117\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcombine\u001b[39m(\n\u001b[0;32m   1118\u001b[0m     combination: nn\u001b[38;5;241m.\u001b[39mModule, base: Sequence[Representation], indices: Optional[torch\u001b[38;5;241m.\u001b[39mLongTensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1119\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor:\n\u001b[0;32m   1120\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1121\u001b[0m \u001b[38;5;124;03m    Combine base representations for the given indices.\u001b[39;00m\n\u001b[0;32m   1122\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;124;03m        the combined representations for the given indices\u001b[39;00m\n\u001b[0;32m   1129\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcombination\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plain_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbase\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\MasterThesis\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\MasterThesis\\lib\\site-packages\\pykeen\\nn\\combination.py:153\u001b[0m, in \u001b[0;36mConcatAggregationCombination.forward\u001b[1;34m(self, xs)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, xs: Sequence[torch\u001b[38;5;241m.\u001b[39mFloatTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor:  \u001b[38;5;66;03m# noqa: D102\u001b[39;00m\n\u001b[1;32m--> 153\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maggregation\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "try:\n",
    "    training_loop.train(\n",
    "        triples_factory=dataset.transductive_training,\n",
    "        num_epochs=num_epochs,\n",
    "        callbacks=\"evaluation\",\n",
    "        callback_kwargs=dict(\n",
    "            evaluator=valid_evaluator,\n",
    "            evaluation_triples=dataset.inductive_validation.mapped_triples,\n",
    "            prefix=\"validation\",\n",
    "            frequency=1,\n",
    "            additional_filter_triples=dataset.inductive_inference.mapped_triples,\n",
    "        ),\n",
    "        stopper = stopper\n",
    "        \n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4aabaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "print(\"Train error\")\n",
    "show_metrics(train_evaluator.evaluate(\n",
    "        model=model,\n",
    "        mapped_triples=dataset.transductive_training.mapped_triples,\n",
    "        additional_filter_triples=[\n",
    "        dataset.transductive_training.mapped_triples,\n",
    "    ]\n",
    "    ).to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c7e30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation\n",
    "print(\"Validation error\")\n",
    "show_metrics(valid_evaluator.evaluate(\n",
    "        model=model,\n",
    "        mapped_triples=dataset.inductive_validation.mapped_triples,\n",
    "        additional_filter_triples=[\n",
    "            # filtering of other positive triples\n",
    "            dataset.inductive_inference.mapped_triples\n",
    "        ],\n",
    "    ).to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98aaf677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result on the test set\n",
    "print(\"Test error\")\n",
    "show_metrics(test_evaluator.evaluate(\n",
    "        model=model,\n",
    "        mapped_triples=dataset.inductive_testing.mapped_triples,\n",
    "        additional_filter_triples=[\n",
    "            # filtering of other positive triples\n",
    "            dataset.inductive_inference.mapped_triples,\n",
    "            dataset.inductive_validation.mapped_triples,\n",
    "        ],\n",
    "    ).to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc0af62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
