{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d30eabec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykeen.pipeline import pipeline\n",
    "from pykeen.datasets import Nations, get_dataset\n",
    "import torch\n",
    "from pykeen.evaluation import evaluate, RankBasedEvaluator\n",
    "from pykeen.metrics.ranking import HitsAtK\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "import click\n",
    "import more_click\n",
    "import torch\n",
    "from pykeen.evaluation import RankBasedEvaluator\n",
    "from pykeen.losses import NSSALoss,CrossEntropyLoss\n",
    "from pykeen.models.inductive import InductiveNodePiece, InductiveNodePieceGNN\n",
    "from pykeen.trackers import ConsoleResultTracker, WANDBResultTracker, FileResultTracker\n",
    "from pykeen.training import SLCWATrainingLoop\n",
    "from pykeen.typing import TESTING, TRAINING, VALIDATION\n",
    "from pykeen.utils import resolve_device, set_random_seed\n",
    "from torch.optim import Adam\n",
    "\n",
    "\n",
    "from pykeen.metrics.ranking import HitsAtK\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from pykeen.datasets.inductive.base import DisjointInductivePathDataset\n",
    "from pykeen.datasets.base import PathDataset, Dataset\n",
    "from typing_extensions import Literal\n",
    "import os\n",
    "from pykeen.hpo import hpo_pipeline\n",
    "from pykeen.triples import TriplesFactory\n",
    "from pykeen.models import InductiveNodePiece, TransE, RGCN, ConvE\n",
    "from pykeen.typing import TESTING, TRAINING, VALIDATION\n",
    "\n",
    "import time\n",
    "\n",
    "import platform\n",
    "\n",
    "import sys\n",
    "\n",
    "import cpuinfo\n",
    "\n",
    "import psutil\n",
    "\n",
    "import subprocess\n",
    "\n",
    "import zipfile\n",
    "\n",
    "seed = 1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fba970fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_metrics(dictionary,model_name,csv_name):\n",
    "    for key in dictionary.keys():\n",
    "        print(key)\n",
    "        df = pd.DataFrame(dictionary[key])\n",
    "        df.to_csv(f\"{model_name}/{model_name}_{csv_name}_{key}.csv\")\n",
    "        print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "612fd4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TYPE = \"_transductive.tsv\"\n",
    "TRAIN_PATH = \"MSCallGraph_train\" + DATA_TYPE\n",
    "TEST_PATH = \"MSCallGraph_test\" + DATA_TYPE\n",
    "VALIDATE_PATH = \"MSCallGraph_validation\" + DATA_TYPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "750b49c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PathDataset(training_path = TRAIN_PATH,\n",
    "                     testing_path = TEST_PATH,\n",
    "                     validation_path = VALIDATE_PATH,\n",
    "                      eager = True\n",
    "                     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b863c567",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'convE_transductive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78e64fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker = ConsoleResultTracker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "141b31a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = NSSALoss() #used by RotatE and NodePiece\n",
    "embedding_dim = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eee10f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Layers RGCNLayer(\n",
      "  (fwd): BasesDecomposition(\n",
      "    (relation_representations): LowRankRepresentation(\n",
      "      (bases): Embedding(\n",
      "        (_embeddings): Embedding(3, 40000)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (bwd): BasesDecomposition(\n",
      "    (relation_representations): LowRankRepresentation(\n",
      "      (bases): Embedding(\n",
      "        (_embeddings): Embedding(3, 40000)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (self_loop): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ") has parameters, but no reset_parameters.\n",
      "Layers RGCNLayer(\n",
      "  (fwd): BasesDecomposition(\n",
      "    (relation_representations): LowRankRepresentation(\n",
      "      (bases): Embedding(\n",
      "        (_embeddings): Embedding(3, 40000)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (bwd): BasesDecomposition(\n",
      "    (relation_representations): LowRankRepresentation(\n",
      "      (bases): Embedding(\n",
      "        (_embeddings): Embedding(3, 40000)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (self_loop): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ") has parameters, but no reset_parameters.\n",
      "No cuda devices were available. The model runs on CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 3893072\n",
      "Space occupied: 15572288 bytes\n"
     ]
    }
   ],
   "source": [
    "model = ConvE(\n",
    "        triples_factory=dataset.training,\n",
    "        random_seed = seed,\n",
    "        loss = loss,\n",
    "        embedding_dim = embedding_dim\n",
    "    ).to(resolve_device())\n",
    "print(f\"Number of parameters: {sum(p.numel() for p in model.parameters())}\")\n",
    "print(f\"Space occupied: {model.num_parameter_bytes} bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61f247b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory transE_transductive already exists.\n"
     ]
    }
   ],
   "source": [
    "directory = model_name\n",
    "\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "    print(f'Directory {directory} created successfully!')\n",
    "else:\n",
    "    print(f'Directory {directory} already exists.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3530c9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "optimizer = Adam(params=model.parameters(), lr=learning_rate)\n",
    "num_epochs = 2000\n",
    "patience = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8fc2a40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['meanreciprocalrank', HitsAtK(1),\n",
    "                 HitsAtK(3), HitsAtK(5), HitsAtK(10)]\n",
    "\n",
    "train_evaluator = RankBasedEvaluator(\n",
    "        metrics=metrics,\n",
    "        add_defaults=False,\n",
    "    )\n",
    "valid_evaluator = RankBasedEvaluator(\n",
    "        metrics=metrics,\n",
    "        add_defaults=False,\n",
    "    )\n",
    "test_evaluator = RankBasedEvaluator(\n",
    "        metrics = metrics,\n",
    "        add_defaults=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf7cd0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykeen.stoppers import EarlyStopper\n",
    "\n",
    "stopper = EarlyStopper(\n",
    "    model = model,\n",
    "    metric='meanreciprocalrank',\n",
    "    patience=patience,\n",
    "    frequency=1,\n",
    "    evaluator = valid_evaluator,\n",
    "    training_triples_factory = dataset.training,\n",
    "    evaluation_triples_factory = dataset.validation,\n",
    "    result_tracker = tracker\n",
    "\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae4971a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default training regime is negative sampling (SLCWA)\n",
    "# you can also use the 1-N regime with the LCWATrainingLoop\n",
    "# the LCWA loop does not need negative sampling kwargs, but accepts label_smoothing in the .train() method\n",
    "training_loop = SLCWATrainingLoop(\n",
    "        triples_factory=dataset.training,\n",
    "        model=model,\n",
    "        result_tracker=tracker,\n",
    "        optimizer=optimizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fdf15a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using RGCN without graph-based sampling! Please select sampler=\"schlichtkrull\" instead of None.\n",
      "Layers RGCNLayer(\n",
      "  (fwd): BasesDecomposition(\n",
      "    (relation_representations): LowRankRepresentation(\n",
      "      (bases): Embedding(\n",
      "        (_embeddings): Embedding(3, 40000)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (bwd): BasesDecomposition(\n",
      "    (relation_representations): LowRankRepresentation(\n",
      "      (bases): Embedding(\n",
      "        (_embeddings): Embedding(3, 40000)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (self_loop): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ") has parameters, but no reset_parameters.\n",
      "Layers RGCNLayer(\n",
      "  (fwd): BasesDecomposition(\n",
      "    (relation_representations): LowRankRepresentation(\n",
      "      (bases): Embedding(\n",
      "        (_embeddings): Embedding(3, 40000)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (bwd): BasesDecomposition(\n",
      "    (relation_representations): LowRankRepresentation(\n",
      "      (bases): Embedding(\n",
      "        (_embeddings): Embedding(3, 40000)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (self_loop): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ") has parameters, but no reset_parameters.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aea935daa7c646f0b019328e196c3470",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epochs on cpu:   0%|          | 0/2000 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "905ffff6181c4176a4a4dbd399066427",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches on cpu:   0%|          | 0/139 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m training_start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m----> 2\u001b[0m train_epoch \u001b[38;5;241m=\u001b[39m  \u001b[43mtraining_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtriples_factory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mevaluation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m            \u001b[49m\u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_evaluator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m            \u001b[49m\u001b[43mevaluation_triples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmapped_triples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalidation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfrequency\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m            \u001b[49m\u001b[43madditional_filter_triples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmapped_triples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopper\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstopper\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m        \u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m training_duration \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m training_start\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\MasterThesis\\lib\\site-packages\\pykeen\\training\\training_loop.py:378\u001b[0m, in \u001b[0;36mTrainingLoop.train\u001b[1;34m(self, triples_factory, num_epochs, batch_size, slice_size, label_smoothing, sampler, continue_training, only_size_probing, use_tqdm, use_tqdm_batch, tqdm_kwargs, stopper, sub_batch_size, num_workers, clear_optimizer, checkpoint_directory, checkpoint_name, checkpoint_frequency, checkpoint_on_failure, drop_last, callbacks, callback_kwargs, gradient_clipping_max_norm, gradient_clipping_norm_type, gradient_clipping_max_abs_value, pin_memory)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    376\u001b[0m     \u001b[38;5;66;03m# send model to device before going into the internal training loop\u001b[39;00m\n\u001b[0;32m    377\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mto(get_preferred_device(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, allow_ambiguity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[1;32m--> 378\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    379\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43mslice_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mslice_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43msampler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msampler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    384\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontinue_training\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontinue_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    385\u001b[0m \u001b[43m        \u001b[49m\u001b[43monly_size_probing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43monly_size_probing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_tqdm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_tqdm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    387\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_tqdm_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_tqdm_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    388\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtqdm_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtqdm_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    389\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstopper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[43m        \u001b[49m\u001b[43msub_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msub_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    391\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    392\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_checkpoints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_checkpoints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    393\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    394\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_frequency\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheckpoint_frequency\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    395\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_on_failure_file_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheckpoint_on_failure_file_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    396\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbest_epoch_model_file_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbest_epoch_model_file_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    397\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlast_best_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlast_best_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    398\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdrop_last\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_last\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    399\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    400\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    401\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgradient_clipping_max_norm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgradient_clipping_max_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    402\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgradient_clipping_norm_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgradient_clipping_norm_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    403\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgradient_clipping_max_abs_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgradient_clipping_max_abs_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtriples_factory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtriples_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpin_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpin_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    406\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    408\u001b[0m \u001b[38;5;66;03m# Ensure the release of memory\u001b[39;00m\n\u001b[0;32m    409\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\MasterThesis\\lib\\site-packages\\pykeen\\training\\training_loop.py:642\u001b[0m, in \u001b[0;36mTrainingLoop._train\u001b[1;34m(self, triples_factory, num_epochs, batch_size, slice_size, label_smoothing, sampler, continue_training, only_size_probing, use_tqdm, use_tqdm_batch, tqdm_kwargs, stopper, sub_batch_size, num_workers, save_checkpoints, checkpoint_path, checkpoint_frequency, checkpoint_on_failure_file_path, best_epoch_model_file_path, last_best_epoch, drop_last, callbacks, callback_kwargs, gradient_clipping_max_norm, gradient_clipping_norm_type, gradient_clipping_max_abs_value, pin_memory)\u001b[0m\n\u001b[0;32m    639\u001b[0m stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(start \u001b[38;5;241m+\u001b[39m _sub_batch_size, current_batch_size)\n\u001b[0;32m    641\u001b[0m \u001b[38;5;66;03m# forward pass call\u001b[39;00m\n\u001b[1;32m--> 642\u001b[0m batch_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_pass\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    643\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    644\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    645\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    646\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcurrent_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    647\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    648\u001b[0m \u001b[43m    \u001b[49m\u001b[43mslice_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    649\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    650\u001b[0m current_epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m batch_loss\n\u001b[0;32m    651\u001b[0m num_training_instances \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m stop \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\MasterThesis\\lib\\site-packages\\pykeen\\training\\training_loop.py:835\u001b[0m, in \u001b[0;36mTrainingLoop._forward_pass\u001b[1;34m(self, batch, start, stop, current_batch_size, label_smoothing, slice_size)\u001b[0m\n\u001b[0;32m    832\u001b[0m     loss \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m this_sub_batch_size \u001b[38;5;241m/\u001b[39m current_batch_size\n\u001b[0;32m    834\u001b[0m \u001b[38;5;66;03m# backward pass\u001b[39;00m\n\u001b[1;32m--> 835\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    836\u001b[0m current_epoch_loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m    838\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mpost_forward_pass()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\MasterThesis\\lib\\site-packages\\torch\\_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    479\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    480\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    481\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    486\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    487\u001b[0m     )\n\u001b[1;32m--> 488\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\MasterThesis\\lib\\site-packages\\torch\\autograd\\__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    192\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    194\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 197\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training_start = time.time()\n",
    "train_epoch =  training_loop.train(\n",
    "        triples_factory=dataset.training,\n",
    "        num_epochs=num_epochs,\n",
    "#         callbacks=\"evaluation\",\n",
    "#         callback_kwargs=dict(\n",
    "#             evaluator=valid_evaluator,\n",
    "#             evaluation_triples=dataset.validation.mapped_triples,\n",
    "#             prefix=\"validation\",\n",
    "#             frequency=1,\n",
    "#             additional_filter_triples=dataset.training.mapped_triples,\n",
    "#         ),\n",
    "        stopper = stopper\n",
    "        \n",
    "    )\n",
    "training_duration = time.time() - training_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98f77bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train error per epoch:\n",
      "          0\n",
      "0  3.967333\n"
     ]
    }
   ],
   "source": [
    "print(\"Train error per epoch:\")\n",
    "df = pd.DataFrame(train_epoch)\n",
    "print(df)\n",
    "df.to_csv(f\"{model_name}/{model_name}_train_error_per_epoch.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4aabaae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train error\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b50f8f0a0c244709abcae77b0eb4703c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating on cpu:   0%|          | 0.00/35.6k [00:00<?, ?triple/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head\n",
      "                            optimistic  realistic  pessimistic\n",
      "inverse_harmonic_mean_rank    0.022962   0.022962     0.022962\n",
      "hits_at_1                     0.010968   0.010968     0.010968\n",
      "hits_at_3                     0.024016   0.024016     0.024016\n",
      "hits_at_5                     0.030147   0.030147     0.030147\n",
      "hits_at_10                    0.041002   0.041002     0.041002\n",
      "tail\n",
      "                            optimistic  realistic  pessimistic\n",
      "inverse_harmonic_mean_rank    0.032993   0.032993     0.032993\n",
      "hits_at_1                     0.010968   0.010968     0.010968\n",
      "hits_at_3                     0.037684   0.037684     0.037684\n",
      "hits_at_5                     0.049101   0.049101     0.049101\n",
      "hits_at_10                    0.067915   0.067915     0.067915\n",
      "both\n",
      "                            optimistic  realistic  pessimistic\n",
      "inverse_harmonic_mean_rank    0.027978   0.027978     0.027978\n",
      "hits_at_1                     0.010968   0.010968     0.010968\n",
      "hits_at_3                     0.030850   0.030850     0.030850\n",
      "hits_at_5                     0.039624   0.039624     0.039624\n",
      "hits_at_10                    0.054459   0.054459     0.054459\n"
     ]
    }
   ],
   "source": [
    "training_evaluation_start = time.time()\n",
    "# train\n",
    "print(\"Train error\")\n",
    "show_metrics(train_evaluator.evaluate(\n",
    "        model=model,\n",
    "        mapped_triples=dataset.training.mapped_triples,\n",
    "        additional_filter_triples=[\n",
    "        dataset.training.mapped_triples,\n",
    "    ]\n",
    "    ).to_dict(),model_name,'train_metrics')\n",
    "training_evaluation_duration = time.time() - training_evaluation_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c3c7e30e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation error\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baacebd89cb043df86cd0c530a5bdde6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating on cpu:   0%|          | 0.00/8.80k [00:00<?, ?triple/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head\n",
      "                            optimistic  realistic  pessimistic\n",
      "inverse_harmonic_mean_rank    0.011896   0.011896     0.011896\n",
      "hits_at_1                     0.010908   0.010908     0.010908\n",
      "hits_at_3                     0.011249   0.011249     0.011249\n",
      "hits_at_5                     0.011590   0.011590     0.011590\n",
      "hits_at_10                    0.012499   0.012499     0.012499\n",
      "tail\n",
      "                            optimistic  realistic  pessimistic\n",
      "inverse_harmonic_mean_rank    0.012953   0.012953     0.012953\n",
      "hits_at_1                     0.010908   0.010908     0.010908\n",
      "hits_at_3                     0.011817   0.011817     0.011817\n",
      "hits_at_5                     0.012953   0.012953     0.012953\n",
      "hits_at_10                    0.015112   0.015112     0.015112\n",
      "both\n",
      "                            optimistic  realistic  pessimistic\n",
      "inverse_harmonic_mean_rank    0.012424   0.012424     0.012424\n",
      "hits_at_1                     0.010908   0.010908     0.010908\n",
      "hits_at_3                     0.011533   0.011533     0.011533\n",
      "hits_at_5                     0.012271   0.012271     0.012271\n",
      "hits_at_10                    0.013805   0.013805     0.013805\n"
     ]
    }
   ],
   "source": [
    "validation_evaluation_start = time.time()\n",
    "# validation\n",
    "print(\"Validation error\")\n",
    "show_metrics(valid_evaluator.evaluate(\n",
    "        model=model,\n",
    "        mapped_triples=dataset.validation.mapped_triples,\n",
    "        additional_filter_triples=[\n",
    "            # filtering of other positive triples\n",
    "            dataset.training.mapped_triples\n",
    "        ],\n",
    "    ).to_dict(),model_name,'validation_metrics')\n",
    "validation_evaluation_duration = time.time() - validation_evaluation_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98aaf677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9697d37ff9074472ac74d942b115d697",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating on cpu:   0%|          | 0.00/11.2k [00:00<?, ?triple/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head\n",
      "                            optimistic  realistic  pessimistic\n",
      "inverse_harmonic_mean_rank    0.011825   0.011825     0.011825\n",
      "hits_at_1                     0.010802   0.010802     0.010802\n",
      "hits_at_3                     0.011069   0.011069     0.011069\n",
      "hits_at_5                     0.011427   0.011427     0.011427\n",
      "hits_at_10                    0.012676   0.012676     0.012676\n",
      "tail\n",
      "                            optimistic  realistic  pessimistic\n",
      "inverse_harmonic_mean_rank    0.012670   0.012670     0.012670\n",
      "hits_at_1                     0.010712   0.010712     0.010712\n",
      "hits_at_3                     0.011962   0.011962     0.011962\n",
      "hits_at_5                     0.012587   0.012587     0.012587\n",
      "hits_at_10                    0.014372   0.014372     0.014372\n",
      "both\n",
      "                            optimistic  realistic  pessimistic\n",
      "inverse_harmonic_mean_rank    0.012247   0.012247     0.012247\n",
      "hits_at_1                     0.010757   0.010757     0.010757\n",
      "hits_at_3                     0.011516   0.011516     0.011516\n",
      "hits_at_5                     0.012007   0.012007     0.012007\n",
      "hits_at_10                    0.013524   0.013524     0.013524\n"
     ]
    }
   ],
   "source": [
    "testing_evaluation_start = time.time()\n",
    "# result on the test set\n",
    "print(\"Test error\")\n",
    "show_metrics(test_evaluator.evaluate(\n",
    "        model=model,\n",
    "        mapped_triples=dataset.testing.mapped_triples,\n",
    "        additional_filter_triples=[\n",
    "            # filtering of other positive triples\n",
    "            dataset.training.mapped_triples,\n",
    "            dataset.validation.mapped_triples,\n",
    "        ],\n",
    "    ).to_dict(),model_name,'test_metrics')\n",
    "testing_evaluation_duration = time.time() - testing_evaluation_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dcb170ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "infodict = {}\n",
    "infodict['device'] = model.device\n",
    "infodict['parameters bytes'] = model.num_parameter_bytes\n",
    "infodict['number parameters'] = model.num_parameters\n",
    "infodict['training duration'] = training_duration\n",
    "infodict['training evaluation duration'] = training_evaluation_duration\n",
    "infodict['validation evaluation duration'] = validation_evaluation_duration\n",
    "infodict['testing evaluation duration'] = testing_evaluation_duration\n",
    "infodict[\"Operating system name\"] = platform.system()\n",
    "infodict[\"Operating system version\"] = platform.release()\n",
    "infodict[\"Processor architecture\"] = platform.machine()\n",
    "infodict[\"Python version\"] = sys.version\n",
    "infodict[\"Processor model name\"] = cpuinfo.get_cpu_info()['brand_raw']\n",
    "infodict['Number cpu cores'] = os.cpu_count()\n",
    "infodict[\"Total physical memory\"] = psutil.virtual_memory().total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cc302cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output = subprocess.check_output(['nvidia-smi', '--query-gpu=name', '--format=csv'])\n",
    "output = output.decode('utf-8')  # convert byte string to regular string\n",
    "\n",
    "# split output into rows and remove header row\n",
    "rows = output.strip().split('\\n')[1:]\n",
    "\n",
    "# extract GPU names from each row\n",
    "gpu_names = []\n",
    "for row in rows:\n",
    "    name = row.strip()\n",
    "    gpu_names.append(name)\n",
    "\n",
    "infodict['GPU'] = gpu_names[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7079e496",
   "metadata": {},
   "outputs": [],
   "source": [
    "infodict['loss'] = NSSALoss\n",
    "infodict['embedding_dim'] = embedding_dim\n",
    "infodict['learning_rate'] = learning_rate\n",
    "infodict['optimizer'] = Adam\n",
    "infodict['num_epochs'] = num_epochs\n",
    "infodict['patience'] = patience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "43a75c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              name  \\\n",
      "0                           device   \n",
      "1                 parameters bytes   \n",
      "2                number parameters   \n",
      "3                training duration   \n",
      "4     training evaluation duration   \n",
      "5   validation evaluation duration   \n",
      "6      testing evaluation duration   \n",
      "7            Operating system name   \n",
      "8         Operating system version   \n",
      "9           Processor architecture   \n",
      "10                  Python version   \n",
      "11            Processor model name   \n",
      "12                Number cpu cores   \n",
      "13           Total physical memory   \n",
      "14                            loss   \n",
      "15                   embedding_dim   \n",
      "16                   learning_rate   \n",
      "17                       optimizer   \n",
      "18                      num_epochs   \n",
      "19                        patience   \n",
      "\n",
      "                                                value  \n",
      "0                                                 cpu  \n",
      "1                                            13330400  \n",
      "2                                             3332600  \n",
      "3                                          252.387353  \n",
      "4                                          474.315323  \n",
      "5                                          119.237597  \n",
      "6                                          154.559298  \n",
      "7                                             Windows  \n",
      "8                                                  10  \n",
      "9                                               AMD64  \n",
      "10  3.9.16 (main, Jan 11 2023, 16:16:36) [MSC v.19...  \n",
      "11             AMD Ryzen 7 5700U with Radeon Graphics  \n",
      "12                                                 16  \n",
      "13                                         7851745280  \n",
      "14                   <class 'pykeen.losses.NSSALoss'>  \n",
      "15                                                200  \n",
      "16                                              0.001  \n",
      "17                    <class 'torch.optim.adam.Adam'>  \n",
      "18                                                  1  \n",
      "19                                                  1  \n"
     ]
    }
   ],
   "source": [
    "info_df = pd.DataFrame(columns=['name','value'], data = infodict.items())\n",
    "info_df.to_csv(f\"{model_name}/{model_name}_information.csv\")\n",
    "print(info_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "28602afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zip_folder(folder_path, output_path):\n",
    "    with zipfile.ZipFile(output_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "        for root, dirs, files in os.walk(folder_path):\n",
    "            for file in files:\n",
    "                zipf.write(os.path.join(root, file))\n",
    "\n",
    "folder_path = model_name\n",
    "output_path = f'{model_name}.zip'\n",
    "\n",
    "zip_folder(folder_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ad8fdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
