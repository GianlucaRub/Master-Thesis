{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d30eabec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykeen.pipeline import pipeline\n",
    "from pykeen.datasets import Nations, get_dataset\n",
    "import torch\n",
    "from pykeen.evaluation import evaluate, RankBasedEvaluator\n",
    "from pykeen.metrics.ranking import HitsAtK\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "import click\n",
    "import more_click\n",
    "import torch\n",
    "from pykeen.evaluation import RankBasedEvaluator\n",
    "from pykeen.losses import NSSALoss,CrossEntropyLoss\n",
    "from pykeen.models.inductive import InductiveNodePiece, InductiveNodePieceGNN\n",
    "from pykeen.trackers import ConsoleResultTracker, WANDBResultTracker\n",
    "from pykeen.training import SLCWATrainingLoop\n",
    "from pykeen.typing import TESTING, TRAINING, VALIDATION\n",
    "from pykeen.utils import resolve_device, set_random_seed\n",
    "from torch.optim import Adam\n",
    "\n",
    "\n",
    "from pykeen.metrics.ranking import HitsAtK\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from pykeen.datasets.inductive.base import DisjointInductivePathDataset\n",
    "from typing_extensions import Literal\n",
    "import os\n",
    "from pykeen.hpo import hpo_pipeline\n",
    "from pykeen.triples import TriplesFactory\n",
    "from pykeen.models import InductiveNodePiece\n",
    "from pykeen.typing import TESTING, TRAINING, VALIDATION\n",
    "\n",
    "import time\n",
    "\n",
    "import platform\n",
    "\n",
    "import sys\n",
    "\n",
    "import cpuinfo\n",
    "\n",
    "import psutil\n",
    "\n",
    "import subprocess\n",
    "\n",
    "import zipfile\n",
    "\n",
    "seed = 1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59954771",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InductiveLPDataset(DisjointInductivePathDataset):\n",
    "    \"\"\"An inductive link prediction dataset for the ILPC 2022 Challenge.\"\"\"\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    def __init__(self , **kwargs):\n",
    "        \"\"\"Initialize the inductive link prediction dataset.\n",
    "\n",
    "        :param size: \"small\" or \"large\"\n",
    "        :param kwargs: keyword arguments to forward to the base dataset class, cf. DisjointInductivePathDataset\n",
    "        \"\"\"\n",
    "        DATA_TYPE = \"_fully_inductive.tsv\"\n",
    "        TRAIN_PATH = \"MSCallGraph_train\" + DATA_TYPE\n",
    "        TEST_PATH = \"MSCallGraph_test\" + DATA_TYPE\n",
    "        VALIDATE_PATH = \"MSCallGraph_validation\" + DATA_TYPE\n",
    "        INFERENCE_PATH = \"MSCallGraph_inference\" + DATA_TYPE\n",
    "\n",
    "\n",
    "        super().__init__(\n",
    "            transductive_training_path=os.getcwd()+\"/\"+TRAIN_PATH,\n",
    "            inductive_inference_path=os.getcwd()+\"/\"+INFERENCE_PATH,\n",
    "            inductive_validation_path=os.getcwd()+\"/\"+VALIDATE_PATH,\n",
    "            inductive_testing_path=os.getcwd()+\"/\"+TEST_PATH,\n",
    "            create_inverse_triples=True,\n",
    "            eager=True,\n",
    "            **kwargs\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fba970fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_metrics(dictionary,model_name,csv_name):\n",
    "    for key in dictionary.keys():\n",
    "        print(key)\n",
    "        df = pd.DataFrame(dictionary[key])\n",
    "        df.to_csv(f\"{model_name}/{model_name}_{csv_name}_{key}.csv\")\n",
    "        print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "766f31a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = InductiveLPDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6814cff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker = ConsoleResultTracker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "022351dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = NSSALoss() #used by RotatE and NodePiece\n",
    "num_tokens = 20\n",
    "embedding_dim = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eee10f05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling:   0%|          | 0.00/9.06k [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No symbolic computation of output shape.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling:   0%|          | 0.00/3.79k [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No symbolic computation of output shape.\n",
      "No cuda devices were available. The model runs on CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 2600\n",
      "Space occupied: 10400 bytes\n"
     ]
    }
   ],
   "source": [
    "model_name = 'nodepiece_inductive'\n",
    "model = InductiveNodePiece(\n",
    "        triples_factory=dataset.transductive_training,\n",
    "        inference_factory=dataset.inductive_inference,\n",
    "        random_seed = seed,\n",
    "        loss = loss,\n",
    "        num_tokens = num_tokens,\n",
    "        embedding_dim = embedding_dim\n",
    "    ).to(resolve_device())\n",
    "print(f\"Number of parameters: {sum(p.numel() for p in model.parameters())}\")\n",
    "print(f\"Space occupied: {model.num_parameter_bytes} bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "721b320b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory nodepiece_inductive created successfully!\n"
     ]
    }
   ],
   "source": [
    "directory = model_name\n",
    "\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "    print(f'Directory {directory} created successfully!')\n",
    "else:\n",
    "    print(f'Directory {directory} already exists.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75121c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "optimizer = Adam(params=model.parameters(), lr=learning_rate)\n",
    "num_epochs = 200\n",
    "patience = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8fc2a40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['meanreciprocalrank', HitsAtK(1),\n",
    "                 HitsAtK(3), HitsAtK(5), HitsAtK(10)]\n",
    "\n",
    "train_evaluator = RankBasedEvaluator(\n",
    "        mode=TRAINING,\n",
    "        metrics=metrics,\n",
    "        add_defaults=False,\n",
    "    )\n",
    "valid_evaluator = RankBasedEvaluator(\n",
    "        mode=VALIDATION,\n",
    "        metrics=metrics,\n",
    "        add_defaults=False,\n",
    "    )\n",
    "test_evaluator = RankBasedEvaluator(\n",
    "        mode=TESTING,\n",
    "        metrics = metrics,\n",
    "        add_defaults=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75f8ba40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykeen.stoppers import EarlyStopper\n",
    "\n",
    "stopper = EarlyStopper(\n",
    "    model = model,\n",
    "    metric='meanreciprocalrank',\n",
    "    patience=patience,\n",
    "    frequency=1,\n",
    "    evaluator = valid_evaluator,\n",
    "    training_triples_factory = dataset.inductive_inference,\n",
    "    evaluation_triples_factory = dataset.inductive_validation,\n",
    "    result_tracker = tracker\n",
    "\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae4971a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default training regime is negative sampling (SLCWA)\n",
    "# you can also use the 1-N regime with the LCWATrainingLoop\n",
    "# the LCWA loop does not need negative sampling kwargs, but accepts label_smoothing in the .train() method\n",
    "training_loop = SLCWATrainingLoop(\n",
    "        triples_factory=dataset.transductive_training,\n",
    "        model=model,\n",
    "        mode=TRAINING,  # must be specified for the inductive setup\n",
    "        result_tracker=tracker,\n",
    "        optimizer=optimizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fdf15a48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33b0c4605cf34254a42e1557ed38e306",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epochs on cpu:   0%|          | 0/1 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches on cpu:   0%|          | 0/184 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef0557c78f3f49e2aab7c5a5e3810ce4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating on cpu:   0%|          | 0.00/3.13k [00:00<?, ?triple/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1\n",
      "Metric: validation.head.optimistic.inverse_harmonic_mean_rank = 0.012906042211660406\n",
      "Metric: validation.tail.optimistic.inverse_harmonic_mean_rank = 0.03473410601969134\n",
      "Metric: validation.both.optimistic.inverse_harmonic_mean_rank = 0.023820074115675872\n",
      "Metric: validation.head.realistic.inverse_harmonic_mean_rank = 0.01227752584964037\n",
      "Metric: validation.tail.realistic.inverse_harmonic_mean_rank = 0.031580857932567596\n",
      "Metric: validation.both.realistic.inverse_harmonic_mean_rank = 0.021929193288087845\n",
      "Metric: validation.head.pessimistic.inverse_harmonic_mean_rank = 0.011888409472556621\n",
      "Metric: validation.tail.pessimistic.inverse_harmonic_mean_rank = 0.02987064980162328\n",
      "Metric: validation.both.pessimistic.inverse_harmonic_mean_rank = 0.020879529637089955\n",
      "Metric: validation.head.optimistic.hits_at_1 = 0.0063959066197633516\n",
      "Metric: validation.tail.optimistic.hits_at_1 = 0.016309561880396548\n",
      "Metric: validation.both.optimistic.hits_at_1 = 0.01135273425007995\n",
      "Metric: validation.head.realistic.hits_at_1 = 0.0063959066197633516\n",
      "Metric: validation.tail.realistic.hits_at_1 = 0.01598976654940838\n",
      "Metric: validation.both.realistic.hits_at_1 = 0.011192836584585865\n",
      "Metric: validation.head.pessimistic.hits_at_1 = 0.0063959066197633516\n",
      "Metric: validation.tail.pessimistic.hits_at_1 = 0.01598976654940838\n",
      "Metric: validation.both.pessimistic.hits_at_1 = 0.011192836584585865\n",
      "Metric: validation.head.optimistic.hits_at_3 = 0.0118324272465622\n",
      "Metric: validation.tail.optimistic.hits_at_3 = 0.028141989126958745\n",
      "Metric: validation.both.optimistic.hits_at_3 = 0.019987208186760475\n",
      "Metric: validation.head.realistic.hits_at_3 = 0.011512631915574032\n",
      "Metric: validation.tail.realistic.hits_at_3 = 0.01982731052126639\n",
      "Metric: validation.both.realistic.hits_at_3 = 0.01566997121842021\n",
      "Metric: validation.head.pessimistic.hits_at_3 = 0.011512631915574032\n",
      "Metric: validation.tail.pessimistic.hits_at_3 = 0.01982731052126639\n",
      "Metric: validation.both.pessimistic.hits_at_3 = 0.01566997121842021\n",
      "Metric: validation.head.optimistic.hits_at_5 = 0.013431403901503039\n",
      "Metric: validation.tail.optimistic.hits_at_5 = 0.03133994243684042\n",
      "Metric: validation.both.optimistic.hits_at_5 = 0.02238567316917173\n",
      "Metric: validation.head.realistic.hits_at_5 = 0.01311160857051487\n",
      "Metric: validation.tail.realistic.hits_at_5 = 0.029421170450911416\n",
      "Metric: validation.both.realistic.hits_at_5 = 0.021266389510713142\n",
      "Metric: validation.head.pessimistic.hits_at_5 = 0.01311160857051487\n",
      "Metric: validation.tail.pessimistic.hits_at_5 = 0.028141989126958745\n",
      "Metric: validation.both.pessimistic.hits_at_5 = 0.02062679884873681\n",
      "Metric: validation.head.optimistic.hits_at_10 = 0.016309561880396548\n",
      "Metric: validation.tail.optimistic.hits_at_10 = 0.07898944675407739\n",
      "Metric: validation.both.optimistic.hits_at_10 = 0.04764950431723697\n",
      "Metric: validation.head.realistic.hits_at_10 = 0.016309561880396548\n",
      "Metric: validation.tail.realistic.hits_at_10 = 0.07163415414134953\n",
      "Metric: validation.both.realistic.hits_at_10 = 0.04397185801087304\n",
      "Metric: validation.head.pessimistic.hits_at_10 = 0.01566997121842021\n",
      "Metric: validation.tail.pessimistic.hits_at_10 = 0.0345378957467221\n",
      "Metric: validation.both.pessimistic.hits_at_10 = 0.025103933482571155\n",
      "Step: 1\n",
      "Metric: loss = 2.7265682920165686\n",
      "Step: 1\n",
      "Metric: validation.head.optimistic.inverse_harmonic_mean_rank = 0.012906042211660406\n",
      "Metric: validation.tail.optimistic.inverse_harmonic_mean_rank = 0.03473410601969134\n",
      "Metric: validation.both.optimistic.inverse_harmonic_mean_rank = 0.023820074115675872\n",
      "Metric: validation.head.realistic.inverse_harmonic_mean_rank = 0.01227752584964037\n",
      "Metric: validation.tail.realistic.inverse_harmonic_mean_rank = 0.031580857932567596\n",
      "Metric: validation.both.realistic.inverse_harmonic_mean_rank = 0.021929193288087845\n",
      "Metric: validation.head.pessimistic.inverse_harmonic_mean_rank = 0.011888409472556621\n",
      "Metric: validation.tail.pessimistic.inverse_harmonic_mean_rank = 0.02987064980162328\n",
      "Metric: validation.both.pessimistic.inverse_harmonic_mean_rank = 0.020879529637089955\n",
      "Metric: validation.head.optimistic.hits_at_1 = 0.0063959066197633516\n",
      "Metric: validation.tail.optimistic.hits_at_1 = 0.016309561880396548\n",
      "Metric: validation.both.optimistic.hits_at_1 = 0.01135273425007995\n",
      "Metric: validation.head.realistic.hits_at_1 = 0.0063959066197633516\n",
      "Metric: validation.tail.realistic.hits_at_1 = 0.01598976654940838\n",
      "Metric: validation.both.realistic.hits_at_1 = 0.011192836584585865\n",
      "Metric: validation.head.pessimistic.hits_at_1 = 0.0063959066197633516\n",
      "Metric: validation.tail.pessimistic.hits_at_1 = 0.01598976654940838\n",
      "Metric: validation.both.pessimistic.hits_at_1 = 0.011192836584585865\n",
      "Metric: validation.head.optimistic.hits_at_3 = 0.0118324272465622\n",
      "Metric: validation.tail.optimistic.hits_at_3 = 0.028141989126958745\n",
      "Metric: validation.both.optimistic.hits_at_3 = 0.019987208186760475\n",
      "Metric: validation.head.realistic.hits_at_3 = 0.011512631915574032\n",
      "Metric: validation.tail.realistic.hits_at_3 = 0.01982731052126639\n",
      "Metric: validation.both.realistic.hits_at_3 = 0.01566997121842021\n",
      "Metric: validation.head.pessimistic.hits_at_3 = 0.011512631915574032\n",
      "Metric: validation.tail.pessimistic.hits_at_3 = 0.01982731052126639\n",
      "Metric: validation.both.pessimistic.hits_at_3 = 0.01566997121842021\n",
      "Metric: validation.head.optimistic.hits_at_5 = 0.013431403901503039\n",
      "Metric: validation.tail.optimistic.hits_at_5 = 0.03133994243684042\n",
      "Metric: validation.both.optimistic.hits_at_5 = 0.02238567316917173\n",
      "Metric: validation.head.realistic.hits_at_5 = 0.01311160857051487\n",
      "Metric: validation.tail.realistic.hits_at_5 = 0.029421170450911416\n",
      "Metric: validation.both.realistic.hits_at_5 = 0.021266389510713142\n",
      "Metric: validation.head.pessimistic.hits_at_5 = 0.01311160857051487\n",
      "Metric: validation.tail.pessimistic.hits_at_5 = 0.028141989126958745\n",
      "Metric: validation.both.pessimistic.hits_at_5 = 0.02062679884873681\n",
      "Metric: validation.head.optimistic.hits_at_10 = 0.016309561880396548\n",
      "Metric: validation.tail.optimistic.hits_at_10 = 0.07898944675407739\n",
      "Metric: validation.both.optimistic.hits_at_10 = 0.04764950431723697\n",
      "Metric: validation.head.realistic.hits_at_10 = 0.016309561880396548\n",
      "Metric: validation.tail.realistic.hits_at_10 = 0.07163415414134953\n",
      "Metric: validation.both.realistic.hits_at_10 = 0.04397185801087304\n",
      "Metric: validation.head.pessimistic.hits_at_10 = 0.01566997121842021\n",
      "Metric: validation.tail.pessimistic.hits_at_10 = 0.0345378957467221\n",
      "Metric: validation.both.pessimistic.hits_at_10 = 0.025103933482571155\n"
     ]
    }
   ],
   "source": [
    "training_start = time.time()\n",
    "train_epoch =  training_loop.train(\n",
    "        triples_factory=dataset.transductive_training,\n",
    "        num_epochs=num_epochs,\n",
    "        callbacks=\"evaluation\",\n",
    "        callback_kwargs=dict(\n",
    "            evaluator=valid_evaluator,\n",
    "            evaluation_triples=dataset.inductive_validation.mapped_triples,\n",
    "            prefix=\"validation\",\n",
    "            frequency=1,\n",
    "            additional_filter_triples=dataset.inductive_inference.mapped_triples,\n",
    "        ),\n",
    "        stopper = stopper\n",
    "        \n",
    "    )\n",
    "training_duration = time.time() - training_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c3f4d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train error per epoch:\n",
      "          0\n",
      "0  2.726568\n"
     ]
    }
   ],
   "source": [
    "print(\"Train error per epoch:\")\n",
    "df = pd.DataFrame(train_epoch)\n",
    "print(df)\n",
    "df.to_csv(f\"{model_name}/{model_name}_train_error_per_epoch.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4aabaae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train error\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a98c9bbd97a400f9a9ed5870f08c6a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating on cpu:   0%|          | 0.00/23.5k [00:00<?, ?triple/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head\n",
      "                            optimistic  realistic  pessimistic\n",
      "inverse_harmonic_mean_rank    0.003790   0.003236     0.002936\n",
      "hits_at_1                     0.000681   0.000681     0.000681\n",
      "hits_at_3                     0.002811   0.001022     0.001022\n",
      "hits_at_5                     0.004642   0.002555     0.002044\n",
      "hits_at_10                    0.006516   0.005579     0.005452\n",
      "tail\n",
      "                            optimistic  realistic  pessimistic\n",
      "inverse_harmonic_mean_rank    0.009647   0.008171     0.007412\n",
      "hits_at_1                     0.002385   0.001533     0.001533\n",
      "hits_at_3                     0.003663   0.003663     0.003663\n",
      "hits_at_5                     0.008731   0.004131     0.004131\n",
      "hits_at_10                    0.014311   0.011926     0.007453\n",
      "both\n",
      "                            optimistic  realistic  pessimistic\n",
      "inverse_harmonic_mean_rank    0.006718   0.005703     0.005174\n",
      "hits_at_1                     0.001533   0.001107     0.001107\n",
      "hits_at_3                     0.003237   0.002343     0.002343\n",
      "hits_at_5                     0.006687   0.003343     0.003088\n",
      "hits_at_10                    0.010414   0.008753     0.006453\n"
     ]
    }
   ],
   "source": [
    "training_evaluation_start = time.time()\n",
    "# train\n",
    "print(\"Train error\")\n",
    "show_metrics(train_evaluator.evaluate(\n",
    "        model=model,\n",
    "        mapped_triples=dataset.transductive_training.mapped_triples,\n",
    "        additional_filter_triples=[\n",
    "        dataset.transductive_training.mapped_triples,\n",
    "    ]\n",
    "    ).to_dict(),model_name,'train_metrics')\n",
    "training_evaluation_duration = time.time() - training_evaluation_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3c7e30e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation error\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8dc8227b172482bad3a73f81ea6ddee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating on cpu:   0%|          | 0.00/3.13k [00:00<?, ?triple/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head\n",
      "                            optimistic  realistic  pessimistic\n",
      "inverse_harmonic_mean_rank    0.012906   0.012278     0.011888\n",
      "hits_at_1                     0.006396   0.006396     0.006396\n",
      "hits_at_3                     0.011832   0.011513     0.011513\n",
      "hits_at_5                     0.013431   0.013112     0.013112\n",
      "hits_at_10                    0.016310   0.016310     0.015670\n",
      "tail\n",
      "                            optimistic  realistic  pessimistic\n",
      "inverse_harmonic_mean_rank    0.034734   0.031581     0.029871\n",
      "hits_at_1                     0.016310   0.015990     0.015990\n",
      "hits_at_3                     0.028142   0.019827     0.019827\n",
      "hits_at_5                     0.031340   0.029421     0.028142\n",
      "hits_at_10                    0.078989   0.071634     0.034538\n",
      "both\n",
      "                            optimistic  realistic  pessimistic\n",
      "inverse_harmonic_mean_rank    0.023820   0.021929     0.020880\n",
      "hits_at_1                     0.011353   0.011193     0.011193\n",
      "hits_at_3                     0.019987   0.015670     0.015670\n",
      "hits_at_5                     0.022386   0.021266     0.020627\n",
      "hits_at_10                    0.047650   0.043972     0.025104\n"
     ]
    }
   ],
   "source": [
    "validation_evaluation_start = time.time()\n",
    "# validation\n",
    "print(\"Validation error\")\n",
    "show_metrics(valid_evaluator.evaluate(\n",
    "        model=model,\n",
    "        mapped_triples=dataset.inductive_validation.mapped_triples,\n",
    "        additional_filter_triples=[\n",
    "            # filtering of other positive triples\n",
    "            dataset.inductive_inference.mapped_triples\n",
    "        ],\n",
    "    ).to_dict(),model_name,'validation_metrics')\n",
    "validation_evaluation_duration = time.time() - validation_evaluation_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98aaf677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ab5a19537054f2fb6c5e00efc40b3fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating on cpu:   0%|          | 0.00/3.98k [00:00<?, ?triple/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head\n",
      "                            optimistic  realistic  pessimistic\n",
      "inverse_harmonic_mean_rank    0.013470   0.012746     0.012298\n",
      "hits_at_1                     0.006533   0.006533     0.006533\n",
      "hits_at_3                     0.013065   0.013065     0.013065\n",
      "hits_at_5                     0.014573   0.014322     0.014322\n",
      "hits_at_10                    0.017337   0.017337     0.017337\n",
      "tail\n",
      "                            optimistic  realistic  pessimistic\n",
      "inverse_harmonic_mean_rank    0.029931   0.026884     0.025214\n",
      "hits_at_1                     0.013065   0.012060     0.012060\n",
      "hits_at_3                     0.022362   0.016583     0.016332\n",
      "hits_at_5                     0.024372   0.023116     0.022111\n",
      "hits_at_10                    0.071357   0.064070     0.025377\n",
      "both\n",
      "                            optimistic  realistic  pessimistic\n",
      "inverse_harmonic_mean_rank    0.021701   0.019815     0.018756\n",
      "hits_at_1                     0.009799   0.009296     0.009296\n",
      "hits_at_3                     0.017714   0.014824     0.014698\n",
      "hits_at_5                     0.019472   0.018719     0.018216\n",
      "hits_at_10                    0.044347   0.040704     0.021357\n"
     ]
    }
   ],
   "source": [
    "testing_evaluation_start = time.time()\n",
    "# result on the test set\n",
    "print(\"Test error\")\n",
    "show_metrics(test_evaluator.evaluate(\n",
    "        model=model,\n",
    "        mapped_triples=dataset.inductive_testing.mapped_triples,\n",
    "        additional_filter_triples=[\n",
    "            # filtering of other positive triples\n",
    "            dataset.inductive_inference.mapped_triples,\n",
    "            dataset.inductive_validation.mapped_triples,\n",
    "        ],\n",
    "    ).to_dict(),model_name,'test_metrics')\n",
    "testing_evaluation_duration = time.time() - testing_evaluation_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6f9d0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "infodict = {}\n",
    "infodict['device'] = model.device\n",
    "infodict['parameters bytes'] = model.num_parameter_bytes\n",
    "infodict['number parameters'] = model.num_parameters\n",
    "infodict['training duration'] = training_duration\n",
    "infodict['training evaluation duration'] = training_evaluation_duration\n",
    "infodict['validation evaluation duration'] = validation_evaluation_duration\n",
    "infodict['testing evaluation duration'] = testing_evaluation_duration\n",
    "infodict[\"Operating system name\"] = platform.system()\n",
    "infodict[\"Operating system version\"] = platform.release()\n",
    "infodict[\"Processor architecture\"] = platform.machine()\n",
    "infodict[\"Python version\"] = sys.version\n",
    "infodict[\"Processor model name\"] = cpuinfo.get_cpu_info()['brand_raw']\n",
    "infodict['Number cpu cores'] = os.cpu_count()\n",
    "infodict[\"Total physical memory\"] = psutil.virtual_memory().total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "707be473",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output = subprocess.check_output(['nvidia-smi', '--query-gpu=name', '--format=csv'])\n",
    "output = output.decode('utf-8')  # convert byte string to regular string\n",
    "\n",
    "# split output into rows and remove header row\n",
    "rows = output.strip().split('\\n')[1:]\n",
    "\n",
    "# extract GPU names from each row\n",
    "gpu_names = []\n",
    "for row in rows:\n",
    "    name = row.strip()\n",
    "    gpu_names.append(name)\n",
    "\n",
    "infodict['GPU'] = gpu_names[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "efd13164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              name  \\\n",
      "0                           device   \n",
      "1                 parameters bytes   \n",
      "2                number parameters   \n",
      "3                training duration   \n",
      "4     training evaluation duration   \n",
      "5   validation evaluation duration   \n",
      "6      testing evaluation duration   \n",
      "7            Operating system name   \n",
      "8         Operating system version   \n",
      "9           Processor architecture   \n",
      "10                  Python version   \n",
      "11            Processor model name   \n",
      "12                Number cpu cores   \n",
      "13           Total physical memory   \n",
      "\n",
      "                                                value  \n",
      "0                                                 cpu  \n",
      "1                                               10400  \n",
      "2                                                2600  \n",
      "3                                           42.500668  \n",
      "4                                           318.45924  \n",
      "5                                           15.159921  \n",
      "6                                           19.057601  \n",
      "7                                             Windows  \n",
      "8                                                  10  \n",
      "9                                               AMD64  \n",
      "10  3.9.16 (main, Jan 11 2023, 16:16:36) [MSC v.19...  \n",
      "11             AMD Ryzen 7 5700U with Radeon Graphics  \n",
      "12                                                 16  \n",
      "13                                         7851745280  \n"
     ]
    }
   ],
   "source": [
    "info_df = pd.DataFrame(columns=['name','value'], data = infodict.items())\n",
    "info_df.to_csv(f\"{model_name}/{model_name}_information.csv\")\n",
    "print(info_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cfec9c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zip_folder(folder_path, output_path):\n",
    "    with zipfile.ZipFile(output_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "        for root, dirs, files in os.walk(folder_path):\n",
    "            for file in files:\n",
    "                zipf.write(os.path.join(root, file))\n",
    "\n",
    "folder_path = model_name\n",
    "output_path = f'{model_name}.zip'\n",
    "\n",
    "zip_folder(folder_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291c034f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
