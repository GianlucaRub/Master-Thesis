{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d30eabec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykeen.pipeline import pipeline\n",
    "from pykeen.datasets import Nations, get_dataset\n",
    "import torch\n",
    "from pykeen.evaluation import evaluate, RankBasedEvaluator\n",
    "from pykeen.metrics.ranking import HitsAtK\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "import click\n",
    "import more_click\n",
    "import torch\n",
    "from pykeen.evaluation import RankBasedEvaluator\n",
    "from pykeen.losses import NSSALoss,CrossEntropyLoss\n",
    "from pykeen.models.inductive import InductiveNodePiece, InductiveNodePieceGNN\n",
    "from pykeen.trackers import ConsoleResultTracker, WANDBResultTracker, FileResultTracker\n",
    "from pykeen.training import SLCWATrainingLoop\n",
    "from pykeen.typing import TESTING, TRAINING, VALIDATION\n",
    "from pykeen.utils import resolve_device, set_random_seed\n",
    "from torch.optim import Adam\n",
    "\n",
    "\n",
    "from pykeen.metrics.ranking import HitsAtK\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from pykeen.datasets.inductive.base import DisjointInductivePathDataset\n",
    "from typing_extensions import Literal\n",
    "import os\n",
    "from pykeen.hpo import hpo_pipeline\n",
    "from pykeen.triples import TriplesFactory\n",
    "from pykeen.models import InductiveNodePiece\n",
    "from pykeen.typing import TESTING, TRAINING, VALIDATION\n",
    "\n",
    "import time\n",
    "\n",
    "import platform\n",
    "\n",
    "import sys\n",
    "\n",
    "import cpuinfo\n",
    "\n",
    "import psutil\n",
    "\n",
    "import subprocess\n",
    "\n",
    "import zipfile\n",
    "\n",
    "seed = 1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59954771",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InductiveLPDataset(DisjointInductivePathDataset):\n",
    "    \"\"\"An inductive link prediction dataset for the ILPC 2022 Challenge.\"\"\"\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    def __init__(self , **kwargs):\n",
    "        \"\"\"Initialize the inductive link prediction dataset.\n",
    "\n",
    "        :param size: \"small\" or \"large\"\n",
    "        :param kwargs: keyword arguments to forward to the base dataset class, cf. DisjointInductivePathDataset\n",
    "        \"\"\"\n",
    "        DATA_TYPE = \"_fully_inductive.tsv\"\n",
    "        TRAIN_PATH = \"MSCallGraph_train\" + DATA_TYPE\n",
    "        TEST_PATH = \"MSCallGraph_test\" + DATA_TYPE\n",
    "        VALIDATE_PATH = \"MSCallGraph_validation\" + DATA_TYPE\n",
    "        INFERENCE_PATH = \"MSCallGraph_inference\" + DATA_TYPE\n",
    "\n",
    "\n",
    "        super().__init__(\n",
    "            transductive_training_path=os.getcwd()+\"/\"+TRAIN_PATH,\n",
    "            inductive_inference_path=os.getcwd()+\"/\"+INFERENCE_PATH,\n",
    "            inductive_validation_path=os.getcwd()+\"/\"+VALIDATE_PATH,\n",
    "            inductive_testing_path=os.getcwd()+\"/\"+TEST_PATH,\n",
    "            create_inverse_triples=True,\n",
    "            eager=True,\n",
    "            **kwargs\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fba970fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_metrics(dictionary,model_name,csv_name):\n",
    "    for key in dictionary.keys():\n",
    "        print(key)\n",
    "        df = pd.DataFrame(dictionary[key])\n",
    "        df.to_csv(f\"{model_name}/{model_name}_{csv_name}_{key}.csv\")\n",
    "        print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "766f31a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = InductiveLPDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b863c567",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'nodepiece_inductive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78e64fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker = ConsoleResultTracker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "141b31a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = NSSALoss() #used by RotatE and NodePiece\n",
    "num_tokens = 20\n",
    "embedding_dim = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eee10f05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling:   0%|          | 0.00/9.06k [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No symbolic computation of output shape.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling:   0%|          | 0.00/3.79k [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No symbolic computation of output shape.\n",
      "No cuda devices were available. The model runs on CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 2600\n",
      "Space occupied: 10400 bytes\n"
     ]
    }
   ],
   "source": [
    "model = InductiveNodePiece(\n",
    "        triples_factory=dataset.transductive_training,\n",
    "        inference_factory=dataset.inductive_inference,\n",
    "        random_seed = seed,\n",
    "        loss = loss,\n",
    "        num_tokens = num_tokens,\n",
    "        embedding_dim = embedding_dim\n",
    "    ).to(resolve_device())\n",
    "print(f\"Number of parameters: {sum(p.numel() for p in model.parameters())}\")\n",
    "print(f\"Space occupied: {model.num_parameter_bytes} bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61f247b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory nodepiece_inductive created successfully!\n"
     ]
    }
   ],
   "source": [
    "directory = model_name\n",
    "\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "    print(f'Directory {directory} created successfully!')\n",
    "else:\n",
    "    print(f'Directory {directory} already exists.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3530c9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "optimizer = Adam(params=model.parameters(), lr=learning_rate)\n",
    "num_epochs = 200\n",
    "patience = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fc2a40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['meanreciprocalrank', HitsAtK(1),\n",
    "                 HitsAtK(3), HitsAtK(5), HitsAtK(10)]\n",
    "\n",
    "train_evaluator = RankBasedEvaluator(\n",
    "        mode=TRAINING,\n",
    "        metrics=metrics,\n",
    "        add_defaults=False,\n",
    "    )\n",
    "valid_evaluator = RankBasedEvaluator(\n",
    "        mode=VALIDATION,\n",
    "        metrics=metrics,\n",
    "        add_defaults=False,\n",
    "    )\n",
    "test_evaluator = RankBasedEvaluator(\n",
    "        mode=TESTING,\n",
    "        metrics = metrics,\n",
    "        add_defaults=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf7cd0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykeen.stoppers import EarlyStopper\n",
    "\n",
    "stopper = EarlyStopper(\n",
    "    model = model,\n",
    "    metric='meanreciprocalrank',\n",
    "    patience=patience,\n",
    "    frequency=1,\n",
    "    evaluator = valid_evaluator,\n",
    "    training_triples_factory = dataset.inductive_inference,\n",
    "    evaluation_triples_factory = dataset.inductive_validation,\n",
    "    result_tracker = tracker\n",
    "\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae4971a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default training regime is negative sampling (SLCWA)\n",
    "# you can also use the 1-N regime with the LCWATrainingLoop\n",
    "# the LCWA loop does not need negative sampling kwargs, but accepts label_smoothing in the .train() method\n",
    "training_loop = SLCWATrainingLoop(\n",
    "        triples_factory=dataset.transductive_training,\n",
    "        model=model,\n",
    "        mode=TRAINING,  # must be specified for the inductive setup\n",
    "        result_tracker=tracker,\n",
    "        optimizer=optimizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fdf15a48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83c628c207ff4c54bb4c52f2158e1a35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epochs on cpu:   0%|          | 0/1 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches on cpu:   0%|          | 0/184 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad8477e20abd49e99903756aa6513226",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating on cpu:   0%|          | 0.00/3.13k [00:00<?, ?triple/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1\n",
      "Metric: validation.head.optimistic.inverse_harmonic_mean_rank = 0.012930770823913638\n",
      "Metric: validation.tail.optimistic.inverse_harmonic_mean_rank = 0.03472970555065172\n",
      "Metric: validation.both.optimistic.inverse_harmonic_mean_rank = 0.02383023818728268\n",
      "Metric: validation.head.realistic.inverse_harmonic_mean_rank = 0.012290675193071365\n",
      "Metric: validation.tail.realistic.inverse_harmonic_mean_rank = 0.031767670065164566\n",
      "Metric: validation.both.realistic.inverse_harmonic_mean_rank = 0.022029172629117966\n",
      "Metric: validation.head.pessimistic.inverse_harmonic_mean_rank = 0.011896052585445814\n",
      "Metric: validation.tail.pessimistic.inverse_harmonic_mean_rank = 0.030488843364832062\n",
      "Metric: validation.both.pessimistic.inverse_harmonic_mean_rank = 0.021192447975138935\n",
      "Metric: validation.head.optimistic.hits_at_1 = 0.0063959066197633516\n",
      "Metric: validation.tail.optimistic.hits_at_1 = 0.017588743204349215\n",
      "Metric: validation.both.optimistic.hits_at_1 = 0.011992324912056283\n",
      "Metric: validation.head.realistic.hits_at_1 = 0.0063959066197633516\n",
      "Metric: validation.tail.realistic.hits_at_1 = 0.01598976654940838\n",
      "Metric: validation.both.realistic.hits_at_1 = 0.011192836584585865\n",
      "Metric: validation.head.pessimistic.hits_at_1 = 0.0063959066197633516\n",
      "Metric: validation.tail.pessimistic.hits_at_1 = 0.01598976654940838\n",
      "Metric: validation.both.pessimistic.hits_at_1 = 0.011192836584585865\n",
      "Metric: validation.head.optimistic.hits_at_3 = 0.011512631915574032\n",
      "Metric: validation.tail.optimistic.hits_at_3 = 0.023984649824112567\n",
      "Metric: validation.both.optimistic.hits_at_3 = 0.0177486408698433\n",
      "Metric: validation.head.realistic.hits_at_3 = 0.011192836584585865\n",
      "Metric: validation.tail.realistic.hits_at_3 = 0.021426287176207228\n",
      "Metric: validation.both.realistic.hits_at_3 = 0.016309561880396548\n",
      "Metric: validation.head.pessimistic.hits_at_3 = 0.011192836584585865\n",
      "Metric: validation.tail.pessimistic.hits_at_3 = 0.021426287176207228\n",
      "Metric: validation.both.pessimistic.hits_at_3 = 0.016309561880396548\n",
      "Metric: validation.head.optimistic.hits_at_5 = 0.013431403901503039\n",
      "Metric: validation.tail.optimistic.hits_at_5 = 0.03197953309881676\n",
      "Metric: validation.both.optimistic.hits_at_5 = 0.0227054685001599\n",
      "Metric: validation.head.realistic.hits_at_5 = 0.01311160857051487\n",
      "Metric: validation.tail.realistic.hits_at_5 = 0.028781579788935082\n",
      "Metric: validation.both.realistic.hits_at_5 = 0.020946594179724977\n",
      "Metric: validation.head.pessimistic.hits_at_5 = 0.01311160857051487\n",
      "Metric: validation.tail.pessimistic.hits_at_5 = 0.02750239846498241\n",
      "Metric: validation.both.pessimistic.hits_at_5 = 0.02030700351774864\n",
      "Metric: validation.head.optimistic.hits_at_10 = 0.016629357211384713\n",
      "Metric: validation.tail.optimistic.hits_at_10 = 0.07323313079629037\n",
      "Metric: validation.both.optimistic.hits_at_10 = 0.044931244003837544\n",
      "Metric: validation.head.realistic.hits_at_10 = 0.016309561880396548\n",
      "Metric: validation.tail.realistic.hits_at_10 = 0.06172049888071634\n",
      "Metric: validation.both.realistic.hits_at_10 = 0.03901503038055645\n",
      "Metric: validation.head.pessimistic.hits_at_10 = 0.01566997121842021\n",
      "Metric: validation.tail.pessimistic.hits_at_10 = 0.058522545570834666\n",
      "Metric: validation.both.pessimistic.hits_at_10 = 0.03709625839462744\n",
      "Step: 1\n",
      "Metric: loss = 2.726568308537421\n",
      "Step: 1\n",
      "Metric: validation.head.optimistic.inverse_harmonic_mean_rank = 0.012930770823913638\n",
      "Metric: validation.tail.optimistic.inverse_harmonic_mean_rank = 0.03472970555065172\n",
      "Metric: validation.both.optimistic.inverse_harmonic_mean_rank = 0.02383023818728268\n",
      "Metric: validation.head.realistic.inverse_harmonic_mean_rank = 0.012290675193071365\n",
      "Metric: validation.tail.realistic.inverse_harmonic_mean_rank = 0.031767670065164566\n",
      "Metric: validation.both.realistic.inverse_harmonic_mean_rank = 0.022029172629117966\n",
      "Metric: validation.head.pessimistic.inverse_harmonic_mean_rank = 0.011896052585445814\n",
      "Metric: validation.tail.pessimistic.inverse_harmonic_mean_rank = 0.030488843364832062\n",
      "Metric: validation.both.pessimistic.inverse_harmonic_mean_rank = 0.021192447975138935\n",
      "Metric: validation.head.optimistic.hits_at_1 = 0.0063959066197633516\n",
      "Metric: validation.tail.optimistic.hits_at_1 = 0.017588743204349215\n",
      "Metric: validation.both.optimistic.hits_at_1 = 0.011992324912056283\n",
      "Metric: validation.head.realistic.hits_at_1 = 0.0063959066197633516\n",
      "Metric: validation.tail.realistic.hits_at_1 = 0.01598976654940838\n",
      "Metric: validation.both.realistic.hits_at_1 = 0.011192836584585865\n",
      "Metric: validation.head.pessimistic.hits_at_1 = 0.0063959066197633516\n",
      "Metric: validation.tail.pessimistic.hits_at_1 = 0.01598976654940838\n",
      "Metric: validation.both.pessimistic.hits_at_1 = 0.011192836584585865\n",
      "Metric: validation.head.optimistic.hits_at_3 = 0.011512631915574032\n",
      "Metric: validation.tail.optimistic.hits_at_3 = 0.023984649824112567\n",
      "Metric: validation.both.optimistic.hits_at_3 = 0.0177486408698433\n",
      "Metric: validation.head.realistic.hits_at_3 = 0.011192836584585865\n",
      "Metric: validation.tail.realistic.hits_at_3 = 0.021426287176207228\n",
      "Metric: validation.both.realistic.hits_at_3 = 0.016309561880396548\n",
      "Metric: validation.head.pessimistic.hits_at_3 = 0.011192836584585865\n",
      "Metric: validation.tail.pessimistic.hits_at_3 = 0.021426287176207228\n",
      "Metric: validation.both.pessimistic.hits_at_3 = 0.016309561880396548\n",
      "Metric: validation.head.optimistic.hits_at_5 = 0.013431403901503039\n",
      "Metric: validation.tail.optimistic.hits_at_5 = 0.03197953309881676\n",
      "Metric: validation.both.optimistic.hits_at_5 = 0.0227054685001599\n",
      "Metric: validation.head.realistic.hits_at_5 = 0.01311160857051487\n",
      "Metric: validation.tail.realistic.hits_at_5 = 0.028781579788935082\n",
      "Metric: validation.both.realistic.hits_at_5 = 0.020946594179724977\n",
      "Metric: validation.head.pessimistic.hits_at_5 = 0.01311160857051487\n",
      "Metric: validation.tail.pessimistic.hits_at_5 = 0.02750239846498241\n",
      "Metric: validation.both.pessimistic.hits_at_5 = 0.02030700351774864\n",
      "Metric: validation.head.optimistic.hits_at_10 = 0.016629357211384713\n",
      "Metric: validation.tail.optimistic.hits_at_10 = 0.07323313079629037\n",
      "Metric: validation.both.optimistic.hits_at_10 = 0.044931244003837544\n",
      "Metric: validation.head.realistic.hits_at_10 = 0.016309561880396548\n",
      "Metric: validation.tail.realistic.hits_at_10 = 0.06172049888071634\n",
      "Metric: validation.both.realistic.hits_at_10 = 0.03901503038055645\n",
      "Metric: validation.head.pessimistic.hits_at_10 = 0.01566997121842021\n",
      "Metric: validation.tail.pessimistic.hits_at_10 = 0.058522545570834666\n",
      "Metric: validation.both.pessimistic.hits_at_10 = 0.03709625839462744\n"
     ]
    }
   ],
   "source": [
    "training_start = time.time()\n",
    "train_epoch =  training_loop.train(\n",
    "        triples_factory=dataset.transductive_training,\n",
    "        num_epochs=num_epochs,\n",
    "        callbacks=\"evaluation\",\n",
    "        callback_kwargs=dict(\n",
    "            evaluator=valid_evaluator,\n",
    "            evaluation_triples=dataset.inductive_validation.mapped_triples,\n",
    "            prefix=\"validation\",\n",
    "            frequency=1,\n",
    "            additional_filter_triples=dataset.inductive_inference.mapped_triples,\n",
    "        ),\n",
    "        stopper = stopper\n",
    "        \n",
    "    )\n",
    "training_duration = time.time() - training_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98f77bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train error per epoch:\n",
      "          0\n",
      "0  2.726568\n"
     ]
    }
   ],
   "source": [
    "print(\"Train error per epoch:\")\n",
    "df = pd.DataFrame(train_epoch)\n",
    "print(df)\n",
    "df.to_csv(f\"{model_name}/{model_name}_train_error_per_epoch.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4aabaae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train error\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9edb8536df643c78589b033d6ab4c6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating on cpu:   0%|          | 0.00/23.5k [00:00<?, ?triple/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head\n",
      "                            optimistic  realistic  pessimistic\n",
      "inverse_harmonic_mean_rank    0.004026   0.003228     0.002842\n",
      "hits_at_1                     0.000681   0.000681     0.000681\n",
      "hits_at_3                     0.003705   0.001107     0.001065\n",
      "hits_at_5                     0.004983   0.002555     0.001576\n",
      "hits_at_10                    0.007155   0.005494     0.005239\n",
      "tail\n",
      "                            optimistic  realistic  pessimistic\n",
      "inverse_harmonic_mean_rank    0.009835   0.008306     0.007555\n",
      "hits_at_1                     0.002002   0.001576     0.001576\n",
      "hits_at_3                     0.006942   0.003280     0.003280\n",
      "hits_at_5                     0.007283   0.003918     0.003876\n",
      "hits_at_10                    0.016312   0.010477     0.010477\n",
      "both\n",
      "                            optimistic  realistic  pessimistic\n",
      "inverse_harmonic_mean_rank    0.006930   0.005767     0.005199\n",
      "hits_at_1                     0.001342   0.001129     0.001129\n",
      "hits_at_3                     0.005324   0.002193     0.002172\n",
      "hits_at_5                     0.006133   0.003237     0.002726\n",
      "hits_at_10                    0.011734   0.007986     0.007858\n"
     ]
    }
   ],
   "source": [
    "training_evaluation_start = time.time()\n",
    "# train\n",
    "print(\"Train error\")\n",
    "show_metrics(train_evaluator.evaluate(\n",
    "        model=model,\n",
    "        mapped_triples=dataset.transductive_training.mapped_triples,\n",
    "        additional_filter_triples=[\n",
    "        dataset.transductive_training.mapped_triples,\n",
    "    ]\n",
    "    ).to_dict(),model_name,'train_metrics')\n",
    "training_evaluation_duration = time.time() - training_evaluation_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3c7e30e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation error\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1b4d76e026d43458fddeb59f3b23ebc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating on cpu:   0%|          | 0.00/3.13k [00:00<?, ?triple/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head\n",
      "                            optimistic  realistic  pessimistic\n",
      "inverse_harmonic_mean_rank    0.012931   0.012291     0.011896\n",
      "hits_at_1                     0.006396   0.006396     0.006396\n",
      "hits_at_3                     0.011513   0.011193     0.011193\n",
      "hits_at_5                     0.013431   0.013112     0.013112\n",
      "hits_at_10                    0.016629   0.016310     0.015670\n",
      "tail\n",
      "                            optimistic  realistic  pessimistic\n",
      "inverse_harmonic_mean_rank    0.034730   0.031768     0.030489\n",
      "hits_at_1                     0.017589   0.015990     0.015990\n",
      "hits_at_3                     0.023985   0.021426     0.021426\n",
      "hits_at_5                     0.031980   0.028782     0.027502\n",
      "hits_at_10                    0.073233   0.061720     0.058523\n",
      "both\n",
      "                            optimistic  realistic  pessimistic\n",
      "inverse_harmonic_mean_rank    0.023830   0.022029     0.021192\n",
      "hits_at_1                     0.011992   0.011193     0.011193\n",
      "hits_at_3                     0.017749   0.016310     0.016310\n",
      "hits_at_5                     0.022705   0.020947     0.020307\n",
      "hits_at_10                    0.044931   0.039015     0.037096\n"
     ]
    }
   ],
   "source": [
    "validation_evaluation_start = time.time()\n",
    "# validation\n",
    "print(\"Validation error\")\n",
    "show_metrics(valid_evaluator.evaluate(\n",
    "        model=model,\n",
    "        mapped_triples=dataset.inductive_validation.mapped_triples,\n",
    "        additional_filter_triples=[\n",
    "            # filtering of other positive triples\n",
    "            dataset.inductive_inference.mapped_triples\n",
    "        ],\n",
    "    ).to_dict(),model_name,'validation_metrics')\n",
    "validation_evaluation_duration = time.time() - validation_evaluation_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98aaf677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bc19b535bf54dbdafd08e72781ffbfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating on cpu:   0%|          | 0.00/3.98k [00:00<?, ?triple/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head\n",
      "                            optimistic  realistic  pessimistic\n",
      "inverse_harmonic_mean_rank    0.013539   0.012773     0.012297\n",
      "hits_at_1                     0.006533   0.006533     0.006533\n",
      "hits_at_3                     0.013065   0.013065     0.013065\n",
      "hits_at_5                     0.014573   0.014322     0.014322\n",
      "hits_at_10                    0.017337   0.017337     0.017085\n",
      "tail\n",
      "                            optimistic  realistic  pessimistic\n",
      "inverse_harmonic_mean_rank    0.029632   0.027024     0.025812\n",
      "hits_at_1                     0.012814   0.012060     0.012060\n",
      "hits_at_3                     0.020854   0.018090     0.018090\n",
      "hits_at_5                     0.026382   0.021859     0.021357\n",
      "hits_at_10                    0.066080   0.053015     0.051005\n",
      "both\n",
      "                            optimistic  realistic  pessimistic\n",
      "inverse_harmonic_mean_rank    0.021586   0.019898     0.019055\n",
      "hits_at_1                     0.009673   0.009296     0.009296\n",
      "hits_at_3                     0.016960   0.015578     0.015578\n",
      "hits_at_5                     0.020477   0.018090     0.017839\n",
      "hits_at_10                    0.041709   0.035176     0.034045\n"
     ]
    }
   ],
   "source": [
    "testing_evaluation_start = time.time()\n",
    "# result on the test set\n",
    "print(\"Test error\")\n",
    "show_metrics(test_evaluator.evaluate(\n",
    "        model=model,\n",
    "        mapped_triples=dataset.inductive_testing.mapped_triples,\n",
    "        additional_filter_triples=[\n",
    "            # filtering of other positive triples\n",
    "            dataset.inductive_inference.mapped_triples,\n",
    "            dataset.inductive_validation.mapped_triples,\n",
    "        ],\n",
    "    ).to_dict(),model_name,'test_metrics')\n",
    "testing_evaluation_duration = time.time() - testing_evaluation_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dcb170ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "infodict = {}\n",
    "infodict['device'] = model.device\n",
    "infodict['parameters bytes'] = model.num_parameter_bytes\n",
    "infodict['number parameters'] = model.num_parameters\n",
    "infodict['training duration'] = training_duration\n",
    "infodict['training evaluation duration'] = training_evaluation_duration\n",
    "infodict['validation evaluation duration'] = validation_evaluation_duration\n",
    "infodict['testing evaluation duration'] = testing_evaluation_duration\n",
    "infodict[\"Operating system name\"] = platform.system()\n",
    "infodict[\"Operating system version\"] = platform.release()\n",
    "infodict[\"Processor architecture\"] = platform.machine()\n",
    "infodict[\"Python version\"] = sys.version\n",
    "infodict[\"Processor model name\"] = cpuinfo.get_cpu_info()['brand_raw']\n",
    "infodict['Number cpu cores'] = os.cpu_count()\n",
    "infodict[\"Total physical memory\"] = psutil.virtual_memory().total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cc302cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output = subprocess.check_output(['nvidia-smi', '--query-gpu=name', '--format=csv'])\n",
    "output = output.decode('utf-8')  # convert byte string to regular string\n",
    "\n",
    "# split output into rows and remove header row\n",
    "rows = output.strip().split('\\n')[1:]\n",
    "\n",
    "# extract GPU names from each row\n",
    "gpu_names = []\n",
    "for row in rows:\n",
    "    name = row.strip()\n",
    "    gpu_names.append(name)\n",
    "\n",
    "infodict['GPU'] = gpu_names[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7079e496",
   "metadata": {},
   "outputs": [],
   "source": [
    "infodict['loss'] = NSSALoss\n",
    "infodict['num_tokens'] = num_tokens\n",
    "infodict['embedding_dim'] = embedding_dim\n",
    "infodict['learning_rate'] = learning_rate\n",
    "infodict['optimizer'] = Adam\n",
    "infodict['num_epochs'] = num_epochs\n",
    "infodict['patience'] = patience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "43a75c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              name  \\\n",
      "0                           device   \n",
      "1                 parameters bytes   \n",
      "2                number parameters   \n",
      "3                training duration   \n",
      "4     training evaluation duration   \n",
      "5   validation evaluation duration   \n",
      "6      testing evaluation duration   \n",
      "7            Operating system name   \n",
      "8         Operating system version   \n",
      "9           Processor architecture   \n",
      "10                  Python version   \n",
      "11            Processor model name   \n",
      "12                Number cpu cores   \n",
      "13           Total physical memory   \n",
      "14                            loss   \n",
      "15                      num_tokens   \n",
      "16                   embedding_dim   \n",
      "17                   learning_rate   \n",
      "18                       optimizer   \n",
      "19                      num_epochs   \n",
      "20                        patience   \n",
      "\n",
      "                                                value  \n",
      "0                                                 cpu  \n",
      "1                                               10400  \n",
      "2                                                2600  \n",
      "3                                           45.056041  \n",
      "4                                          310.346963  \n",
      "5                                           18.037162  \n",
      "6                                           23.113256  \n",
      "7                                             Windows  \n",
      "8                                                  10  \n",
      "9                                               AMD64  \n",
      "10  3.9.16 (main, Jan 11 2023, 16:16:36) [MSC v.19...  \n",
      "11             AMD Ryzen 7 5700U with Radeon Graphics  \n",
      "12                                                 16  \n",
      "13                                         7851745280  \n",
      "14                   <class 'pykeen.losses.NSSALoss'>  \n",
      "15                                                 20  \n",
      "16                                                200  \n",
      "17                                              0.001  \n",
      "18                    <class 'torch.optim.adam.Adam'>  \n",
      "19                                                  1  \n",
      "20                                                 20  \n"
     ]
    }
   ],
   "source": [
    "info_df = pd.DataFrame(columns=['name','value'], data = infodict.items())\n",
    "info_df.to_csv(f\"{model_name}/{model_name}_information.csv\")\n",
    "print(info_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "28602afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zip_folder(folder_path, output_path):\n",
    "    with zipfile.ZipFile(output_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "        for root, dirs, files in os.walk(folder_path):\n",
    "            for file in files:\n",
    "                zipf.write(os.path.join(root, file))\n",
    "\n",
    "folder_path = model_name\n",
    "output_path = f'{model_name}.zip'\n",
    "\n",
    "zip_folder(folder_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ad8fdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
